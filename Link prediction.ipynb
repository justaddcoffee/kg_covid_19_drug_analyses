{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction\n",
    "In this notebook we do link prediction starting from the embeddings\n",
    "previously obtained from for example Skipgram, CBOW, GloVe\n",
    "\n",
    "Graphs used in the NB are available here:\n",
    "http://doi.org/10.5281/zenodo.4011267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto # Import needed to avoid TensorFlow warnings and general useless infos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge embeddings\n",
    "We will compute the edge embeddings using all the 5 available methods:\n",
    "\n",
    "- Hadamart: an element-wise product\n",
    "- Mean\n",
    "- Norm L1\n",
    "- Norm L2\n",
    "- Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a simple Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.metrics import AUC, Recall, Precision\n",
    "\n",
    "def build_link_prediction_model(input_shape:int):\n",
    "    model = Sequential([\n",
    "        Input(input_shape),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"nadam\",\n",
    "        metrics=[\n",
    "            AUC(curve=\"PR\", name=\"auprc\"),\n",
    "            AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "            Recall(),\n",
    "            Precision(),\n",
    "            \"accuracy\"\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "graph = EnsmallenGraph.from_csv(\n",
    "    edge_path=\"/home/jtr4v/merged-kg_edges.tsv\",\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    edge_types_column=\"edge_label\",\n",
    "    default_edge_type=\"biolink:association\",\n",
    "    node_path=\"/home/jtr4v/merged-kg_nodes.tsv\",\n",
    "    nodes_column=\"id\",\n",
    "    node_types_column=\"category\",\n",
    "    default_node_type=\"biolink:NamedThing\",\n",
    "    ignore_duplicated_edges=True,\n",
    "    ignore_duplicated_nodes=True,\n",
    "    force_conversion_to_undirected=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degrees_max': '90378',\n",
       " 'unique_edge_types_number': '211',\n",
       " 'degrees_min': '0',\n",
       " 'singleton_nodes': '8223',\n",
       " 'density': '0.00021904928054478553',\n",
       " 'degrees_mean': '82.22343319169342',\n",
       " 'strongly_connected_components_number': '8976',\n",
       " 'degrees_median': '6',\n",
       " 'traps_rate': '0.021906677500566116',\n",
       " 'nodes_number': '375365',\n",
       " 'is_directed': 'false',\n",
       " 'edges_number': '30863799',\n",
       " 'selfloops_rate': '0.00001539019872440201',\n",
       " 'connected_components_number': '8976',\n",
       " 'bidirectional_rate': '1',\n",
       " 'unique_node_types_number': '36',\n",
       " 'degrees_mode': '1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining holdouts and tasks data generator\n",
    "We are going to create the same edge embeddings as in the training of the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "train_percentage = 0.8\n",
    "\n",
    "pos_training, pos_validation = graph.connected_holdout(seed, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python /home/jtr4v/kg_covid_19_drug_analyses/kg-covid-19/run.py edges -n /home/jtr4v/merged-kg_nodes-min.tsv -e /home/jtr4v/merged-kg_edges-min.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_training, neg_validation = graph.sample_negatives(\n",
    "#    seed=seed,\n",
    "#    negatives_number=graph.get_edges_number(),\n",
    "#    allow_selfloops=False\n",
    "#).random_holdout(seed=seed, train_percentage=train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "neg_validation = EnsmallenGraph.from_csv(\n",
    "    edge_path=\"/home/jtr4v/kg_covid_19_drug_analyses/kg-covid-19/data/edges/neg_test_edges.tsv\",\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    edge_types_column=\"edge_label\",\n",
    "    default_node_type=\"biolink:NamedThing\",\n",
    "    ignore_duplicated_edges=True,\n",
    "    ignore_duplicated_nodes=True,\n",
    "    force_conversion_to_undirected=True\n",
    ")\n",
    "\n",
    "neg_training = EnsmallenGraph.from_csv(\n",
    "    edge_path=\"/home/jtr4v/kg_covid_19_drug_analyses/kg-covid-19/data/edges/neg_train_edges.tsv\",\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    edge_types_column=\"edge_label\",\n",
    "    default_node_type=\"biolink:NamedThing\",\n",
    "    ignore_duplicated_edges=True,\n",
    "    ignore_duplicated_nodes=True,\n",
    "    force_conversion_to_undirected=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_percentage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a533c6fb735e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mneg_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mEnsmallenGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mneg_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mEnsmallenGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_percentage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_percentage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m ):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_percentage' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "from embiggen import GraphTransformer, EdgeTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def task_generator(\n",
    "    pos_training:EnsmallenGraph,\n",
    "    pos_validation:EnsmallenGraph,\n",
    "    neg_training:EnsmallenGraph,\n",
    "    neg_validation:EnsmallenGraph,\n",
    "    train_percentage:float=train_percentage,\n",
    "    seed:int=seed\n",
    "):\n",
    "    \"\"\"Create new generator of tasks.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------------------\n",
    "    pos_training:EnsmallenGraph,\n",
    "        The positive edges of the training graph.\n",
    "    pos_validation:EnsmallenGraph,\n",
    "        The positive edges of the validation graph.\n",
    "    neg_training:EnsmallenGraph,\n",
    "        The negative edges of the training graph.\n",
    "    neg_validation:EnsmallenGraph,\n",
    "        The negative edges of the validation graph.\n",
    "    train_percentage:float=0.8,\n",
    "    seed:int=42\n",
    "\n",
    "    \"\"\"\n",
    "    for path in tqdm(glob(\"*embedding.npy\"), desc=\"Embedding\"):\n",
    "        model_name = path.split(\"_\")[0]\n",
    "        embedding = np.load(path)\n",
    "        for method in tqdm(EdgeTransformer.methods, desc=\"Methods\", leave=False):\n",
    "            transformer = GraphTransformer(method)\n",
    "            transformer.fit(embedding)\n",
    "            train_edges = np.vstack([\n",
    "                transformer.transform(graph)\n",
    "                for graph in (pos_training, neg_training)\n",
    "            ])\n",
    "            valid_edges = np.vstack([\n",
    "                transformer.transform(graph)\n",
    "                for graph in (pos_validation, neg_validation)\n",
    "            ])\n",
    "            train_labels = np.concatenate([\n",
    "                np.ones(pos_training.get_edges_number()),\n",
    "                np.zeros(neg_training.get_edges_number())\n",
    "            ])\n",
    "            valid_labels = np.concatenate([\n",
    "                np.ones(pos_validation.get_edges_number()),\n",
    "                np.zeros(neg_validation.get_edges_number())\n",
    "            ])\n",
    "            train_indices = np.arange(0, train_labels.size)\n",
    "            valid_indices = np.arange(0, valid_labels.size)\n",
    "            np.random.shuffle(train_indices)\n",
    "            np.random.shuffle(valid_indices)\n",
    "            train_edges = train_edges[train_indices]\n",
    "            train_labels = train_labels[train_indices]\n",
    "            valid_edges = valid_edges[valid_indices]\n",
    "            valid_labels = valid_labels[valid_indices]\n",
    "            yield model_name, method, (train_edges, train_labels), (valid_edges, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d87c028b9e4f4dabf42e99087ce206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Embedding', max=1.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac957d48bf54c2ea51830f0a662daed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Methods', max=4.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "14383/14383 [==============================] - 120s 8ms/step - loss: 0.1431 - auprc: 0.9772 - auroc: 0.9855 - recall: 0.9465 - precision: 0.9362 - accuracy: 0.9505 - val_loss: 0.1721 - val_auprc: 0.9772 - val_auroc: 0.9865 - val_recall: 0.9430 - val_precision: 0.9473 - val_accuracy: 0.9541\n",
      "Epoch 2/1000\n",
      "14383/14383 [==============================] - 109s 8ms/step - loss: 0.1289 - auprc: 0.9811 - auroc: 0.9882 - recall: 0.9493 - precision: 0.9427 - accuracy: 0.9545 - val_loss: 0.1529 - val_auprc: 0.9794 - val_auroc: 0.9877 - val_recall: 0.9490 - val_precision: 0.9462 - val_accuracy: 0.9560\n",
      "Epoch 3/1000\n",
      "14383/14383 [==============================] - 110s 8ms/step - loss: 0.1255 - auprc: 0.9820 - auroc: 0.9888 - recall: 0.9493 - precision: 0.9452 - accuracy: 0.9557 - val_loss: 0.1510 - val_auprc: 0.9803 - val_auroc: 0.9881 - val_recall: 0.9558 - val_precision: 0.9412 - val_accuracy: 0.9564\n",
      "Epoch 4/1000\n",
      "14383/14383 [==============================] - 108s 8ms/step - loss: 0.1239 - auprc: 0.9824 - auroc: 0.9890 - recall: 0.9498 - precision: 0.9460 - accuracy: 0.9562 - val_loss: 0.1415 - val_auprc: 0.9800 - val_auroc: 0.9882 - val_recall: 0.9586 - val_precision: 0.9381 - val_accuracy: 0.9561\n",
      "Epoch 5/1000\n",
      "14383/14383 [==============================] - 119s 8ms/step - loss: 0.1230 - auprc: 0.9826 - auroc: 0.9892 - recall: 0.9501 - precision: 0.9464 - accuracy: 0.9565 - val_loss: 0.1432 - val_auprc: 0.9792 - val_auroc: 0.9878 - val_recall: 0.9565 - val_precision: 0.9407 - val_accuracy: 0.9565\n",
      "Epoch 6/1000\n",
      "14383/14383 [==============================] - 108s 8ms/step - loss: 0.1223 - auprc: 0.9828 - auroc: 0.9893 - recall: 0.9505 - precision: 0.9466 - accuracy: 0.9568 - val_loss: 0.1414 - val_auprc: 0.9805 - val_auroc: 0.9884 - val_recall: 0.9623 - val_precision: 0.9345 - val_accuracy: 0.9559\n",
      "Epoch 7/1000\n",
      "14383/14383 [==============================] - 110s 8ms/step - loss: 0.1217 - auprc: 0.9829 - auroc: 0.9894 - recall: 0.9505 - precision: 0.9469 - accuracy: 0.9569 - val_loss: 0.1403 - val_auprc: 0.9807 - val_auroc: 0.9885 - val_recall: 0.9624 - val_precision: 0.9356 - val_accuracy: 0.9565\n",
      "Epoch 8/1000\n",
      "14383/14383 [==============================] - 111s 8ms/step - loss: 0.1213 - auprc: 0.9830 - auroc: 0.9895 - recall: 0.9507 - precision: 0.9471 - accuracy: 0.9571 - val_loss: 0.1455 - val_auprc: 0.9798 - val_auroc: 0.9882 - val_recall: 0.9602 - val_precision: 0.9383 - val_accuracy: 0.9569\n",
      "Epoch 9/1000\n",
      "14383/14383 [==============================] - 109s 8ms/step - loss: 0.1209 - auprc: 0.9831 - auroc: 0.9895 - recall: 0.9508 - precision: 0.9473 - accuracy: 0.9572 - val_loss: 0.1378 - val_auprc: 0.9807 - val_auroc: 0.9885 - val_recall: 0.9573 - val_precision: 0.9417 - val_accuracy: 0.9573\n",
      "Epoch 10/1000\n",
      "14383/14383 [==============================] - 112s 8ms/step - loss: 0.1206 - auprc: 0.9832 - auroc: 0.9896 - recall: 0.9509 - precision: 0.9475 - accuracy: 0.9573 - val_loss: 0.1391 - val_auprc: 0.9810 - val_auroc: 0.9886 - val_recall: 0.9627 - val_precision: 0.9354 - val_accuracy: 0.9565\n",
      "Epoch 11/1000\n",
      "14383/14383 [==============================] - 111s 8ms/step - loss: 0.1203 - auprc: 0.9833 - auroc: 0.9896 - recall: 0.9510 - precision: 0.9476 - accuracy: 0.9574 - val_loss: 0.1402 - val_auprc: 0.9806 - val_auroc: 0.9886 - val_recall: 0.9649 - val_precision: 0.9320 - val_accuracy: 0.9558\n",
      "Epoch 12/1000\n",
      "14383/14383 [==============================] - 110s 8ms/step - loss: 0.1200 - auprc: 0.9833 - auroc: 0.9897 - recall: 0.9510 - precision: 0.9479 - accuracy: 0.9575 - val_loss: 0.1454 - val_auprc: 0.9812 - val_auroc: 0.9888 - val_recall: 0.9630 - val_precision: 0.9352 - val_accuracy: 0.9565\n",
      "Epoch 13/1000\n",
      "14383/14383 [==============================] - 121s 8ms/step - loss: 0.1198 - auprc: 0.9834 - auroc: 0.9897 - recall: 0.9509 - precision: 0.9480 - accuracy: 0.9576 - val_loss: 0.1405 - val_auprc: 0.9809 - val_auroc: 0.9887 - val_recall: 0.9615 - val_precision: 0.9376 - val_accuracy: 0.9570\n",
      "Epoch 14/1000\n",
      "14383/14383 [==============================] - 129s 9ms/step - loss: 0.1196 - auprc: 0.9834 - auroc: 0.9897 - recall: 0.9510 - precision: 0.9481 - accuracy: 0.9576 - val_loss: 0.1379 - val_auprc: 0.9814 - val_auroc: 0.9888 - val_recall: 0.9651 - val_precision: 0.9315 - val_accuracy: 0.9557\n",
      "Epoch 15/1000\n",
      "14383/14383 [==============================] - 109s 8ms/step - loss: 0.1195 - auprc: 0.9835 - auroc: 0.9898 - recall: 0.9510 - precision: 0.9482 - accuracy: 0.9577 - val_loss: 0.1430 - val_auprc: 0.9808 - val_auroc: 0.9887 - val_recall: 0.9660 - val_precision: 0.9311 - val_accuracy: 0.9558\n",
      "Epoch 16/1000\n",
      "14383/14383 [==============================] - 108s 8ms/step - loss: 0.1193 - auprc: 0.9835 - auroc: 0.9898 - recall: 0.9508 - precision: 0.9485 - accuracy: 0.9577 - val_loss: 0.1472 - val_auprc: 0.9808 - val_auroc: 0.9886 - val_recall: 0.9634 - val_precision: 0.9347 - val_accuracy: 0.9564\n",
      "Epoch 17/1000\n",
      "14383/14383 [==============================] - 107s 7ms/step - loss: 0.1192 - auprc: 0.9835 - auroc: 0.9898 - recall: 0.9508 - precision: 0.9486 - accuracy: 0.9578 - val_loss: 0.1429 - val_auprc: 0.9808 - val_auroc: 0.9886 - val_recall: 0.9651 - val_precision: 0.9325 - val_accuracy: 0.9561\n",
      "Epoch 18/1000\n",
      "14383/14383 [==============================] - 111s 8ms/step - loss: 0.1190 - auprc: 0.9836 - auroc: 0.9898 - recall: 0.9509 - precision: 0.9486 - accuracy: 0.9578 - val_loss: 0.1426 - val_auprc: 0.9807 - val_auroc: 0.9886 - val_recall: 0.9645 - val_precision: 0.9329 - val_accuracy: 0.9561\n",
      "Epoch 19/1000\n",
      "14383/14383 [==============================] - 107s 7ms/step - loss: 0.1189 - auprc: 0.9836 - auroc: 0.9898 - recall: 0.9508 - precision: 0.9488 - accuracy: 0.9579 - val_loss: 0.1492 - val_auprc: 0.9802 - val_auroc: 0.9885 - val_recall: 0.9601 - val_precision: 0.9383 - val_accuracy: 0.9568\n",
      "Epoch 20/1000\n",
      "14383/14383 [==============================] - 107s 7ms/step - loss: 0.1175 - auprc: 0.9841 - auroc: 0.9901 - recall: 0.9511 - precision: 0.9495 - accuracy: 0.9583 - val_loss: 0.1431 - val_auprc: 0.9813 - val_auroc: 0.9889 - val_recall: 0.9667 - val_precision: 0.9303 - val_accuracy: 0.9557\n",
      "Epoch 21/1000\n",
      "14383/14383 [==============================] - 108s 7ms/step - loss: 0.1173 - auprc: 0.9841 - auroc: 0.9901 - recall: 0.9511 - precision: 0.9495 - accuracy: 0.9583 - val_loss: 0.1411 - val_auprc: 0.9812 - val_auroc: 0.9889 - val_recall: 0.9666 - val_precision: 0.9306 - val_accuracy: 0.9558\n",
      "Epoch 22/1000\n",
      "14383/14383 [==============================] - 105s 7ms/step - loss: 0.1173 - auprc: 0.9841 - auroc: 0.9901 - recall: 0.9512 - precision: 0.9495 - accuracy: 0.9583 - val_loss: 0.1436 - val_auprc: 0.9811 - val_auroc: 0.9888 - val_recall: 0.9670 - val_precision: 0.9297 - val_accuracy: 0.9555\n",
      "Epoch 23/1000\n",
      "14383/14383 [==============================] - 105s 7ms/step - loss: 0.1172 - auprc: 0.9841 - auroc: 0.9901 - recall: 0.9513 - precision: 0.9494 - accuracy: 0.9584 - val_loss: 0.1406 - val_auprc: 0.9813 - val_auroc: 0.9889 - val_recall: 0.9672 - val_precision: 0.9299 - val_accuracy: 0.9557\n",
      "Epoch 24/1000\n",
      "14383/14383 [==============================] - 106s 7ms/step - loss: 0.1172 - auprc: 0.9841 - auroc: 0.9902 - recall: 0.9515 - precision: 0.9493 - accuracy: 0.9584 - val_loss: 0.1416 - val_auprc: 0.9813 - val_auroc: 0.9889 - val_recall: 0.9664 - val_precision: 0.9309 - val_accuracy: 0.9558\n",
      "Epoch 25/1000\n",
      "14383/14383 [==============================] - 106s 7ms/step - loss: 0.1172 - auprc: 0.9842 - auroc: 0.9902 - recall: 0.9515 - precision: 0.9493 - accuracy: 0.9584 - val_loss: 0.1422 - val_auprc: 0.9813 - val_auroc: 0.9889 - val_recall: 0.9663 - val_precision: 0.9313 - val_accuracy: 0.9560\n",
      "Epoch 26/1000\n",
      "14383/14383 [==============================] - 104s 7ms/step - loss: 0.1171 - auprc: 0.9842 - auroc: 0.9902 - recall: 0.9515 - precision: 0.9494 - accuracy: 0.9584 - val_loss: 0.1419 - val_auprc: 0.9810 - val_auroc: 0.9888 - val_recall: 0.9669 - val_precision: 0.9305 - val_accuracy: 0.9559\n",
      "Epoch 27/1000\n",
      "14383/14383 [==============================] - 106s 7ms/step - loss: 0.1171 - auprc: 0.9842 - auroc: 0.9902 - recall: 0.9515 - precision: 0.9493 - accuracy: 0.9584 - val_loss: 0.1412 - val_auprc: 0.9810 - val_auroc: 0.9888 - val_recall: 0.9661 - val_precision: 0.9314 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "14383/14383 [==============================] - 103s 7ms/step - loss: 0.1171 - auprc: 0.9842 - auroc: 0.9902 - recall: 0.9514 - precision: 0.9494 - accuracy: 0.9584 - val_loss: 0.1416 - val_auprc: 0.9810 - val_auroc: 0.9888 - val_recall: 0.9659 - val_precision: 0.9315 - val_accuracy: 0.9560\n",
      "Epoch 29/1000\n",
      "14383/14383 [==============================] - 102s 7ms/step - loss: 0.1171 - auprc: 0.9842 - auroc: 0.9902 - recall: 0.9515 - precision: 0.9494 - accuracy: 0.9584 - val_loss: 0.1458 - val_auprc: 0.9811 - val_auroc: 0.9889 - val_recall: 0.9674 - val_precision: 0.9295 - val_accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "histories = {}\n",
    "strategy = MirroredStrategy()\n",
    "os.makedirs(\"classical_link_prediction\", exist_ok=True)\n",
    "\n",
    "for embedding_model, method, train, valid in task_generator(pos_training, pos_validation, neg_training, neg_validation):\n",
    "    history_path = f\"classical_link_prediction/{embedding_model}_{method}.csv\"\n",
    "    if os.path.exists(history_path):\n",
    "        histories[(embedding_model, method)] = pd.read_csv(history_path)\n",
    "        continue\n",
    "    with strategy.scope():\n",
    "        model = build_link_prediction_model(train[0].shape[1:])\n",
    "    history = pd.DataFrame(model.fit(\n",
    "        *train,\n",
    "        batch_size=2**12,\n",
    "        validation_data=valid,\n",
    "        epochs=1000,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\"val_loss\", patience=20, min_delta=0.0001),\n",
    "            ReduceLROnPlateau()\n",
    "        ]\n",
    "    ).history)\n",
    "\n",
    "    history.to_csv(history_path, index=False)\n",
    "    histories[(embedding_model, method)] = history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all the computer histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plot_keras_history import plot_history\n",
    "\n",
    "for history in histories.values():\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying results of various embedding methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we covert the histories into an homogeneous report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitize_ml_labels import sanitize_ml_labels\n",
    "\n",
    "report = []\n",
    "for (model, method), history in histories.items():\n",
    "    last_epoch = history.iloc[-1].to_dict()\n",
    "    sanitize = {\n",
    "        sanitize_ml_labels(label):value\n",
    "        for label, value in last_epoch.items()\n",
    "        if label not in (\"lr\")\n",
    "    }\n",
    "    training = {\n",
    "        key:val\n",
    "        for key, val in sanitize.items()\n",
    "        if \"Val\" not in key\n",
    "    }\n",
    "    validation = {\n",
    "        sanitize_ml_labels(key.replace(\"Val \", \"\")):val\n",
    "        for key, val in sanitize.items()\n",
    "        if \"Val\" in key\n",
    "    }\n",
    "\n",
    "    report.append({\n",
    "        \"run\":\"training\",\n",
    "        \"embedding_model\":model,\n",
    "        \"model\":\"MLP\",\n",
    "        \"method\":method,\n",
    "        **training\n",
    "    })\n",
    "    report.append({\n",
    "        \"run\":\"validation\",\n",
    "        \"embedding_model\":model,\n",
    "        \"model\":\"MLP\",\n",
    "        \"method\":method,\n",
    "        **validation\n",
    "    })\n",
    "\n",
    "report = pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training link prediction on some other models\n",
    "Here we execute the link prediction using Random Forests, Decision Trees and Logistic Regression so to have a good comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sanitize_ml_labels import sanitize_ml_labels\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "kwargs = {\n",
    "    \"DecisionTreeClassifier\":dict(\n",
    "        max_depth=30,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"RandomForestClassifier\":dict(\n",
    "        n_estimators=500,\n",
    "        max_depth=30,\n",
    "        n_jobs=cpu_count(),\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LogisticRegression\":dict(\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "}\n",
    "\n",
    "def metric_report(y_true, y_pred):\n",
    "    metrics = (\n",
    "        roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "    )\n",
    "    return {\n",
    "        sanitize_ml_labels(metric.__name__):metric(y_true, y_pred)\n",
    "        for metric in metrics\n",
    "    }\n",
    "\n",
    "metrics_reports_path = \"classical_link_prediction/linear_models_reports.csv\"\n",
    "if os.path.exists(metrics_reports_path):\n",
    "    metrics_reports = pd.read_csv(metrics_reports_path)\n",
    "else:\n",
    "    metrics_reports = []\n",
    "\n",
    "    for embedding_model, method, train, valid in task_generator(pos_training, pos_validation, neg_training, neg_validation):\n",
    "        for model_builder in tqdm((DecisionTreeClassifier, RandomForestClassifier, LogisticRegression), desc=\"Model\", leave=False):\n",
    "            model = model_builder(**kwargs[model_builder.__name__])\n",
    "            train_x, train_y = train\n",
    "            valid_x, valid_y = valid\n",
    "            model.fit(train_x, train_y)\n",
    "            train_y_pred = model.predict(train_x)\n",
    "            valid_y_pred = model.predict(valid_x)\n",
    "            metrics_reports.append({\n",
    "                \"run\":\"training\",\n",
    "                \"embedding_model\":embedding_model,\n",
    "                \"model\":model_builder.__name__,\n",
    "                \"method\":method,\n",
    "                **metric_report(train_y, train_y_pred)\n",
    "            })\n",
    "            metrics_reports.append({\n",
    "                \"run\":\"validation\",\n",
    "                \"embedding_model\":embedding_model,\n",
    "                \"model\":model_builder.__name__,\n",
    "                \"method\":method,\n",
    "                **metric_report(valid_y, valid_y_pred)\n",
    "            })\n",
    "\n",
    "    metrics_reports = pd.DataFrame(metrics_reports)\n",
    "    metrics_reports.to_csv(metrics_reports_path, index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reports = pd.concat([\n",
    "    metrics_reports,\n",
    "    report\n",
    "])\n",
    "\n",
    "all_reports.to_csv(\"classical_link_prediction/all_reports.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from barplots import barplots\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# show_standard_deviation is False because there is only one holdout!\n",
    "barplots(\n",
    "    all_reports,\n",
    "    [\"run\", \"method\", \"embedding_model\", \"model\"],\n",
    "    path = 'barplots/{feature}.jpg',\n",
    "    show_standard_deviation=False,\n",
    "    height=5,\n",
    "    subplots=True,\n",
    "    plots_per_row=1\n",
    ")\n",
    "\n",
    "for barplot_path in glob(\"barplots/*\"):\n",
    "    display(Image.open(barplot_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "scored_per_method = [\n",
    "    (group, x[\"AUPRC\"].values)\n",
    "    for group, x in list(all_reports[[\"AUPRC\", \"method\"]].groupby(\"method\"))\n",
    "]\n",
    "\n",
    "for i, (method1, scores1) in enumerate(scored_per_method):\n",
    "    for method2, scores2 in scored_per_method[i+1:]:\n",
    "        print(\n",
    "            method1, method2, wilcoxon(scores1, scores2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
