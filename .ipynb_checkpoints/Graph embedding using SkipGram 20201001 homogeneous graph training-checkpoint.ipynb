{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embedding using SkipGram\n",
    "\n",
    "This is an embedding of the whole graph, no training and validation split and all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto # Import needed to avoid TensorFlow warnings and general useless infos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"98_2 training_test_epoch_500_delta_0.0001\"\n",
    "graph_data_dir = \"graph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the graphs\n",
    "We load the ppi graph from the repository as an undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "os.makedirs(graph_data_dir, exist_ok=True)\n",
    "if not os.path.exists(graph_data_dir + \"/kg-covid-19-skipgram-aug-2020.tar.gz\"):\n",
    "    with urllib.request.urlopen(\"https://zenodo.org/record/4011267/files/kg-covid-19-skipgram-aug-2020.tar.gz\") as response, \\\n",
    "        open(graph_data_dir + \"/kg-covid-19-skipgram-aug-2020.tar.gz\", 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"tar -xvzf \" + graph_data_dir + \"/kg-covid-19-skipgram-aug-2020.tar.gz -C \" + graph_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 8.18 s, total: 2min 4s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "graph = EnsmallenGraph.from_csv(\n",
    "    edge_path = graph_data_dir + \"/merged-kg_edges.tsv\",\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    node_path = graph_data_dir + \"/merged-kg_nodes.tsv\",\n",
    "    nodes_column = 'id',\n",
    "    node_types_column = 'category',\n",
    "    default_node_type = 'biolink:NamedThing'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first thing, we print a short report showing all the avalable graph details, including the number of edges, nodes, trap nodes and both the connected components and the strongly connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unique_node_types_number': '36',\n",
       " 'selfloops_rate': '0.000015391581103247148',\n",
       " 'is_multigraph': 'false',\n",
       " 'mean_number_of_types_for_edge': '0',\n",
       " 'edges_number': '30861027',\n",
       " 'multigraph_edges_ratio': '0',\n",
       " 'traps_rate': '0.021906677500566116',\n",
       " 'selfloops_number': '475',\n",
       " 'degrees_mean': '82.21604837957722',\n",
       " 'singleton_nodes': '8223',\n",
       " 'degrees_median': '6',\n",
       " 'degrees_min': '0',\n",
       " 'nodes_number': '375365',\n",
       " 'bidirectional_rate': '1',\n",
       " 'connected_components_number': '8976',\n",
       " 'strongly_connected_components_number': '8976',\n",
       " 'multigraph_edges_number': '0',\n",
       " 'degrees_mode': '1',\n",
       " 'degrees_max': '90378',\n",
       " 'is_directed': 'false',\n",
       " 'unique_edge_types_number': '0',\n",
       " 'density': '0.00021902960686152735'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings are check that are not necessary, but are offered as sanity checks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considered parameters\n",
    "We are going to use the following parameters:\n",
    "\n",
    "- **Walk lengths:** $100$ nodes.\n",
    "- **Batch size:** $2^{7} = 128$ walks per batch.\n",
    "- **Walk iterations:** $20$ iterations on the graph.\n",
    "- **Window size:** $4$ nodes, meaning $4$ on the left and $4$ on the right of the center nodes. Consider that the first *window_size* values on the left and the right of the walks will be trimmed.\n",
    "- **Return weight, inverse of $p$:** $1.0$.\n",
    "- **Explore weight, inverse of $q$:** $1.0$.\n",
    "- **Embedding size:** $100$.\n",
    "- **Negative samples:** For the porpose of the [NCE function negative samples](https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss), we are going to use $10$. These are the number of negative classes to randomly sample per batch. This single sample of negative classes is evaluated for each element in the batch.\n",
    "- **Optimizer:** [Nadam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam).\n",
    "- **Early stopping parameters:** We are going to use an Early Stopping criterion on the *validation loss*, with patience $5$ and delta $0.0001$.\n",
    "- **Epochs:** The model will be trained up to $1000$ epochs.\n",
    "- **Learning rate:** default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation = graph.connected_holdout(0.97626, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'connected_components_number': '85456',\n",
       " 'nodes_number': '375365',\n",
       " 'mean_number_of_types_for_edge': '0',\n",
       " 'bidirectional_rate': '1',\n",
       " 'multigraph_edges_ratio': '0',\n",
       " 'multigraph_edges_number': '0',\n",
       " 'is_multigraph': 'false',\n",
       " 'traps_rate': '0.22393403753679753',\n",
       " 'degrees_min': '0',\n",
       " 'degrees_mean': '80.26424147163428',\n",
       " 'density': '0.00021382984953747492',\n",
       " 'selfloops_number': '475',\n",
       " 'strongly_connected_components_number': '85456',\n",
       " 'singleton_nodes': '84057',\n",
       " 'unique_edge_types_number': '0',\n",
       " 'degrees_max': '90342',\n",
       " 'unique_node_types_number': '36',\n",
       " 'is_directed': 'false',\n",
       " 'degrees_median': '5',\n",
       " 'degrees_mode': '0',\n",
       " 'edges_number': '30128387',\n",
       " 'selfloops_rate': '0.000015765862274671392'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degrees_median': '1',\n",
       " 'bidirectional_rate': '1',\n",
       " 'degrees_mode': '1',\n",
       " 'singleton_nodes': '8312',\n",
       " 'unique_edge_types_number': '0',\n",
       " 'density': '0.000005199757324052417',\n",
       " 'degrees_min': '0',\n",
       " 'mean_number_of_types_for_edge': '0',\n",
       " 'unique_node_types_number': '36',\n",
       " 'multigraph_edges_ratio': '0',\n",
       " 'traps_rate': '0.022143780054080693',\n",
       " 'selfloops_number': '0',\n",
       " 'nodes_number': '375365',\n",
       " 'selfloops_rate': '0',\n",
       " 'degrees_max': '13829',\n",
       " 'is_directed': 'false',\n",
       " 'connected_components_number': '9045',\n",
       " 'strongly_connected_components_number': '9045',\n",
       " 'degrees_mean': '1.9518069079429354',\n",
       " 'is_multigraph': 'false',\n",
       " 'edges_number': '732640',\n",
       " 'multigraph_edges_number': '0'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert graph > training\n",
    "assert graph > validation\n",
    "assert (training + validation).contains(graph)  # this + will eventually fail, replace with | to fix\n",
    "assert graph.contains(training + validation)  # this + will eventually fail, replace with | to fix\n",
    "assert not training.overlaps(validation)\n",
    "assert not validation.overlaps(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length=100\n",
    "batch_size=2**9\n",
    "iterations=20\n",
    "window_size=4\n",
    "p=1.0\n",
    "q=1.0\n",
    "embedding_size=100\n",
    "negatives_samples=30\n",
    "patience=5\n",
    "delta=0.0001\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the training and validation Keras sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the SkipGram model\n",
    "We are going to setup the model to use, if available, multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen import Node2VecSequence\n",
    "\n",
    "training_sequence = Node2VecSequence(\n",
    "    training,\n",
    "    walk_length=walk_length,\n",
    "    batch_size=batch_size,\n",
    "    iterations=iterations,\n",
    "    window_size=window_size,\n",
    "    return_weight=1/p,\n",
    "    explore_weight=1/q\n",
    ")\n",
    "\n",
    "validation_sequence = Node2VecSequence(\n",
    "    graph, # Here we use the entire graph. This will only be used for the early stopping.\n",
    "    walk_length=walk_length,\n",
    "    batch_size=batch_size,\n",
    "    iterations=iterations,\n",
    "    window_size=window_size,\n",
    "    return_weight=1/p,\n",
    "    explore_weight=1/q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SkipGram\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_embedding (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 100)       37536500    words_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100)          0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise_contrastive_estimation (N (None, 375365)       37911865    flatten[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 75,448,365\n",
      "Trainable params: 75,448,365\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from embiggen import SkipGram\n",
    "\n",
    "# strategy = MirroredStrategy()\n",
    "#with strategy.scope():\n",
    "model = SkipGram(\n",
    "    vocabulary_size=training.get_nodes_number(),\n",
    "    embedding_size=embedding_size,\n",
    "    window_size=window_size,\n",
    "    negatives_samples=negatives_samples,\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the SkipGram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "569/569 [==============================] - 1067s 2s/step - loss: 186.4717 - val_loss: 201.8976\n",
      "Epoch 2/500\n",
      "569/569 [==============================] - 1063s 2s/step - loss: 134.8705 - val_loss: 190.6003\n",
      "Epoch 3/500\n",
      "569/569 [==============================] - 1063s 2s/step - loss: 121.4650 - val_loss: 185.4298\n",
      "Epoch 4/500\n",
      "569/569 [==============================] - 1056s 2s/step - loss: 111.9199 - val_loss: 180.6608\n",
      "Epoch 5/500\n",
      "569/569 [==============================] - 1063s 2s/step - loss: 105.0344 - val_loss: 177.3538\n",
      "Epoch 6/500\n",
      "569/569 [==============================] - 1064s 2s/step - loss: 99.3354 - val_loss: 171.9322\n",
      "Epoch 7/500\n",
      "569/569 [==============================] - 1058s 2s/step - loss: 94.6407 - val_loss: 169.0677\n",
      "Epoch 8/500\n",
      "569/569 [==============================] - 1062s 2s/step - loss: 89.2208 - val_loss: 166.9772\n",
      "Epoch 9/500\n",
      "569/569 [==============================] - 1051s 2s/step - loss: 84.6479 - val_loss: 165.3797\n",
      "Epoch 10/500\n",
      "569/569 [==============================] - 1071s 2s/step - loss: 81.1030 - val_loss: 163.2846\n",
      "Epoch 11/500\n",
      "569/569 [==============================] - 1126s 2s/step - loss: 77.6284 - val_loss: 160.3102\n",
      "Epoch 12/500\n",
      "569/569 [==============================] - 1130s 2s/step - loss: 75.7098 - val_loss: 158.5877\n",
      "Epoch 13/500\n",
      "569/569 [==============================] - 1131s 2s/step - loss: 73.4751 - val_loss: 156.5117\n",
      "Epoch 14/500\n",
      "569/569 [==============================] - 1112s 2s/step - loss: 69.7943 - val_loss: 153.9442\n",
      "Epoch 15/500\n",
      "569/569 [==============================] - 1071s 2s/step - loss: 67.8079 - val_loss: 153.7208\n",
      "Epoch 16/500\n",
      "569/569 [==============================] - 1079s 2s/step - loss: 67.8569 - val_loss: 152.7731\n",
      "Epoch 17/500\n",
      "569/569 [==============================] - 1067s 2s/step - loss: 63.8182 - val_loss: 151.4749\n",
      "Epoch 18/500\n",
      "569/569 [==============================] - 1068s 2s/step - loss: 62.6232 - val_loss: 149.5766\n",
      "Epoch 19/500\n",
      "569/569 [==============================] - 1065s 2s/step - loss: 59.6160 - val_loss: 148.5574\n",
      "Epoch 20/500\n",
      "569/569 [==============================] - 1076s 2s/step - loss: 59.4998 - val_loss: 147.6992\n",
      "Epoch 21/500\n",
      "569/569 [==============================] - 1073s 2s/step - loss: 58.0603 - val_loss: 147.1906\n",
      "Epoch 22/500\n",
      "569/569 [==============================] - 1074s 2s/step - loss: 59.3478 - val_loss: 145.7990\n",
      "Epoch 23/500\n",
      "569/569 [==============================] - 1070s 2s/step - loss: 56.0907 - val_loss: 143.5676\n",
      "Epoch 24/500\n",
      "569/569 [==============================] - 1061s 2s/step - loss: 54.2620 - val_loss: 144.0740\n",
      "Epoch 25/500\n",
      "569/569 [==============================] - 1067s 2s/step - loss: 56.1458 - val_loss: 143.5699\n",
      "Epoch 26/500\n",
      "569/569 [==============================] - 1076s 2s/step - loss: 51.3974 - val_loss: 141.9422\n",
      "Epoch 27/500\n",
      "569/569 [==============================] - 1077s 2s/step - loss: 50.9470 - val_loss: 143.2130\n",
      "Epoch 28/500\n",
      "569/569 [==============================] - 1075s 2s/step - loss: 51.8272 - val_loss: 142.2802\n",
      "Epoch 29/500\n",
      "569/569 [==============================] - 1081s 2s/step - loss: 49.8179 - val_loss: 140.5015\n",
      "Epoch 30/500\n",
      "569/569 [==============================] - 1078s 2s/step - loss: 49.7081 - val_loss: 139.1748\n",
      "Epoch 31/500\n",
      "569/569 [==============================] - 1074s 2s/step - loss: 49.7781 - val_loss: 139.6105\n",
      "Epoch 32/500\n",
      "569/569 [==============================] - 1074s 2s/step - loss: 48.9805 - val_loss: 139.1150\n",
      "Epoch 33/500\n",
      "569/569 [==============================] - 1073s 2s/step - loss: 48.3746 - val_loss: 138.0111\n",
      "Epoch 34/500\n",
      "569/569 [==============================] - 1071s 2s/step - loss: 45.3371 - val_loss: 136.8562\n",
      "Epoch 35/500\n",
      "569/569 [==============================] - 1068s 2s/step - loss: 45.6184 - val_loss: 136.9223\n",
      "Epoch 36/500\n",
      "569/569 [==============================] - 1071s 2s/step - loss: 45.6551 - val_loss: 135.8149\n",
      "Epoch 37/500\n",
      "569/569 [==============================] - 1062s 2s/step - loss: 45.5472 - val_loss: 136.0983\n",
      "Epoch 38/500\n",
      "569/569 [==============================] - 1071s 2s/step - loss: 45.8087 - val_loss: 134.6466\n",
      "Epoch 39/500\n",
      " 50/569 [=>............................] - ETA: 9:38 - loss: 45.8378"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "history = model.fit(\n",
    "    training_sequence,\n",
    "    steps_per_epoch=training_sequence.steps_per_epoch,\n",
    "    validation_data=validation_sequence,\n",
    "    validation_steps=validation_sequence.steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            \"val_loss\",\n",
    "            min_delta=delta,\n",
    "            patience=patience,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the model weights\n",
    "# We save the obtained model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"{model.name}_\" + exp_name + \"_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the training history\n",
    "We can visualize the performance of the model during the training process as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_keras_history import plot_history\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some hiccups in the plot of the history if the model is reloaded from stored weights: [this is a known Keras issue](https://github.com/keras-team/keras/issues/4875) and is not related to either the holdouts used or the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the obtained embeddings\n",
    "Finally we save our hard earned model embeddings. In another notebook we will show how to do link prediction on the obtained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(f\"{model.name}_\" + exp_name + \"_embedding.npy\", model.embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
