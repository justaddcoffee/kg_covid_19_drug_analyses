{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embedding using SkipGram\n",
    "\n",
    "This is an embedding of the whole graph, 80/20 training and validation split and all sources\n",
    "\n",
    "kg-covid-19:\n",
    "version 20201012\n",
    "\n",
    "Name: ensmallen-graph\n",
    "Version: 0.4.4\n",
    "\n",
    "Name: embiggen\n",
    "Version: 0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg_resources import get_distribution\n",
    "assert(get_distribution(\"ensmallen-graph\").version == '0.4.4')  # identical to 0.4.3 except for addition of some methods like get_edge_id()\n",
    "assert(get_distribution(\"embiggen\").version == '0.6.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "exp_name = \"80_20_kg_covid_19_20201012_training_test_epoch_500_delta_0.0001_updated_holdouts\"\n",
    "s3_path = \"s3://kg-hub-public-data/embeddings/20201012/\"  # keep trailing slash\n",
    "\n",
    "base_dl_dir = \"downloaded_data\"\n",
    "graph_data_dir = os.path.join(base_dl_dir, \"kg-covid-19-20201012\")\n",
    "embedding_data_dir = os.path.join(base_dl_dir, \"embeddings-20201012\")\n",
    "\n",
    "# graph stuff\n",
    "graph_out_file = os.path.join(graph_data_dir + \"/kg-covid-19.tar.gz\")\n",
    "nodes_file = os.path.join(graph_data_dir, \"merged-kg_nodes.tsv\")\n",
    "edges_file = os.path.join(graph_data_dir, \"merged-kg_edges.tsv\")\n",
    "sorted_edges_file = os.path.join(graph_data_dir, \"merged-kg_edges_SORTED.tsv\")\n",
    "graph_tar_url = \"https://kg-hub.berkeleybop.io/kg-covid-19/20201012/kg-covid-19.tar.gz\"\n",
    "\n",
    "# embeddings URLs\n",
    "base_kghub_url = \"http://kg-hub.berkeleybop.io/\"\n",
    "embeddings_url = os.path.join(base_kghub_url, \"embeddings/20201012/SkipGram_80_20_kg_covid_19_20201012_training_test_epoch_500_delta_0.0001_embedding.npy\")\n",
    "embedding_file = os.path.join(embedding_data_dir, \"SkipGram_embedding.npy\")\n",
    "\n",
    "# params\n",
    "seed = 42\n",
    "train_percentage = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto # Import needed to avoid TensorFlow warnings and general useless infos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the graphs\n",
    "We load the kg-covid-19 graph from the repository as an undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the graphs, if necessary\n",
    "\n",
    "import urllib\n",
    "import os\n",
    "os.makedirs(graph_data_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(nodes_file) or not os.path.exists(edges_file):\n",
    "    with urllib.request.urlopen(graph_tar_url) as response, \\\n",
    "        open(graph_out_file, 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)\n",
    "    os.system(\"tar -xvzf \" + graph_out_file + \" -C \" + graph_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only need to do this once, b/c we'll load the sorted.tsv from now on once it is made below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtr4v/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (0,9,10,11,12,13,14,15,16,17,18,21,22,24,25,26,29,30,31,32,33,34,37,41,43,45,48) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "edges = pd.read_csv(graph_data_dir + \"/merged-kg_edges.tsv\", \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_cov_2_curie = 'NCBITaxon:2697049'\n",
    "chembl_prefix = 'CHEMBL.COMPOUND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_to_sars_cov_2_edges = (\n",
    "    (edges.subject.str.contains(chembl_prefix) & (edges.object == sars_cov_2_curie)) | \n",
    "    (edges.object.str.contains(chembl_prefix) & (edges.subject == sars_cov_2_curie))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges['holdout_edge_label'] = [\n",
    "    'chembl_to_sars_cov_2' if value else 'normal'\n",
    "    for value in chembl_to_sars_cov_2_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "new_edge_file = os.path.join(graph_data_dir, 'edges_with_holdout_column.tsv')\n",
    "edges.to_csv(new_edge_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensmallen_graph import EnsmallenGraph\n",
    "graph = EnsmallenGraph.from_unsorted_csv(\n",
    "    name=\"kg-covid-19\",\n",
    "    edge_path = new_edge_file,\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    edge_types_column='holdout_edge_label',\n",
    "    directed=False,\n",
    "    node_path = graph_data_dir + \"/merged-kg_nodes.tsv\",\n",
    "    nodes_column = 'id',\n",
    "    node_types_column = 'category',\n",
    "    default_node_type = 'biolink:NamedThing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The undirected graph kg-covid-19 has 447766 nodes with 42 different node types:  the 5 most common are biolink:Publication (nodes number 129930), biolink:OntologyClass (nodes number 108266), biolink:Drug (nodes number 32120), biolink:ChemicalSubstance (nodes number 27157) and biolink:Disease (nodes number 24236), of which 8355 are singletons, and 15611957 unweighted edges with 2 different edge types: normal and chembl_to_sars_cov_2, of which 480 are self-loops. The graph is quite sparse as it has a density of 0.00016 and has 9107 connected components, where the component with most nodes has 435728 nodes and the component with the least nodes has 1 nodes. The graph median node degree is 4, the mean node degree is 69.73 and the node degree mode is 1. The top 5 most central nodes are MESH:D014780 (degree 90378), MESH:D006801 (degree 78249), WD:Q30 (degree 65223), MESH:D014777 (degree 54155) and MESH:D017934 (degree 45196)."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_graph = graph.remove_components(edge_types=['chembl_to_sars_cov_2'])\n",
    "reduced_graph = reduced_graph.remove(singletons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The undirected graph kg-covid-19 has 435728 nodes with 40 different node types:  the 5 most common are biolink:Publication (nodes number 129492), biolink:OntologyClass (nodes number 104951), biolink:Drug (nodes number 32016), biolink:ChemicalSubstance (nodes number 27152) and biolink:Disease (nodes number 22281) and 15608444 unweighted edges with 2 different edge types: normal and chembl_to_sars_cov_2, of which 314 are self-loops. The graph is quite sparse as it has a density of 0.00016 and is connected, as it has a single component. The graph median node degree is 4, the mean node degree is 71.64 and the node degree mode is 1. The top 5 most central nodes are MESH:D014780 (degree 90378), MESH:D006801 (degree 78249), WD:Q30 (degree 65223), MESH:D014777 (degree 54155) and MESH:D017934 (degree 45196)."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the SkipGram model\n",
    "We are going to setup the model to use, if available, multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cache_decorator import Cache\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from embiggen import SkipGram\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from embiggen import Node2VecSequence\n",
    "\n",
    "\n",
    "@Cache(\n",
    "    cache_path=\"{cache_dir}/SkipGram/{_hash}_{holdout_idx}.csv.gz\",\n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=['train_graph']\n",
    ")\n",
    "def compute_skipgram_embedding(\n",
    "    train_graph: EnsmallenGraph,\n",
    "    holdout_idx: int,\n",
    "    walk_length: int = 100,\n",
    "    batch_size: int = 2**9,\n",
    "    iterations: int = 20,\n",
    "    return_weight: float = 1.0,\n",
    "    explore_weight: float = 1.0,\n",
    "    embedding_size: int = 100,\n",
    "    window_size: int = 4,\n",
    "    negative_samples: int = 7,\n",
    "    patience: int = 6,\n",
    "    delta: float = 0.1,\n",
    "    epochs: int = 500\n",
    "):\n",
    "    \"\"\"Return dataframe with node embedding obtained with SkipGram for train_graph\n",
    "    \n",
    "    Given a graph, learn embeddings and return dataframe with node embeddings\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    train_graph: EnsmallenGraph\n",
    "    holdout_idx: int, \n",
    "        an int to identify the holdout\n",
    "    walk_length: int = 100,\n",
    "        how many nodes for each walk\n",
    "    batch_size: int = 2**9,\n",
    "        how many walks for each batch\n",
    "    iterations: int = 20,\n",
    "        how many walks per node\n",
    "    return_weight: float = 1.0,\n",
    "        node2vec param, equal to 1/p\n",
    "    explore_weight: float = 1.0,\n",
    "        node2vec param, equal to 1/q\n",
    "    embedding_size: int = 100,\n",
    "        dimensions for embedding\n",
    "    window_size: int = 4,\n",
    "        SkipGram window size\n",
    "    negative_samples: int = 7,\n",
    "        how many negative samples that NCE function needs to sample\n",
    "    patience: int = 6,\n",
    "        how many epochs to wait for loss fxn to improve by [delta]\n",
    "    delta: float = 0.1\n",
    "        change in loss fxn to be considered an improvement\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pd.DataFrame containing an embedding for each node in train_graph\n",
    "    \"\"\"\n",
    "    training_sequence = Node2VecSequence(\n",
    "        train_graph,\n",
    "        walk_length=walk_length,\n",
    "        batch_size=batch_size,\n",
    "        iterations=iterations,\n",
    "        window_size=window_size,\n",
    "        return_weight=return_weight,\n",
    "        explore_weight=explore_weight,\n",
    "        support_mirror_strategy=True\n",
    "    )\n",
    "\n",
    "    strategy = MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = SkipGram(\n",
    "            vocabulary_size=train_graph.get_nodes_number(),\n",
    "            embedding_size=embedding_size,\n",
    "            window_size=window_size,\n",
    "            negative_samples=negative_samples,\n",
    "        )\n",
    "\n",
    "    history = model.fit(\n",
    "        training_sequence,\n",
    "        steps_per_epoch=training_sequence.steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                \"loss\",\n",
    "                min_delta=delta,\n",
    "                patience=patience,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor=\"loss\",\n",
    "                patience=patience//2,\n",
    "                min_delta=delta\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return model.get_embedding_dataframe(train_graph.get_nodes_reverse_mapping())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def create_ranking(edges: List[Tuple[str, str]], predictions: np.ndarray) -> Dict:\n",
    "    \"\"\"Return ranking of edges and predictions.\n",
    "\n",
    "    Parameters\n",
    "    ---------------------\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edges to be predicted.\n",
    "    predictions: np.ndarray,\n",
    "        Predictions of the model.\n",
    "\n",
    "    Returns\n",
    "    ---------------------\n",
    "    Dictionary of the ranking.\n",
    "    \"\"\"\n",
    "    return dict(zip(edges, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import AUC, Recall, Precision\n",
    "from typing import Dict\n",
    "\n",
    "@Cache(    \n",
    "    cache_path=\"model_predictions/mlp/{embedding_model}/{holdout}_{_hash}.pkl.gz\",\n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\", \"batch_size\"]\n",
    ")\n",
    "def mlp(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,    \n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]],\n",
    "    epochs: int = 500,\n",
    "    batch_size: int = 256,\n",
    "    patience: int = 10,\n",
    "    min_delta: float = 0.000001,\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"Return random forest predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(train_X.shape[1:]),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\",\n",
    "              activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"nadam\",\n",
    "        metrics=[\n",
    "            AUC(curve=\"PR\", name=\"auprc\"),\n",
    "            AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "            Recall(name=\"Recall\"),\n",
    "            Precision(name=\"Precision\"),            \n",
    "            \"accuracy\"\n",
    "        ]\n",
    "    )\n",
    "    model.fit(\n",
    "        train_X, train_y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\"loss\", patience=patience, min_delta=min_delta)\n",
    "        ]\n",
    "    )\n",
    "    train_pred = model.predict(train_X)\n",
    "    test_pred = model.predict(test_X)\n",
    "    return train_pred, test_pred, create_ranking(\n",
    "        edges, model.predict(graph_test_X)\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Submodule offering method to execute cached random forest.\"\"\"\n",
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from multiprocessing import cpu_count\n",
    "from cache_decorator import Cache\n",
    "\n",
    "@Cache(    \n",
    "    cache_path=\"model_predictions/random_forest/{embedding_model}/{holdout}_{_hash}.pkl.gz\",\n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\"]\n",
    ")\n",
    "def random_forest(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,\n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]]\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"Return random forest predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    edge_embedding_method: str,\n",
    "        Name of the edge embedding model.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=10,\n",
    "        n_jobs=cpu_count(),\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        max_samples=0.5\n",
    "    )\n",
    "    model.fit(train_X, train_y)\n",
    "    train_pred = model.predict_proba(train_X)[:, 1]\n",
    "    test_pred = model.predict_proba(test_X)[:, 1]\n",
    "    return train_pred, test_pred, create_ranking(edges, model.predict_proba(graph_test_X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from cache_decorator import Cache\n",
    "\n",
    "@Cache(\n",
    "    cache_path=\"{cache_dir}/model_predictions/decision_tree/{embedding_model}/{holdout}_{_hash}.pkl.gz\",    \n",
    "    cache_dir=embedding_data_dir,    \n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\"]\n",
    ")\n",
    "def decision_tree(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,    \n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]]\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"Return decision tree predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    edge_embedding_method: str,\n",
    "        Name of the edge embedding model.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(max_depth=10, class_weight=\"balanced\")\n",
    "    model.fit(train_X, train_y)\n",
    "    train_pred = model.predict_proba(train_X)[:, 1]\n",
    "    test_pred = model.predict_proba(test_X)[:, 1]\n",
    "    return train_pred, test_pred, create_ranking(edges, model.predict_proba(graph_test_X)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from cache_decorator import Cache\n",
    "\n",
    "@Cache(\n",
    "    cache_path=\"{cache_dir}/model_predictions/logistic_regression/{embedding_model}/{holdout}_{_hash}.pkl.gz\",    \n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\"]\n",
    ")\n",
    "def logistic_regression(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,    \n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]]\n",
    ") -> Tuple[np.ndarray, np.ndarray, LogisticRegression]:\n",
    "    \"\"\"Return logistic regression predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    edge_embedding_method: str,\n",
    "        Name of the edge embedding model.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_pred = model.predict_proba(train_X)[:, 1]\n",
    "    test_pred = model.predict_proba(test_X)[:, 1]\n",
    "    return train_pred, test_pred, create_ranking(edges, model.predict_proba(graph_test_X)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_of_interest = ['biolink:Drug', 'biolink:ChemicalSubstance']\n",
    "node_idx = [reduced_graph.get_node_types_reverse_mapping().index(noi) for noi in nodes_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_set = {\n",
    "    reduced_graph.get_node_name(node_id)\n",
    "    for node_id in range(reduced_graph.get_nodes_number())\n",
    "    if reduced_graph.get_node_type(node_id) in node_idx\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_drugs_only = reduced_graph.remove(allow_nodes_set=allow_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, recall_score, precision_score\n",
    "from sanitize_ml_labels import sanitize_ml_labels\n",
    "from typing import Dict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def specificity_score(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn+fp)\n",
    "\n",
    "def get_metrics_report(y_true: np.ndarray, y_pred: np.ndarray)->Dict[str, float]:\n",
    "    float_metrics = (average_precision_score, roc_auc_score)\n",
    "    integer_metrics = (accuracy_score, recall_score, precision_score, specificity_score)\n",
    "    integer_y_pred = y_pred.round().astype(int)\n",
    "\n",
    "    return {\n",
    "        **{\n",
    "            sanitize_ml_labels(metric.__name__): metric(y_true, integer_y_pred)\n",
    "            for metric in integer_metrics\n",
    "        },\n",
    "        **{\n",
    "            sanitize_ml_labels(metric.__name__): metric(y_true, y_pred)\n",
    "            for metric in float_metrics\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32be9e43e734ce5b91185867771923e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='computing embeddings', max=5.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef77a3c258d8491a9fcad81a2f41841a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='edge embeddings', max=4.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='models', max=4.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.2700 - auprc: 0.8614 - auroc: 0.9577 - Recall: 0.8178 - Precision: 0.7980 - accuracy: 0.9351\n",
      "Epoch 2/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0607 - auprc: 0.9759 - auroc: 0.9961 - Recall: 0.9543 - Precision: 0.9306 - accuracy: 0.9805\n",
      "Epoch 3/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0412 - auprc: 0.9873 - auroc: 0.9980 - Recall: 0.9723 - Precision: 0.9495 - accuracy: 0.9868\n",
      "Epoch 4/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0305 - auprc: 0.9923 - auroc: 0.9988 - Recall: 0.9817 - Precision: 0.9640 - accuracy: 0.9908\n",
      "Epoch 5/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0240 - auprc: 0.9950 - auroc: 0.9992 - Recall: 0.9814 - Precision: 0.9751 - accuracy: 0.9927\n",
      "Epoch 6/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0187 - auprc: 0.9967 - auroc: 0.9995 - Recall: 0.9876 - Precision: 0.9793 - accuracy: 0.9945\n",
      "Epoch 7/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0134 - auprc: 0.9975 - auroc: 0.9997 - Recall: 0.9927 - Precision: 0.9863 - accuracy: 0.9965\n",
      "Epoch 8/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0110 - auprc: 0.9990 - auroc: 0.9998 - Recall: 0.9935 - Precision: 0.9893 - accuracy: 0.9971\n",
      "Epoch 9/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0081 - auprc: 0.9993 - auroc: 0.9999 - Recall: 0.9962 - Precision: 0.9928 - accuracy: 0.9982\n",
      "Epoch 10/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0074 - auprc: 0.9995 - auroc: 0.9999 - Recall: 0.9954 - Precision: 0.9947 - accuracy: 0.9984\n",
      "Epoch 11/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0075 - auprc: 0.9995 - auroc: 0.9999 - Recall: 0.9900 - Precision: 0.9966 - accuracy: 0.9978\n",
      "Epoch 12/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0077 - auprc: 0.9996 - auroc: 0.9999 - Recall: 0.9845 - Precision: 0.9972 - accuracy: 0.9970\n",
      "Epoch 13/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0065 - auprc: 0.9996 - auroc: 0.9999 - Recall: 0.9932 - Precision: 0.9965 - accuracy: 0.9983\n",
      "Epoch 14/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0047 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9945 - Precision: 0.9982 - accuracy: 0.9988\n",
      "Epoch 15/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0079 - auprc: 0.9991 - auroc: 0.9997 - Recall: 0.9856 - Precision: 0.9979 - accuracy: 0.9973\n",
      "Epoch 16/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0042 - auprc: 0.9999 - auroc: 0.9999 - Recall: 0.9946 - Precision: 0.9977 - accuracy: 0.9987\n",
      "Epoch 17/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0057 - auprc: 0.9995 - auroc: 0.9998 - Recall: 0.9951 - Precision: 0.9976 - accuracy: 0.9988\n",
      "Epoch 18/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0110 - auprc: 0.9990 - auroc: 0.9998 - Recall: 0.9755 - Precision: 0.9968 - accuracy: 0.9954\n",
      "Epoch 19/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0050 - auprc: 0.9999 - auroc: 0.9999 - Recall: 0.9907 - Precision: 0.9979 - accuracy: 0.9981\n",
      "Epoch 20/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0033 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9957 - Precision: 0.9990 - accuracy: 0.9991\n",
      "Epoch 21/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0038 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9957 - Precision: 0.9980 - accuracy: 0.9989\n",
      "Epoch 22/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0059 - auprc: 0.9995 - auroc: 0.9999 - Recall: 0.9959 - Precision: 0.9966 - accuracy: 0.9987\n",
      "Epoch 23/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0050 - auprc: 0.9997 - auroc: 1.0000 - Recall: 0.9956 - Precision: 0.9968 - accuracy: 0.9987\n",
      "Epoch 24/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0031 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9968 - Precision: 0.9986 - accuracy: 0.9992\n",
      "Epoch 25/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0027 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9957 - Precision: 0.9992 - accuracy: 0.9991\n",
      "Epoch 26/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0038 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9941 - Precision: 0.9984 - accuracy: 0.9987\n",
      "Epoch 27/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0023 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9970 - Precision: 0.9995 - accuracy: 0.9994\n",
      "Epoch 28/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0030 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9978 - Precision: 0.9981 - accuracy: 0.9993\n",
      "Epoch 29/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0050 - auprc: 0.9994 - auroc: 0.9999 - Recall: 0.9942 - Precision: 0.9974 - accuracy: 0.9986\n",
      "Epoch 30/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0065 - auprc: 0.9996 - auroc: 0.9998 - Recall: 0.9866 - Precision: 0.9984 - accuracy: 0.9975\n",
      "Epoch 31/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0027 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9947 - Precision: 0.9995 - accuracy: 0.9990\n",
      "Epoch 32/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0027 - auprc: 0.9996 - auroc: 0.9999 - Recall: 0.9971 - Precision: 0.9992 - accuracy: 0.9994\n",
      "Epoch 33/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0023 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9973 - Precision: 0.9992 - accuracy: 0.9994\n",
      "Epoch 34/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0016 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9990 - Precision: 0.9996 - accuracy: 0.9998\n",
      "Epoch 35/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0021 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9986 - Precision: 0.9991 - accuracy: 0.9996\n",
      "Epoch 36/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0039 - auprc: 0.9997 - auroc: 0.9999 - Recall: 0.9912 - Precision: 0.9990 - accuracy: 0.9984\n",
      "Epoch 37/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0055 - auprc: 0.9995 - auroc: 0.9998 - Recall: 0.9927 - Precision: 0.9958 - accuracy: 0.9981\n",
      "Epoch 38/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0040 - auprc: 0.9995 - auroc: 0.9999 - Recall: 0.9962 - Precision: 0.9975 - accuracy: 0.9989\n",
      "Epoch 39/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0031 - auprc: 0.9999 - auroc: 0.9999 - Recall: 0.9952 - Precision: 0.9988 - accuracy: 0.9990\n",
      "Epoch 40/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0023 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9966 - Precision: 0.9993 - accuracy: 0.9993\n",
      "Epoch 41/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0016 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9979 - Precision: 0.9997 - accuracy: 0.9996\n",
      "Epoch 42/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0014 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9986 - Precision: 0.9994 - accuracy: 0.9997\n",
      "Epoch 43/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0018 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9986 - Precision: 0.9994 - accuracy: 0.9997\n",
      "Epoch 44/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0018 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9976 - Precision: 0.9994 - accuracy: 0.9995\n",
      "Epoch 45/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0050 - auprc: 0.9994 - auroc: 0.9998 - Recall: 0.9955 - Precision: 0.9984 - accuracy: 0.9990\n",
      "Epoch 46/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0029 - auprc: 0.9997 - auroc: 0.9999 - Recall: 0.9967 - Precision: 0.9988 - accuracy: 0.9993\n",
      "Epoch 47/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0031 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9970 - Precision: 0.9978 - accuracy: 0.9991\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0036 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9963 - Precision: 0.9980 - accuracy: 0.9990\n",
      "Epoch 49/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0030 - auprc: 0.9997 - auroc: 0.9999 - Recall: 0.9976 - Precision: 0.9986 - accuracy: 0.9994\n",
      "Epoch 50/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0015 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9980 - Precision: 0.9999 - accuracy: 0.9997\n",
      "Epoch 51/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0012 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9989 - Precision: 0.9998 - accuracy: 0.9998\n",
      "Epoch 52/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0027 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9976 - Precision: 0.9996 - accuracy: 0.9995\n",
      "Epoch 53/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0016 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9983 - Precision: 0.9996 - accuracy: 0.9997\n",
      "Epoch 54/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0023 - auprc: 0.9997 - auroc: 0.9999 - Recall: 0.9976 - Precision: 0.9989 - accuracy: 0.9994\n",
      "Epoch 55/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0040 - auprc: 0.9994 - auroc: 0.9998 - Recall: 0.9964 - Precision: 0.9981 - accuracy: 0.9991\n",
      "Epoch 56/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0029 - auprc: 0.9996 - auroc: 0.9999 - Recall: 0.9972 - Precision: 0.9985 - accuracy: 0.9993\n",
      "Epoch 57/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0013 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9990 - Precision: 0.9998 - accuracy: 0.9998\n",
      "Epoch 58/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0019 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9982 - Precision: 0.9995 - accuracy: 0.9996\n",
      "Epoch 59/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0073 - auprc: 0.9989 - auroc: 0.9997 - Recall: 0.9976 - Precision: 0.9984 - accuracy: 0.9993\n",
      "Epoch 60/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0011 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9994 - Precision: 0.9999 - accuracy: 0.9999\n",
      "Epoch 61/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 9.2585e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9994 - Precision: 1.0000 - accuracy: 0.9999\n",
      "Epoch 62/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0010 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9993 - Precision: 0.9998 - accuracy: 0.9998\n",
      "Epoch 63/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0013 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9994 - Precision: 0.9998 - accuracy: 0.9999\n",
      "Epoch 64/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0036 - auprc: 0.9997 - auroc: 0.9999 - Recall: 0.9961 - Precision: 0.9993 - accuracy: 0.9992\n",
      "Epoch 65/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0023 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9963 - Precision: 0.9996 - accuracy: 0.9993\n",
      "Epoch 66/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0011 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9991 - Precision: 0.9996 - accuracy: 0.9998\n",
      "Epoch 67/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0012 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9981 - Precision: 0.9998 - accuracy: 0.9997\n",
      "Epoch 68/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0045 - auprc: 0.9996 - auroc: 0.9999 - Recall: 0.9962 - Precision: 0.9971 - accuracy: 0.9989\n",
      "Epoch 69/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0020 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9986 - Precision: 0.9992 - accuracy: 0.9996\n",
      "Epoch 70/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0011 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9995 - Precision: 0.9996 - accuracy: 0.9999\n",
      "Epoch 71/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0018 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9970 - Precision: 0.9995 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='models', max=4.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.2252 - auprc: 0.9775 - auroc: 0.9943 - Recall: 0.9864 - Precision: 0.8163 - accuracy: 0.9607\n",
      "Epoch 2/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0197 - auprc: 0.9979 - auroc: 0.9996 - Recall: 0.9944 - Precision: 0.9845 - accuracy: 0.9965\n",
      "Epoch 3/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0146 - auprc: 0.9982 - auroc: 0.9997 - Recall: 0.9971 - Precision: 0.9892 - accuracy: 0.9977\n",
      "Epoch 4/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0127 - auprc: 0.9986 - auroc: 0.9996 - Recall: 0.9966 - Precision: 0.9905 - accuracy: 0.9978\n",
      "Epoch 5/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0177 - auprc: 0.9960 - auroc: 0.9995 - Recall: 0.9957 - Precision: 0.9848 - accuracy: 0.9967\n",
      "Epoch 6/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0086 - auprc: 0.9996 - auroc: 1.0000 - Recall: 0.9978 - Precision: 0.9943 - accuracy: 0.9987\n",
      "Epoch 7/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0087 - auprc: 0.9992 - auroc: 0.9999 - Recall: 0.9980 - Precision: 0.9934 - accuracy: 0.9986\n",
      "Epoch 8/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0059 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9990 - Precision: 0.9968 - accuracy: 0.9993\n",
      "Epoch 9/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0050 - auprc: 0.9997 - auroc: 0.9999 - Recall: 0.9993 - Precision: 0.9977 - accuracy: 0.9995\n",
      "Epoch 10/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0046 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9992 - Precision: 0.9976 - accuracy: 0.9995\n",
      "Epoch 11/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0070 - auprc: 0.9991 - auroc: 0.9999 - Recall: 0.9983 - Precision: 0.9952 - accuracy: 0.9989\n",
      "Epoch 12/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0082 - auprc: 0.9979 - auroc: 0.9997 - Recall: 0.9977 - Precision: 0.9945 - accuracy: 0.9987\n",
      "Epoch 13/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0041 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9987 - Precision: 0.9980 - accuracy: 0.9995\n",
      "Epoch 14/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0036 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9986 - Precision: 0.9984 - accuracy: 0.9995\n",
      "Epoch 15/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0042 - auprc: 0.9994 - auroc: 0.9998 - Recall: 0.9993 - Precision: 0.9978 - accuracy: 0.9995\n",
      "Epoch 16/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0029 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9993 - Precision: 0.9986 - accuracy: 0.9997\n",
      "Epoch 17/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0024 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9996 - Precision: 0.9993 - accuracy: 0.9998\n",
      "Epoch 18/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0017 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0018 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9997 - accuracy: 0.9999\n",
      "Epoch 20/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0018 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9995 - accuracy: 0.9999\n",
      "Epoch 21/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0013 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0019 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9996 - Precision: 0.9993 - accuracy: 0.9998\n",
      "Epoch 23/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0014 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9996 - accuracy: 0.9999\n",
      "Epoch 24/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0010 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0088 - auprc: 0.9977 - auroc: 0.9991 - Recall: 0.9957 - Precision: 0.9943 - accuracy: 0.9983\n",
      "Epoch 26/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0016 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9993 - accuracy: 0.9998\n",
      "Epoch 27/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0018 - auprc: 0.9998 - auroc: 0.9999 - Recall: 0.9996 - Precision: 0.9988 - accuracy: 0.9997\n",
      "Epoch 28/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0011 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9997 - accuracy: 0.9999\n",
      "Epoch 29/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0011 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9995 - accuracy: 0.9999\n",
      "Epoch 30/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0011 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9997 - accuracy: 0.9999\n",
      "Epoch 31/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0013 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9993 - accuracy: 0.9998\n",
      "Epoch 32/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 8.0597e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9998 - accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 8.4540e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9997 - accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 7.6757e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 7.3239e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 0.9998 - accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 7.3280e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9999 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0013 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9995 - Precision: 0.9991 - accuracy: 0.9998\n",
      "Epoch 38/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 5.4768e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 4.6919e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 4.5828e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0025 - auprc: 0.9994 - auroc: 0.9999 - Recall: 0.9991 - Precision: 0.9987 - accuracy: 0.9996\n",
      "Epoch 42/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 9.5561e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9995 - accuracy: 0.9999\n",
      "Epoch 43/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 5.7308e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9998 - accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 5.5031e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.4562e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9998 - accuracy: 0.9999\n",
      "Epoch 46/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.6064e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9996 - accuracy: 0.9999\n",
      "Epoch 47/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 8.8252e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9993 - accuracy: 0.9998\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 1s 6ms/step - loss: 4.6067e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 3.7565e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 3.4989e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 3.5929e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 3.3196e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 3.0008e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0020 - auprc: 0.9996 - auroc: 0.9999 - Recall: 0.9994 - Precision: 0.9990 - accuracy: 0.9997\n",
      "Epoch 55/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 3.4381e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 3.1921e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 3.1467e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.6565e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0020 - auprc: 0.9994 - auroc: 0.9999 - Recall: 0.9996 - Precision: 0.9990 - accuracy: 0.9998\n",
      "Epoch 60/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.8830e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.5576e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.0995e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 2.3346e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 5.1082e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9998 - accuracy: 0.9999\n",
      "Epoch 65/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.6812e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.2919e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.0349e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0017 - auprc: 0.9993 - auroc: 0.9999 - Recall: 0.9995 - Precision: 0.9989 - accuracy: 0.9997\n",
      "Epoch 69/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.0066e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.2327e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9998 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 1.7748e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 1.5784e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 1.4812e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 1.4467e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 1.7252e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0023 - auprc: 0.9996 - auroc: 1.0000 - Recall: 0.9987 - Precision: 0.9988 - accuracy: 0.9996\n",
      "Epoch 77/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 3.7008e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9999 - accuracy: 0.9999\n",
      "Epoch 78/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 4.8491e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9995 - Precision: 0.9997 - accuracy: 0.9999\n",
      "Epoch 79/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.5034e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9998 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 2.8661e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9996 - Precision: 1.0000 - accuracy: 0.9999\n",
      "Epoch 81/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0012 - auprc: 0.9997 - auroc: 0.9999 - Recall: 0.9995 - Precision: 0.9994 - accuracy: 0.9998\n",
      "Epoch 82/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 3.4712e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9999 - accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 9.5726e-04 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9994 - Precision: 0.9993 - accuracy: 0.9998\n",
      "Epoch 84/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 2.8217e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9997 - Precision: 1.0000 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='models', max=4.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.1592 - auprc: 0.9716 - auroc: 0.9881 - Recall: 0.9596 - Precision: 0.8970 - accuracy: 0.9749\n",
      "Epoch 2/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0149 - auprc: 0.9978 - auroc: 0.9997 - Recall: 0.9957 - Precision: 0.9892 - accuracy: 0.9975\n",
      "Epoch 3/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0332 - auprc: 0.9880 - auroc: 0.9986 - Recall: 0.9903 - Precision: 0.9662 - accuracy: 0.9926\n",
      "Epoch 4/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0154 - auprc: 0.9979 - auroc: 0.9997 - Recall: 0.9965 - Precision: 0.9834 - accuracy: 0.9966\n",
      "Epoch 5/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0413 - auprc: 0.9869 - auroc: 0.9975 - Recall: 0.9913 - Precision: 0.9550 - accuracy: 0.9908\n",
      "Epoch 6/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0382 - auprc: 0.9881 - auroc: 0.9983 - Recall: 0.9920 - Precision: 0.9549 - accuracy: 0.9909\n",
      "Epoch 7/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0210 - auprc: 0.9994 - auroc: 0.9999 - Recall: 0.9968 - Precision: 0.9894 - accuracy: 0.9977\n",
      "Epoch 8/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0157 - auprc: 0.9992 - auroc: 0.9999 - Recall: 0.9976 - Precision: 0.9901 - accuracy: 0.9979\n",
      "Epoch 9/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0104 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9990 - Precision: 0.9944 - accuracy: 0.9989\n",
      "Epoch 10/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0086 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9990 - Precision: 0.9954 - accuracy: 0.9991\n",
      "Epoch 11/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0069 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9990 - Precision: 0.9970 - accuracy: 0.9993\n",
      "Epoch 12/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0451 - auprc: 0.9834 - auroc: 0.9969 - Recall: 0.9862 - Precision: 0.9721 - accuracy: 0.9930\n",
      "Epoch 13/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0143 - auprc: 0.9984 - auroc: 0.9996 - Recall: 0.9930 - Precision: 0.9926 - accuracy: 0.9976\n",
      "Epoch 14/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0103 - auprc: 0.9990 - auroc: 0.9997 - Recall: 0.9954 - Precision: 0.9956 - accuracy: 0.9985\n",
      "Epoch 15/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0080 - auprc: 0.9994 - auroc: 0.9999 - Recall: 0.9970 - Precision: 0.9960 - accuracy: 0.9988\n",
      "Epoch 16/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0068 - auprc: 0.9996 - auroc: 0.9999 - Recall: 0.9972 - Precision: 0.9970 - accuracy: 0.9990\n",
      "Epoch 17/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0066 - auprc: 0.9993 - auroc: 0.9999 - Recall: 0.9967 - Precision: 0.9975 - accuracy: 0.9990\n",
      "Epoch 18/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0060 - auprc: 0.9994 - auroc: 0.9999 - Recall: 0.9969 - Precision: 0.9976 - accuracy: 0.9991\n",
      "Epoch 19/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0044 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9969 - Precision: 0.9982 - accuracy: 0.9992\n",
      "Epoch 20/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0033 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9986 - Precision: 0.9987 - accuracy: 0.9996\n",
      "Epoch 21/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0094 - auprc: 0.9974 - auroc: 0.9984 - Recall: 0.9947 - Precision: 0.9980 - accuracy: 0.9988\n",
      "Epoch 22/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0144 - auprc: 0.9945 - auroc: 0.9993 - Recall: 0.9971 - Precision: 0.9922 - accuracy: 0.9982\n",
      "Epoch 23/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0060 - auprc: 0.9991 - auroc: 0.9997 - Recall: 0.9971 - Precision: 0.9986 - accuracy: 0.9993\n",
      "Epoch 24/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0036 - auprc: 0.9994 - auroc: 0.9995 - Recall: 0.9983 - Precision: 0.9995 - accuracy: 0.9996\n",
      "Epoch 25/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0027 - auprc: 0.9998 - auroc: 0.9998 - Recall: 0.9994 - Precision: 0.9991 - accuracy: 0.9997\n",
      "Epoch 26/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0030 - auprc: 0.9993 - auroc: 0.9995 - Recall: 0.9987 - Precision: 0.9995 - accuracy: 0.9997\n",
      "Epoch 27/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0028 - auprc: 0.9995 - auroc: 0.9996 - Recall: 0.9987 - Precision: 0.9994 - accuracy: 0.9997\n",
      "Epoch 28/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0025 - auprc: 0.9995 - auroc: 0.9996 - Recall: 0.9988 - Precision: 0.9996 - accuracy: 0.9997\n",
      "Epoch 29/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0021 - auprc: 0.9996 - auroc: 0.9997 - Recall: 0.9991 - Precision: 0.9998 - accuracy: 0.9998\n",
      "Epoch 30/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0025 - auprc: 0.9994 - auroc: 0.9995 - Recall: 0.9986 - Precision: 0.9996 - accuracy: 0.9997\n",
      "Epoch 31/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0127 - auprc: 0.9951 - auroc: 0.9976 - Recall: 0.9943 - Precision: 0.9940 - accuracy: 0.9981\n",
      "Epoch 32/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0035 - auprc: 0.9989 - auroc: 0.9992 - Recall: 0.9975 - Precision: 0.9997 - accuracy: 0.9995\n",
      "Epoch 33/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0030 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9977 - Precision: 0.9996 - accuracy: 0.9996\n",
      "Epoch 34/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0033 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9970 - Precision: 0.9999 - accuracy: 0.9995\n",
      "Epoch 35/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0030 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9971 - Precision: 0.9998 - accuracy: 0.9995\n",
      "Epoch 36/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0028 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9971 - Precision: 0.9998 - accuracy: 0.9995\n",
      "Epoch 37/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0024 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9973 - Precision: 1.0000 - accuracy: 0.9995\n",
      "Epoch 38/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0019 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9979 - Precision: 0.9999 - accuracy: 0.9996\n",
      "Epoch 39/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0020 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9973 - Precision: 1.0000 - accuracy: 0.9995\n",
      "Epoch 40/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0022 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9965 - Precision: 1.0000 - accuracy: 0.9994\n",
      "Epoch 41/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0018 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9973 - Precision: 1.0000 - accuracy: 0.9995\n",
      "Epoch 42/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0011 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9987 - Precision: 1.0000 - accuracy: 0.9998\n",
      "Epoch 43/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0012 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9980 - Precision: 0.9999 - accuracy: 0.9997\n",
      "Epoch 44/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0129 - auprc: 0.9957 - auroc: 0.9990 - Recall: 0.9939 - Precision: 0.9942 - accuracy: 0.9980\n",
      "Epoch 45/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0017 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9981 - Precision: 0.9999 - accuracy: 0.9997\n",
      "Epoch 46/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0016 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9976 - Precision: 1.0000 - accuracy: 0.9996\n",
      "Epoch 47/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0015 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9976 - Precision: 1.0000 - accuracy: 0.9996\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0014 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9973 - Precision: 1.0000 - accuracy: 0.9995\n",
      "Epoch 49/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0012 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9971 - Precision: 1.0000 - accuracy: 0.9995\n",
      "Epoch 50/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0010 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9971 - Precision: 1.0000 - accuracy: 0.9995\n",
      "Epoch 51/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 8.8352e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9977 - Precision: 1.0000 - accuracy: 0.9996\n",
      "Epoch 52/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0013 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9982 - Precision: 0.9997 - accuracy: 0.9997\n",
      "Epoch 53/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 8.3902e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9996 - accuracy: 0.9999\n",
      "Epoch 54/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0012 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9995 - Precision: 0.9991 - accuracy: 0.9998\n",
      "Epoch 55/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 8.9976e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9999 - Precision: 0.9995 - accuracy: 0.9999\n",
      "Epoch 56/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.9019e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9998 - accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 9.9458e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9998 - Precision: 0.9996 - accuracy: 0.9999\n",
      "Epoch 58/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.6679e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9996 - accuracy: 0.9999\n",
      "Epoch 59/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 5.8735e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9997 - accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 5.2145e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 1.0000 - accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 5.5590e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9998 - accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0132 - auprc: 0.9961 - auroc: 0.9985 - Recall: 0.9963 - Precision: 0.9937 - accuracy: 0.9983\n",
      "Epoch 63/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 8.7339e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9995 - accuracy: 0.9999\n",
      "Epoch 64/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 9.4961e-04 - auprc: 0.9999 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9998 - accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 8.3563e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 0.9997 - Precision: 0.9995 - accuracy: 0.9999\n",
      "Epoch 66/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 8.0110e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9993 - accuracy: 0.9999\n",
      "Epoch 67/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.1331e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9998 - accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.8055e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9995 - accuracy: 0.9999\n",
      "Epoch 69/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.3279e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9996 - accuracy: 0.9999\n",
      "Epoch 70/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 6.2392e-04 - auprc: 1.0000 - auroc: 1.0000 - Recall: 1.0000 - Precision: 0.9996 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aec07f72cf43cca521f8c81eee22b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='models', max=4.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.7361 - auprc: 0.9007 - auroc: 0.9814 - Recall: 0.9786 - Precision: 0.7262 - accuracy: 0.9349\n",
      "Epoch 2/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.4630 - auprc: 0.9822 - auroc: 0.9871 - Recall: 0.9727 - Precision: 0.9752 - accuracy: 0.9913\n",
      "Epoch 3/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.4245 - auprc: 0.7939 - auroc: 0.7921 - Recall: 0.7466 - Precision: 0.9902 - accuracy: 0.9565\n",
      "Epoch 4/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.4171 - auprc: 0.7205 - auroc: 0.8288 - Recall: 0.5612 - Precision: 0.9793 - accuracy: 0.9249\n",
      "Epoch 5/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.3615 - auprc: 0.7388 - auroc: 0.8050 - Recall: 0.6361 - Precision: 0.9912 - accuracy: 0.9384\n",
      "Epoch 6/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.2800 - auprc: 0.8825 - auroc: 0.8978 - Recall: 0.8320 - Precision: 0.9991 - accuracy: 0.9719\n",
      "Epoch 7/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.2477 - auprc: 0.9505 - auroc: 0.9765 - Recall: 0.9022 - Precision: 0.9911 - accuracy: 0.9824\n",
      "Epoch 8/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.1860 - auprc: 0.9756 - auroc: 0.9770 - Recall: 0.9667 - Precision: 0.9990 - accuracy: 0.9943\n",
      "Epoch 9/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.1741 - auprc: 0.9568 - auroc: 0.9709 - Recall: 0.9294 - Precision: 0.9982 - accuracy: 0.9880\n",
      "Epoch 10/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.1406 - auprc: 0.9832 - auroc: 0.9875 - Recall: 0.9736 - Precision: 0.9992 - accuracy: 0.9955\n",
      "Epoch 11/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.1596 - auprc: 0.9346 - auroc: 0.9536 - Recall: 0.8984 - Precision: 0.9930 - accuracy: 0.9820\n",
      "Epoch 12/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.1345 - auprc: 0.9399 - auroc: 0.9535 - Recall: 0.9082 - Precision: 0.9997 - accuracy: 0.9846\n",
      "Epoch 13/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.1467 - auprc: 0.9468 - auroc: 0.9611 - Recall: 0.9243 - Precision: 0.9928 - accuracy: 0.9863\n",
      "Epoch 14/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.1141 - auprc: 0.9446 - auroc: 0.9571 - Recall: 0.9149 - Precision: 0.9996 - accuracy: 0.9858\n",
      "Epoch 15/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.1103 - auprc: 0.9842 - auroc: 0.9960 - Recall: 0.9177 - Precision: 0.9970 - accuracy: 0.9858\n",
      "Epoch 16/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0744 - auprc: 0.9972 - auroc: 0.9993 - Recall: 0.9758 - Precision: 0.9996 - accuracy: 0.9959\n",
      "Epoch 17/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0673 - auprc: 0.9972 - auroc: 0.9993 - Recall: 0.9757 - Precision: 0.9999 - accuracy: 0.9959\n",
      "Epoch 18/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0630 - auprc: 0.9969 - auroc: 0.9993 - Recall: 0.9719 - Precision: 0.9998 - accuracy: 0.9953\n",
      "Epoch 19/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0595 - auprc: 0.9972 - auroc: 0.9991 - Recall: 0.9870 - Precision: 0.9973 - accuracy: 0.9974\n",
      "Epoch 20/500\n",
      "259/259 [==============================] - 2s 6ms/step - loss: 0.0582 - auprc: 0.9933 - auroc: 0.9982 - Recall: 0.9659 - Precision: 0.9991 - accuracy: 0.9942\n",
      "Epoch 21/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0498 - auprc: 0.9948 - auroc: 0.9986 - Recall: 0.9750 - Precision: 0.9995 - accuracy: 0.9958\n",
      "Epoch 22/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0436 - auprc: 0.9958 - auroc: 0.9988 - Recall: 0.9809 - Precision: 0.9996 - accuracy: 0.9968\n",
      "Epoch 23/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0385 - auprc: 0.9967 - auroc: 0.9987 - Recall: 0.9859 - Precision: 0.9997 - accuracy: 0.9976\n",
      "Epoch 24/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0348 - auprc: 0.9962 - auroc: 0.9976 - Recall: 0.9889 - Precision: 0.9995 - accuracy: 0.9981\n",
      "Epoch 25/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0368 - auprc: 0.9955 - auroc: 0.9988 - Recall: 0.9781 - Precision: 0.9999 - accuracy: 0.9963\n",
      "Epoch 26/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0339 - auprc: 0.9966 - auroc: 0.9992 - Recall: 0.9837 - Precision: 0.9986 - accuracy: 0.9971\n",
      "Epoch 27/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0370 - auprc: 0.9961 - auroc: 0.9991 - Recall: 0.9736 - Precision: 0.9984 - accuracy: 0.9954\n",
      "Epoch 28/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0314 - auprc: 0.9973 - auroc: 0.9992 - Recall: 0.9875 - Precision: 0.9994 - accuracy: 0.9978\n",
      "Epoch 29/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0234 - auprc: 0.9989 - auroc: 0.9998 - Recall: 0.9907 - Precision: 0.9997 - accuracy: 0.9984\n",
      "Epoch 30/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0247 - auprc: 0.9984 - auroc: 0.9996 - Recall: 0.9861 - Precision: 0.9999 - accuracy: 0.9977\n",
      "Epoch 31/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0298 - auprc: 0.9959 - auroc: 0.9990 - Recall: 0.9744 - Precision: 0.9999 - accuracy: 0.9957\n",
      "Epoch 32/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0457 - auprc: 0.9910 - auroc: 0.9981 - Recall: 0.9469 - Precision: 0.9969 - accuracy: 0.9907\n",
      "Epoch 33/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0286 - auprc: 0.9966 - auroc: 0.9992 - Recall: 0.9846 - Precision: 0.9985 - accuracy: 0.9972\n",
      "Epoch 34/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0226 - auprc: 0.9990 - auroc: 0.9998 - Recall: 0.9753 - Precision: 1.0000 - accuracy: 0.9959\n",
      "Epoch 35/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0222 - auprc: 0.9985 - auroc: 0.9997 - Recall: 0.9722 - Precision: 1.0000 - accuracy: 0.9954\n",
      "Epoch 36/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0197 - auprc: 0.9985 - auroc: 0.9997 - Recall: 0.9751 - Precision: 1.0000 - accuracy: 0.9958\n",
      "Epoch 37/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0190 - auprc: 0.9987 - auroc: 0.9997 - Recall: 0.9743 - Precision: 1.0000 - accuracy: 0.9957\n",
      "Epoch 38/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0229 - auprc: 0.9973 - auroc: 0.9988 - Recall: 0.9705 - Precision: 0.9994 - accuracy: 0.9950\n",
      "Epoch 39/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0191 - auprc: 0.9983 - auroc: 0.9996 - Recall: 0.9727 - Precision: 1.0000 - accuracy: 0.9955\n",
      "Epoch 40/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0146 - auprc: 0.9995 - auroc: 0.9999 - Recall: 0.9746 - Precision: 1.0000 - accuracy: 0.9958\n",
      "Epoch 41/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0163 - auprc: 0.9995 - auroc: 0.9999 - Recall: 0.9813 - Precision: 0.9998 - accuracy: 0.9969\n",
      "Epoch 42/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0098 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9908 - Precision: 1.0000 - accuracy: 0.9985\n",
      "Epoch 43/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0086 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9900 - Precision: 1.0000 - accuracy: 0.9983\n",
      "Epoch 44/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0082 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9890 - Precision: 1.0000 - accuracy: 0.9982\n",
      "Epoch 45/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0190 - auprc: 0.9977 - auroc: 0.9988 - Recall: 0.9806 - Precision: 0.9901 - accuracy: 0.9951\n",
      "Epoch 46/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0154 - auprc: 0.9984 - auroc: 0.9995 - Recall: 0.9720 - Precision: 0.9990 - accuracy: 0.9952\n",
      "Epoch 47/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0196 - auprc: 0.9984 - auroc: 0.9996 - Recall: 0.9881 - Precision: 0.9966 - accuracy: 0.9975\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0108 - auprc: 0.9995 - auroc: 0.9999 - Recall: 0.9909 - Precision: 0.9991 - accuracy: 0.9983\n",
      "Epoch 49/500\n",
      "259/259 [==============================] - 1s 5ms/step - loss: 0.0097 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9901 - Precision: 0.9997 - accuracy: 0.9983\n",
      "Epoch 50/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0074 - auprc: 0.9999 - auroc: 1.0000 - Recall: 0.9915 - Precision: 0.9998 - accuracy: 0.9986\n",
      "Epoch 51/500\n",
      "259/259 [==============================] - 1s 6ms/step - loss: 0.0067 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9927 - Precision: 0.9995 - accuracy: 0.9987\n",
      "Epoch 52/500\n",
      " 19/259 [=>............................] - ETA: 1s - loss: 0.0085 - auprc: 0.9998 - auroc: 1.0000 - Recall: 0.9849 - Precision: 1.0000 - accuracy: 0.9975"
     ]
    }
   ],
   "source": [
    "# make holdouts\n",
    "from tqdm.auto import trange, tqdm\n",
    "from embiggen import EdgeTransformer, GraphTransformer, LinkPredictionTransformer\n",
    "\n",
    "link_prediction_models = [\n",
    "    mlp, \n",
    "    logistic_regression,\n",
    "    random_forest,\n",
    "    decision_tree\n",
    "]\n",
    "\n",
    "rankings = {}\n",
    "results = []\n",
    "\n",
    "# make negative graph\n",
    "neg_graph = reduced_graph.sample_negatives(\n",
    "            seed_graph=graph_drugs_only,\n",
    "            random_state=seed,\n",
    "            only_from_same_component=True,\n",
    "            negatives_number=chembl_to_sars_cov_2_edges.sum() * 10\n",
    "        )\n",
    "\n",
    "for holdout in trange(5, desc=\"computing embeddings\"):\n",
    "    \n",
    "    pos_training, pos_validation = reduced_graph.connected_holdout(\n",
    "        train_size=train_percentage, \n",
    "        edge_types=['chembl_to_sars_cov_2'],\n",
    "        random_state=seed + holdout)        \n",
    "\n",
    "    neg_training, neg_validation = neg_graph.random_holdout(\n",
    "        random_state=seed + holdout, train_size=train_percentage\n",
    "    )    \n",
    "\n",
    "    pos_training.enable_fast_walk()\n",
    "    embedding = compute_skipgram_embedding(pos_training, holdout)    \n",
    "    \n",
    "    for edge_embedding_method in tqdm(EdgeTransformer.methods,\n",
    "                                      desc=\"edge embeddings\",\n",
    "                                      leave=False):\n",
    "        rankings[edge_embedding_method] = rankings.get(edge_embedding_method, {})\n",
    "\n",
    "        graph_transformer = GraphTransformer(method=edge_embedding_method)\n",
    "        graph_transformer.fit(embedding)\n",
    "        graph_test_X = graph_transformer.transform(pos_validation)\n",
    "\n",
    "        transformer = LinkPredictionTransformer(method=edge_embedding_method)\n",
    "        transformer.fit(embedding)\n",
    "        train_X, train_y = transformer.transform(\n",
    "            pos_training.filter(edge_types=['chembl_to_sars_cov_2']), \n",
    "            neg_training\n",
    "        )\n",
    "        test_X, test_y = transformer.transform(pos_validation, neg_validation)\n",
    "    \n",
    "        for link_prediction_model in tqdm(link_prediction_models, desc=\"models\", leave=False):\n",
    "            rankings[edge_embedding_method][link_prediction_model] = rankings[edge_embedding_method].get(link_prediction_model, [])            \n",
    "            train_pred, test_pred, link_prediction_ranking = link_prediction_model(\n",
    "                holdout=holdout,\n",
    "                edge_embedding_method=edge_embedding_method,\n",
    "                embedding_model='SkipGram',\n",
    "                train_X=train_X,\n",
    "                train_y=train_y,\n",
    "                test_X=test_X,\n",
    "                graph_test_X=graph_test_X,\n",
    "                edges=list(zip(\n",
    "                    pos_validation.get_source_names(),\n",
    "                    pos_validation.get_destination_names(),\n",
    "                ))\n",
    "            )\n",
    "            rankings[edge_embedding_method][link_prediction_model].append(link_prediction_ranking)\n",
    "            \n",
    "            for run, true, predictions in (\n",
    "                (\"train\", train_y, train_pred),\n",
    "                (\"test\", test_y, test_pred)\n",
    "            ):\n",
    "                results.append({\n",
    "                    \"run\": run,\n",
    "                    \"model\": link_prediction_model.__name__,\n",
    "                    \"edge_embedding_method\": edge_embedding_method,\n",
    "                    \"holdout_number\": holdout,\n",
    "                    **get_metrics_report(true, predictions)\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the weights and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "for path in glob(f\"{embedding_data_dir}/**/*.csv.gz\", recursive=True):\n",
    "    os.system(f\"s3cmd put --acl-public --cf-invalidate {path} {s3_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
