{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embedding using SkipGram\n",
    "\n",
    "This is an embedding of the whole graph, 80/20 training and validation split and all sources\n",
    "\n",
    "kg-covid-19:\n",
    "version 20201012\n",
    "\n",
    "Name: ensmallen-graph\n",
    "Version: 0.4.4\n",
    "\n",
    "Name: embiggen\n",
    "Version: 0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg_resources import get_distribution\n",
    "assert(get_distribution(\"ensmallen-graph\").version == '0.4.4')  # identical to 0.4.3 except for addition of some methods like get_edge_id()\n",
    "assert(get_distribution(\"embiggen\").version == '0.6.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "exp_name = \"80_20_kg_covid_19_20201012_training_test_epoch_500_delta_0.0001_updated_holdouts\"\n",
    "s3_path = \"s3://kg-hub-public-data/embeddings/20201012/\"  # keep trailing slash\n",
    "base_url = \"https://kg-hub.berkeleybop.io/embeddings/20201012/\"\n",
    "\n",
    "base_dl_dir = \"downloaded_data\"\n",
    "graph_data_dir = os.path.join(base_dl_dir, \"kg-covid-19-20201012\")\n",
    "embedding_data_dir = os.path.join(base_dl_dir, \"embeddings-20201012\")\n",
    "pos_neg_data_dir = os.path.join(base_dl_dir, \"pos_neg_data_dir\")\n",
    "pos_neg_data_dir = os.path.join(base_dl_dir, \"pos_neg_data_dir\")\n",
    "ranked_drug_dir = os.path.join(base_dl_dir, \"ranked-drug-lists\")\n",
    "\n",
    "# graph stuff\n",
    "graph_out_file = os.path.join(graph_data_dir + \"/kg-covid-19.tar.gz\")\n",
    "nodes_file = os.path.join(graph_data_dir, \"merged-kg_nodes.tsv\")\n",
    "edges_file = os.path.join(graph_data_dir, \"merged-kg_edges.tsv\")\n",
    "sorted_edges_file = os.path.join(graph_data_dir, \"merged-kg_edges_SORTED.tsv\")\n",
    "graph_tar_url = \"https://kg-hub.berkeleybop.io/kg-covid-19/20201012/kg-covid-19.tar.gz\"\n",
    "\n",
    "# embeddings URLs\n",
    "base_kghub_url = \"http://kg-hub.berkeleybop.io/\"\n",
    "embeddings_url = os.path.join(base_kghub_url, \"embeddings/20201012/SkipGram_80_20_kg_covid_19_20201012_training_test_epoch_500_delta_0.0001_embedding.npy\")\n",
    "embedding_file = os.path.join(embedding_data_dir, \"SkipGram_embedding.npy\")\n",
    "\n",
    "# pos/neg nodes for better pos/neg edge set\n",
    "pos_node_url = os.path.join(base_url, pos_neg_data_dir, \"positive_nodes.tsv\")\n",
    "pos_node_file = os.path.join(pos_neg_data_dir, \"positive_nodes.tsv\")\n",
    "neg_node_url = os.path.join(base_url, pos_neg_data_dir, \"negative_nodes.tsv\")\n",
    "neg_node_file = os.path.join(pos_neg_data_dir, \"negative_nodes.tsv\")\n",
    "\n",
    "# ranked list stuff\n",
    "mlp_link_pred_outdir = os.path.join(ranked_drug_dir, \"mlp_link_pred\")\n",
    "os.makedirs(mlp_link_pred_outdir, exist_ok=True)\n",
    "\n",
    "# params\n",
    "seed = 42\n",
    "train_percentage = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_cov_2_curie = 'NCBITaxon:2697049'\n",
    "chembl_prefix = 'CHEMBL.COMPOUND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes_of_interest = ['biolink:Drug',\n",
    "                     'biolink:Drug|biolink:ChemicalSubstance',\n",
    "                     'biolink:ChemicalSubstance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto # Import needed to avoid TensorFlow warnings and general useless infos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the positive and negative nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(pos_neg_data_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(pos_node_file):\n",
    "    with urllib.request.urlopen(pos_node_url) as response, \\\n",
    "        open(pos_node_file, 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)\n",
    "\n",
    "if not os.path.exists(neg_node_file):\n",
    "    with urllib.request.urlopen(neg_node_url) as response, \\\n",
    "        open(neg_node_file, 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)\n",
    "            \n",
    "positive_nodes = pd.read_csv(pos_node_file, \"\\t\", header=0, comment='#')\n",
    "negative_nodes = pd.read_csv(neg_node_file, \"\\t\", header=0, comment='#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the graphs\n",
    "We load the kg-covid-19 graph from the repository as an undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the graphs, if necessary\n",
    "\n",
    "import urllib\n",
    "import os\n",
    "os.makedirs(graph_data_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(nodes_file) or not os.path.exists(edges_file):\n",
    "    with urllib.request.urlopen(graph_tar_url) as response, \\\n",
    "        open(graph_out_file, 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)\n",
    "    os.system(\"tar -xvzf \" + graph_out_file + \" -C \" + graph_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only need to do this once, b/c we'll load the sorted.tsv from now on once it is made below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "new_edge_file = os.path.join(graph_data_dir, 'edges_with_holdout_column.tsv')\n",
    "\n",
    "if not os.path.exists(new_edge_file): \n",
    "    edges = pd.read_csv(\n",
    "        graph_data_dir + \"/merged-kg_edges.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        usecols=[1,3],\n",
    "        dtype={'subject': str, 'object': str}\n",
    "    )\n",
    "    \n",
    "    pos_node_curies_set = set(positive_nodes.curie)\n",
    "\n",
    "    chembl_to_sars_cov_2_edges = (\n",
    "        (edges.subject.str.contains(chembl_prefix) & (edges.object.isin(pos_node_curies_set))) | \n",
    "        (edges.object.str.contains(chembl_prefix) & (edges.subject.isin(pos_node_curies_set)))\n",
    "    )\n",
    "\n",
    "    edges['holdout_edge_label'] = [\n",
    "        'chembl_to_sars_cov_2' if value else 'normal'\n",
    "        for value in chembl_to_sars_cov_2_edges]\n",
    "\n",
    "\n",
    "    edges.to_csv(new_edge_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensmallen_graph import EnsmallenGraph\n",
    "graph = EnsmallenGraph.from_unsorted_csv(\n",
    "    name=\"kg-covid-19\",\n",
    "    edge_path = new_edge_file,\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    edge_types_column='holdout_edge_label',\n",
    "    directed=False,\n",
    "    node_path = graph_data_dir + \"/merged-kg_nodes.tsv\",\n",
    "    nodes_column = 'id',\n",
    "    node_types_column = 'category',\n",
    "    default_node_type = 'biolink:NamedThing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The undirected graph kg-covid-19 has 447766 nodes with 42 different node types:  the 5 most common are biolink:Publication (nodes number 129930), biolink:OntologyClass (nodes number 108266), biolink:Drug (nodes number 32120), biolink:ChemicalSubstance (nodes number 27157) and biolink:Disease (nodes number 24236), of which 8396 are singletons, and 15611957 unweighted edges with 2 different edge types: normal and chembl_to_sars_cov_2, of which 480 are self-loops. The graph is quite sparse as it has a density of 0.00016 and has 9107 connected components, where the component with most nodes has 435728 nodes and the component with the least nodes has 1 nodes. The graph median node degree is 4, the mean node degree is 69.73 and the node degree mode is 1. The top 5 most central nodes are MESH:D014780 (degree 90378), MESH:D006801 (degree 78249), WD:Q30 (degree 65223), MESH:D014777 (degree 54155) and MESH:D017934 (degree 45196)."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_graph = graph.remove_components(edge_types=['chembl_to_sars_cov_2'])\n",
    "reduced_graph = reduced_graph.remove(singletons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The undirected graph kg-covid-19 has 435728 nodes with 40 different node types:  the 5 most common are biolink:Publication (nodes number 129492), biolink:OntologyClass (nodes number 104951), biolink:Drug (nodes number 32016), biolink:ChemicalSubstance (nodes number 27152) and biolink:Disease (nodes number 22281) and 15608444 unweighted edges with 2 different edge types: normal and chembl_to_sars_cov_2, of which 314 are self-loops. The graph is quite sparse as it has a density of 0.00016 and is connected, as it has a single component. The graph median node degree is 4, the mean node degree is 71.64 and the node degree mode is 1. The top 5 most central nodes are MESH:D014780 (degree 90378), MESH:D006801 (degree 78249), WD:Q30 (degree 65223), MESH:D014777 (degree 54155) and MESH:D017934 (degree 45196)."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the SkipGram model\n",
    "We are going to setup the model to use, if available, multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cache_decorator import Cache\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from embiggen import SkipGram\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from embiggen import Node2VecSequence\n",
    "\n",
    "\n",
    "@Cache(\n",
    "    cache_path=\"{cache_dir}/SkipGram/{_hash}_{holdout_idx}.csv.gz\",\n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=['train_graph']\n",
    ")\n",
    "def compute_skipgram_embedding(\n",
    "    train_graph: EnsmallenGraph,\n",
    "    holdout_idx: int,\n",
    "    walk_length: int = 100,\n",
    "    batch_size: int = 2**9,\n",
    "    iterations: int = 20,\n",
    "    return_weight: float = 1.0,\n",
    "    explore_weight: float = 1.0,\n",
    "    embedding_size: int = 100,\n",
    "    change_edge_type_weight: float = 1.0,\n",
    "    window_size: int = 4,\n",
    "    negative_samples: int = 7,\n",
    "    patience: int = 6,\n",
    "    delta: float = 0.1,\n",
    "    epochs: int = 500\n",
    "):\n",
    "    \"\"\"Return dataframe with node embedding obtained with SkipGram for train_graph\n",
    "    \n",
    "    Given a graph, learn embeddings and return dataframe with node embeddings\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    train_graph: EnsmallenGraph\n",
    "    holdout_idx: int, \n",
    "        an int to identify the holdout\n",
    "    walk_length: int = 100,\n",
    "        how many nodes for each walk\n",
    "    batch_size: int = 2**9,\n",
    "        how many walks for each batch\n",
    "    iterations: int = 20,\n",
    "        how many walks per node\n",
    "    return_weight: float = 1.0,\n",
    "        node2vec param, equal to 1/p\n",
    "    explore_weight: float = 1.0,\n",
    "        node2vec param, equal to 1/q\n",
    "    embedding_size: int = 100,\n",
    "        dimensions for embedding\n",
    "    window_size: int = 4,\n",
    "        SkipGram window size\n",
    "    negative_samples: int = 7,\n",
    "        how many negative samples that NCE function needs to sample\n",
    "    patience: int = 6,\n",
    "        how many epochs to wait for loss fxn to improve by [delta]\n",
    "    delta: float = 0.1\n",
    "        change in loss fxn to be considered an improvement\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pd.DataFrame containing an embedding for each node in train_graph\n",
    "    \"\"\"\n",
    "    training_sequence = Node2VecSequence(\n",
    "        train_graph,\n",
    "        walk_length=walk_length,\n",
    "        batch_size=batch_size,\n",
    "        iterations=iterations,\n",
    "        window_size=window_size,\n",
    "        return_weight=return_weight,\n",
    "        explore_weight=explore_weight,\n",
    "        change_edge_type_weight=change_edge_type_weight,\n",
    "        support_mirror_strategy=True\n",
    "    )\n",
    "\n",
    "    strategy = MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = SkipGram(\n",
    "            vocabulary_size=train_graph.get_nodes_number(),\n",
    "            embedding_size=embedding_size,\n",
    "            window_size=window_size,\n",
    "            negative_samples=negative_samples,\n",
    "        )\n",
    "\n",
    "    history = model.fit(\n",
    "        training_sequence,\n",
    "        steps_per_epoch=training_sequence.steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                \"loss\",\n",
    "                min_delta=delta,\n",
    "                patience=patience,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor=\"loss\",\n",
    "                patience=patience//2,\n",
    "                min_delta=delta\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return model.get_embedding_dataframe(train_graph.get_node_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def create_ranking(edges: List[Tuple[str, str]], predictions: np.ndarray) -> Dict:\n",
    "    \"\"\"Return ranking of edges and predictions.\n",
    "\n",
    "    Parameters\n",
    "    ---------------------\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edges to be predicted.\n",
    "    predictions: np.ndarray,\n",
    "        Predictions of the model.\n",
    "\n",
    "    Returns\n",
    "    ---------------------\n",
    "    Dictionary of the ranking.\n",
    "    \"\"\"\n",
    "    return dict(zip(edges, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import AUC, Recall, Precision\n",
    "from typing import Dict\n",
    "\n",
    "@Cache(    \n",
    "    cache_path=\"{cache_dir}/model_predictions/mlp/{embedding_model}/{holdout}_{_hash}.pkl.gz\",\n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\", \"batch_size\"]\n",
    ")\n",
    "def mlp(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,    \n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]],\n",
    "    epochs: int = 500,\n",
    "    batch_size: int = 256,\n",
    "    patience: int = 10,\n",
    "    min_delta: float = 0.000001,\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"Return random forest predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(train_X.shape[1:]),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\",\n",
    "              activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"nadam\",\n",
    "        metrics=[\n",
    "            AUC(curve=\"PR\", name=\"auprc\"),\n",
    "            AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "            Recall(name=\"Recall\"),\n",
    "            Precision(name=\"Precision\"),            \n",
    "            \"accuracy\"\n",
    "        ]\n",
    "    )\n",
    "    model.fit(\n",
    "        train_X, train_y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\"loss\", patience=patience, min_delta=min_delta)\n",
    "        ],\n",
    "        verbose=False\n",
    "    )\n",
    "    train_pred = model.predict(train_X)\n",
    "    test_pred = model.predict(test_X).flatten()\n",
    "    return train_pred, test_pred, create_ranking(\n",
    "        edges, model.predict(graph_test_X).flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Submodule offering method to execute cached random forest.\"\"\"\n",
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from multiprocessing import cpu_count\n",
    "from cache_decorator import Cache\n",
    "\n",
    "@Cache(    \n",
    "    cache_path=\"{cache_dir}/model_predictions/random_forest/{embedding_model}/{holdout}_{_hash}.pkl.gz\",\n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\"]\n",
    ")\n",
    "def random_forest(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,\n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]]\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"Return random forest predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    edge_embedding_method: str,\n",
    "        Name of the edge embedding model.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=10,\n",
    "        n_jobs=cpu_count(),\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        max_samples=0.5\n",
    "    )\n",
    "    model.fit(train_X, train_y)\n",
    "    train_pred = model.predict_proba(train_X)[:, 1]\n",
    "    test_pred = model.predict_proba(test_X)[:, 1]\n",
    "    return train_pred, test_pred, create_ranking(edges, model.predict_proba(graph_test_X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from cache_decorator import Cache\n",
    "\n",
    "@Cache(\n",
    "    cache_path=\"{cache_dir}/model_predictions/decision_tree/{embedding_model}/{holdout}_{_hash}.pkl.gz\",    \n",
    "    cache_dir=embedding_data_dir,    \n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\"]\n",
    ")\n",
    "def decision_tree(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,    \n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]]\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"Return decision tree predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    edge_embedding_method: str,\n",
    "        Name of the edge embedding model.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(max_depth=10, class_weight=\"balanced\")\n",
    "    model.fit(train_X, train_y)\n",
    "    train_pred = model.predict_proba(train_X)[:, 1]\n",
    "    test_pred = model.predict_proba(test_X)[:, 1]\n",
    "    return train_pred, test_pred, create_ranking(edges, model.predict_proba(graph_test_X)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from cache_decorator import Cache\n",
    "\n",
    "@Cache(\n",
    "    cache_path=\"{cache_dir}/model_predictions/logistic_regression/{embedding_model}/{holdout}_{_hash}.pkl.gz\",    \n",
    "    cache_dir=embedding_data_dir,\n",
    "    args_to_ignore=[\"train_X\", \"train_y\", \"test_X\", \"graph_test_X\", \"edges\"]\n",
    ")\n",
    "def logistic_regression(\n",
    "    holdout: int,\n",
    "    edge_embedding_method: str,    \n",
    "    embedding_model: str,\n",
    "    train_X: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    graph_test_X: np.ndarray,\n",
    "    edges: List[Tuple[str, str]]\n",
    ") -> Tuple[np.ndarray, np.ndarray, LogisticRegression]:\n",
    "    \"\"\"Return logistic regression predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    holdout: int,\n",
    "        Number of the holdout.\n",
    "    edge_embedding_method: str,\n",
    "        Name of the edge embedding model.\n",
    "    embedding_model: str,\n",
    "        Name of the embedding model.\n",
    "    train_X: np.ndarray,\n",
    "        Data to use as input for training process.\n",
    "    train_y: np.ndarray,\n",
    "        Data to use as output for the training process.\n",
    "    test_X: np.ndarray,\n",
    "        Data to use as input for the testing process.\n",
    "    graph_test_X: np.ndarray,\n",
    "        Data to use for the ranking of the edges.\n",
    "    edges: List[Tuple[str, str]],\n",
    "        Edge names to be ranked.\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    Tuple with training and test predictions.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_pred = model.predict_proba(train_X)[:, 1]\n",
    "    test_pred = model.predict_proba(test_X)[:, 1]\n",
    "    return train_pred, test_pred, create_ranking(edges, model.predict_proba(graph_test_X)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, recall_score, precision_score\n",
    "from sanitize_ml_labels import sanitize_ml_labels\n",
    "from typing import Dict\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def specificity_score(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn+fp)\n",
    "\n",
    "def get_metrics_report(y_true: np.ndarray, y_pred: np.ndarray)->Dict[str, float]:\n",
    "    float_metrics = (average_precision_score, roc_auc_score)\n",
    "    integer_metrics = (accuracy_score, recall_score, precision_score, specificity_score, f1_score)\n",
    "    integer_y_pred = y_pred.round().astype(int)\n",
    "\n",
    "    return {\n",
    "        **{\n",
    "            sanitize_ml_labels(metric.__name__): metric(y_true, integer_y_pred)\n",
    "            for metric in integer_metrics\n",
    "        },\n",
    "        **{\n",
    "            sanitize_ml_labels(metric.__name__): metric(y_true, y_pred)\n",
    "            for metric in float_metrics\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_pca_scatter_plot(train_X, train_y, test_X, test_y, edge_method):\n",
    "    pca = PCA(\n",
    "        n_components=2,\n",
    "        random_state=seed\n",
    "    )\n",
    "    pca.fit(train_X)\n",
    "    train_X_2d = pca.transform(train_X)\n",
    "\n",
    "    test_X_2d = pca.transform(test_X)\n",
    "    \n",
    "    plt.title(edge_method)\n",
    "    plt.scatter(*train_X_2d[train_y==0].T, s=3, alpha=0.8, label=\"neg train edges\")\n",
    "    plt.scatter(*train_X_2d[train_y==1].T, s=3, alpha=0.8, label=\"pos train edges\")\n",
    "\n",
    "    plt.scatter(*test_X_2d[test_y==0].T, s=3, alpha=0.8, label=\"neg test edges\")\n",
    "    plt.scatter(*test_X_2d[test_y==1].T, s=3, alpha=0.8, label=\"pos test edges\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure performance by making Skipgram embeddings for N different holdouts, train link prediction classifiers, and measure performance N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_nodes = [\n",
    "    node\n",
    "    for node in reduced_graph.filter(edge_types=['chembl_to_sars_cov_2']).remove(singletons=True).get_node_names()\n",
    "    if node.startswith(\"CHEMBL.COMPOUND\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "neg_bp_edges = np.array(reduced_graph.get_bipartite_edge_names(\n",
    "    removed_existing_edges=False,\n",
    "    first_nodes_set=set(chembl_nodes),\n",
    "    second_nodes_set=set(negative_nodes.curie)\n",
    "))\n",
    "num_neg_edges = int(reduced_graph.get_edge_count_by_edge_type_name('chembl_to_sars_cov_2')/2 * 50)\n",
    "np.random.shuffle(neg_bp_edges)\n",
    "neg_bp_edges = neg_bp_edges[:num_neg_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4391acf9f00f4e91a04677665f664d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='computing embeddings', max=10.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc83678942614a26b78f94db94ac3afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='edge embeddings', max=4.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec5e47bf0784a08b91e2a32841944d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='models', max=4.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a47d54eda7fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mrankings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_embedding_method\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_prediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             train_pred, test_pred, link_prediction_ranking = link_prediction_model(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mholdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0medge_embedding_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_embedding_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;31m#   not to any other argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;31m# - setting the SavedModel saving spec.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_out_first_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_split_out_first_arg\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   2980\u001b[0m           'The first argument to `Layer.call` must always be passed.')\n\u001b[1;32m   2981\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": [
    "# make holdouts\n",
    "from tqdm.auto import trange, tqdm\n",
    "from embiggen import EdgeTransformer, GraphTransformer, LinkPredictionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plot = False\n",
    "\n",
    "link_prediction_models = [\n",
    "    mlp, \n",
    "    logistic_regression,\n",
    "    random_forest,\n",
    "    decision_tree\n",
    "]\n",
    "\n",
    "rankings = {}\n",
    "results = []\n",
    "\n",
    "for holdout in trange(7, desc=\"computing embeddings\"): # TODO: increase holdout to 15-20\n",
    "    \n",
    "    pos_training, pos_validation = reduced_graph.connected_holdout(\n",
    "        train_size=train_percentage, \n",
    "        edge_types=['chembl_to_sars_cov_2'],\n",
    "        random_state=seed + holdout)\n",
    "    \n",
    "    # pos_training.enable_fast_walk()\n",
    "    embedding = compute_skipgram_embedding(pos_training, holdout)\n",
    "            \n",
    "    for edge_embedding_method in tqdm(EdgeTransformer.methods,\n",
    "                                      desc=\"edge embeddings\",\n",
    "                                      leave=False):\n",
    "        rankings[edge_embedding_method] = rankings.get(edge_embedding_method, {})\n",
    "\n",
    "        graph_transformer = GraphTransformer(method=edge_embedding_method)\n",
    "        graph_transformer.fit(embedding)\n",
    "        graph_test_X = graph_transformer.transform(pos_validation)\n",
    "\n",
    "        transformer = LinkPredictionTransformer(method=edge_embedding_method)\n",
    "        transformer.fit(embedding)\n",
    "        \n",
    "        neg_bp_train, neg_bp_test = train_test_split(neg_bp_edges,\n",
    "                                                     test_size=1-train_percentage,\n",
    "                                                     random_state=seed + holdout)\n",
    "        \n",
    "        train_X, train_y = transformer.transform(\n",
    "            positive_graph=pos_training.filter(edge_types=['chembl_to_sars_cov_2']), \n",
    "            negative_graph=neg_bp_train,\n",
    "            random_state=seed + holdout\n",
    "        )\n",
    "        test_X, test_y = transformer.transform(\n",
    "            positive_graph=pos_validation.filter(edge_types=['chembl_to_sars_cov_2']),\n",
    "            negative_graph=neg_bp_test,\n",
    "            random_state=seed + holdout\n",
    "        )\n",
    "\n",
    "        if plot:\n",
    "            make_pca_scatter_plot(train_X, train_y, test_X, test_y, edge_embedding_method)\n",
    "            \n",
    "        for link_prediction_model in tqdm(link_prediction_models, desc=\"models\", leave=False):\n",
    "            rankings[edge_embedding_method][link_prediction_model.name] = \\\n",
    "                rankings[edge_embedding_method].get(link_prediction_model.name, [])            \n",
    "\n",
    "            train_pred, test_pred, link_prediction_ranking = link_prediction_model(\n",
    "                holdout=holdout,\n",
    "                edge_embedding_method=edge_embedding_method,\n",
    "                embedding_model='SkipGram',\n",
    "                train_X=train_X,\n",
    "                train_y=train_y,\n",
    "                test_X=test_X,\n",
    "                graph_test_X=graph_test_X,\n",
    "                edges=pos_validation.get_edge_names()\n",
    "            )\n",
    "            rankings[edge_embedding_method][link_prediction_model.__name__].append(link_prediction_ranking)\n",
    "            \n",
    "            for run, true, predictions in (\n",
    "                (\"train\", train_y, train_pred),\n",
    "                (\"test\", test_y, test_pred)\n",
    "            ):\n",
    "                results.append({\n",
    "                    \"run\": run,\n",
    "                    \"model\": link_prediction_model.__name__,\n",
    "                    \"edge_embedding_method\": edge_embedding_method,\n",
    "                    \"holdout_number\": holdout,\n",
    "                    **get_metrics_report(true, predictions)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f0058f477847ba85ffe11eab6ff228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Rendering barplots', layout=Layout(flex='2'), max=7.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from barplots import barplots\n",
    "\n",
    "results_pd = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def sort_bars(df:pd.DataFrame)->pd.DataFrame:\n",
    "    return df.sort_values([\"model\", \"run\"], ascending=[True, False])\n",
    "\n",
    "custom_defaults={\n",
    "    \"Decision Tree\": \"decision_tree_cached\",\n",
    "    \"Logistic Regression\": \"logistic_regression_cached\",\n",
    "    \"Random Forest\": \"random_forest_cached\"\n",
    "}\n",
    "\n",
    "figures = barplots(\n",
    "    results_pd.drop(columns=[\"holdout_number\"]),\n",
    "    groupby=[\"edge_embedding_method\",  \"model\", \"run\"],\n",
    "    sort_bars=sort_bars,\n",
    "    subplots=True,\n",
    "    show_legend=False,\n",
    "    orientation=\"horizontal\",\n",
    "    # height=4,\n",
    "    # bar_width=0.15,\n",
    "    # space_width=0.1,\n",
    "    # legend_position=\"lower right\",\n",
    "    custom_defaults=custom_defaults,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do link prediction on reduced_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduced_graph_embedding = compute_skipgram_embedding(reduced_graph, -100)\n",
    "reduced_graph_embedding.to_csv(os.path.join(embedding_data_dir, \"SkipGram\", \"reduced_graph.csv.gz\"),\n",
    "                               compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import AUC, Recall, Precision\n",
    "from typing import Tuple\n",
    "\n",
    "def mlp_link_pred(shape: Tuple) -> Sequential:\n",
    "    \"\"\"Return random forest predictions on the given values.\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    Lorem ipsum\n",
    "\n",
    "    Returns\n",
    "    ----------------------\n",
    "    MLP model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(64, activation=\"linear\"),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation=\"relu\"),\n",
    "        Dropout(0.2),        \n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(64, activation=\"linear\"),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation=\"relu\"),\n",
    "        Dropout(0.3),        \n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(32, activation=\"linear\"),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation=\"relu\"), \n",
    "        Dropout(0.4),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(32, activation=\"linear\"),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation=\"relu\"),         \n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"nadam\",\n",
    "        metrics=[\n",
    "            AUC(curve=\"PR\", name=\"auprc\"),\n",
    "            AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "            Recall(name=\"Recall\"),\n",
    "            Precision(name=\"Precision\"),            \n",
    "            \"accuracy\"\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 36,993\n",
      "Trainable params: 36,609\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from embiggen import LinkPredictionSequence\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "\n",
    "best_edge_method = \"average\"\n",
    "\n",
    "link_prediction_seq = LinkPredictionSequence(\n",
    "    graph=reduced_graph,\n",
    "    embedding=reduced_graph_embedding,\n",
    "    method=best_edge_method,\n",
    "    batches_per_epoch=2**10,\n",
    "    batch_size=2**12,\n",
    "    negative_samples=2,\n",
    "    support_mirror_strategy=True,\n",
    "    aligned_node_mapping=True,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "strategy = MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    mlp = mlp_link_pred(\n",
    "        shape=(100,)\n",
    "    )\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2901 - auprc: 0.9035 - auroc: 0.9298 - Recall: 0.8055 - Precision: 0.8514 - accuracy: 0.8882\n",
      "Epoch 2/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2636 - auprc: 0.9178 - auroc: 0.9372 - Recall: 0.8286 - Precision: 0.8609 - accuracy: 0.8982\n",
      "Epoch 3/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2597 - auprc: 0.9200 - auroc: 0.9382 - Recall: 0.8313 - Precision: 0.8625 - accuracy: 0.8996\n",
      "Epoch 4/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2577 - auprc: 0.9213 - auroc: 0.9388 - Recall: 0.8350 - Precision: 0.8617 - accuracy: 0.9003\n",
      "Epoch 5/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2560 - auprc: 0.9223 - auroc: 0.9394 - Recall: 0.8353 - Precision: 0.8631 - accuracy: 0.9009\n",
      "Epoch 6/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2552 - auprc: 0.9228 - auroc: 0.9399 - Recall: 0.8385 - Precision: 0.8618 - accuracy: 0.9013\n",
      "Epoch 7/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2543 - auprc: 0.9234 - auroc: 0.9403 - Recall: 0.8388 - Precision: 0.8625 - accuracy: 0.9017\n",
      "Epoch 8/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2542 - auprc: 0.9234 - auroc: 0.9403 - Recall: 0.8397 - Precision: 0.8618 - accuracy: 0.9016\n",
      "Epoch 9/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2534 - auprc: 0.9239 - auroc: 0.9406 - Recall: 0.8407 - Precision: 0.8618 - accuracy: 0.9019\n",
      "Epoch 10/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2529 - auprc: 0.9242 - auroc: 0.9408 - Recall: 0.8406 - Precision: 0.8623 - accuracy: 0.9021\n",
      "Epoch 11/1000\n",
      "1024/1024 [==============================] - 21s 20ms/step - loss: 0.2527 - auprc: 0.9243 - auroc: 0.9410 - Recall: 0.8416 - Precision: 0.8620 - accuracy: 0.9022\n",
      "Epoch 12/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2523 - auprc: 0.9245 - auroc: 0.9411 - Recall: 0.8415 - Precision: 0.8623 - accuracy: 0.9023\n",
      "Epoch 13/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2519 - auprc: 0.9248 - auroc: 0.9414 - Recall: 0.8420 - Precision: 0.8625 - accuracy: 0.9025\n",
      "Epoch 14/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2517 - auprc: 0.9249 - auroc: 0.9414 - Recall: 0.8416 - Precision: 0.8628 - accuracy: 0.9025\n",
      "Epoch 15/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2515 - auprc: 0.9250 - auroc: 0.9415 - Recall: 0.8433 - Precision: 0.8619 - accuracy: 0.9027\n",
      "Epoch 16/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2514 - auprc: 0.9250 - auroc: 0.9415 - Recall: 0.8418 - Precision: 0.8630 - accuracy: 0.9027\n",
      "Epoch 17/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2512 - auprc: 0.9252 - auroc: 0.9416 - Recall: 0.8420 - Precision: 0.8631 - accuracy: 0.9028\n",
      "Epoch 18/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2511 - auprc: 0.9253 - auroc: 0.9417 - Recall: 0.8423 - Precision: 0.8627 - accuracy: 0.9027\n",
      "Epoch 19/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2510 - auprc: 0.9253 - auroc: 0.9418 - Recall: 0.8434 - Precision: 0.8621 - accuracy: 0.9028\n",
      "Epoch 20/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2507 - auprc: 0.9255 - auroc: 0.9419 - Recall: 0.8437 - Precision: 0.8623 - accuracy: 0.9030\n",
      "Epoch 21/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2505 - auprc: 0.9256 - auroc: 0.9421 - Recall: 0.8436 - Precision: 0.8625 - accuracy: 0.9030\n",
      "Epoch 22/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2506 - auprc: 0.9255 - auroc: 0.9420 - Recall: 0.8432 - Precision: 0.8625 - accuracy: 0.9029\n",
      "Epoch 23/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2503 - auprc: 0.9258 - auroc: 0.9422 - Recall: 0.8436 - Precision: 0.8628 - accuracy: 0.9031\n",
      "Epoch 24/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2502 - auprc: 0.9258 - auroc: 0.9422 - Recall: 0.8429 - Precision: 0.8634 - accuracy: 0.9031\n",
      "Epoch 25/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2500 - auprc: 0.9259 - auroc: 0.9424 - Recall: 0.8444 - Precision: 0.8623 - accuracy: 0.9031\n",
      "Epoch 26/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2499 - auprc: 0.9260 - auroc: 0.9425 - Recall: 0.8439 - Precision: 0.8630 - accuracy: 0.9033\n",
      "Epoch 27/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2499 - auprc: 0.9260 - auroc: 0.9425 - Recall: 0.8440 - Precision: 0.8630 - accuracy: 0.9033\n",
      "Epoch 28/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2500 - auprc: 0.9260 - auroc: 0.9425 - Recall: 0.8434 - Precision: 0.8630 - accuracy: 0.9031\n",
      "Epoch 29/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2496 - auprc: 0.9262 - auroc: 0.9427 - Recall: 0.8445 - Precision: 0.8629 - accuracy: 0.9034\n",
      "Epoch 30/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2494 - auprc: 0.9264 - auroc: 0.9430 - Recall: 0.8451 - Precision: 0.8627 - accuracy: 0.9035\n",
      "Epoch 31/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2494 - auprc: 0.9265 - auroc: 0.9431 - Recall: 0.8454 - Precision: 0.8626 - accuracy: 0.9035\n",
      "Epoch 32/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2492 - auprc: 0.9266 - auroc: 0.9432 - Recall: 0.8451 - Precision: 0.8630 - accuracy: 0.9036\n",
      "Epoch 33/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2491 - auprc: 0.9267 - auroc: 0.9434 - Recall: 0.8453 - Precision: 0.8630 - accuracy: 0.9036\n",
      "Epoch 34/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2491 - auprc: 0.9267 - auroc: 0.9434 - Recall: 0.8448 - Precision: 0.8631 - accuracy: 0.9035\n",
      "Epoch 35/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2490 - auprc: 0.9268 - auroc: 0.9436 - Recall: 0.8444 - Precision: 0.8633 - accuracy: 0.9035\n",
      "Epoch 36/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2489 - auprc: 0.9269 - auroc: 0.9438 - Recall: 0.8456 - Precision: 0.8627 - accuracy: 0.9036\n",
      "Epoch 37/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2488 - auprc: 0.9270 - auroc: 0.9439 - Recall: 0.8447 - Precision: 0.8635 - accuracy: 0.9037\n",
      "Epoch 38/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2485 - auprc: 0.9272 - auroc: 0.9441 - Recall: 0.8453 - Precision: 0.8631 - accuracy: 0.9037\n",
      "Epoch 39/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2485 - auprc: 0.9272 - auroc: 0.9442 - Recall: 0.8453 - Precision: 0.8634 - accuracy: 0.9038\n",
      "Epoch 40/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2484 - auprc: 0.9273 - auroc: 0.9444 - Recall: 0.8441 - Precision: 0.8642 - accuracy: 0.9038\n",
      "Epoch 41/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2483 - auprc: 0.9274 - auroc: 0.9444 - Recall: 0.8461 - Precision: 0.8629 - accuracy: 0.9039\n",
      "Epoch 42/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2482 - auprc: 0.9275 - auroc: 0.9445 - Recall: 0.8469 - Precision: 0.8622 - accuracy: 0.9038\n",
      "Epoch 43/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2483 - auprc: 0.9275 - auroc: 0.9446 - Recall: 0.8456 - Precision: 0.8633 - accuracy: 0.9039\n",
      "Epoch 44/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2480 - auprc: 0.9277 - auroc: 0.9447 - Recall: 0.8460 - Precision: 0.8632 - accuracy: 0.9040\n",
      "Epoch 45/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2479 - auprc: 0.9277 - auroc: 0.9448 - Recall: 0.8456 - Precision: 0.8636 - accuracy: 0.9040\n",
      "Epoch 46/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2478 - auprc: 0.9278 - auroc: 0.9449 - Recall: 0.8458 - Precision: 0.8638 - accuracy: 0.9041\n",
      "Epoch 47/1000\n",
      "1024/1024 [==============================] - 19s 18ms/step - loss: 0.2480 - auprc: 0.9277 - auroc: 0.9448 - Recall: 0.8455 - Precision: 0.8635 - accuracy: 0.9039\n",
      "Epoch 48/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2477 - auprc: 0.9279 - auroc: 0.9450 - Recall: 0.8467 - Precision: 0.8631 - accuracy: 0.9041\n",
      "Epoch 49/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2477 - auprc: 0.9279 - auroc: 0.9450 - Recall: 0.8461 - Precision: 0.8636 - accuracy: 0.9041\n",
      "Epoch 50/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2476 - auprc: 0.9280 - auroc: 0.9451 - Recall: 0.8478 - Precision: 0.8626 - accuracy: 0.9042\n",
      "Epoch 51/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2475 - auprc: 0.9280 - auroc: 0.9452 - Recall: 0.8469 - Precision: 0.8632 - accuracy: 0.9042\n",
      "Epoch 52/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2475 - auprc: 0.9280 - auroc: 0.9453 - Recall: 0.8474 - Precision: 0.8626 - accuracy: 0.9041\n",
      "Epoch 53/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2474 - auprc: 0.9281 - auroc: 0.9454 - Recall: 0.8473 - Precision: 0.8633 - accuracy: 0.9043\n",
      "Epoch 54/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2473 - auprc: 0.9282 - auroc: 0.9454 - Recall: 0.8480 - Precision: 0.8627 - accuracy: 0.9043\n",
      "Epoch 55/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2472 - auprc: 0.9283 - auroc: 0.9455 - Recall: 0.8486 - Precision: 0.8625 - accuracy: 0.9044\n",
      "Epoch 56/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2472 - auprc: 0.9283 - auroc: 0.9455 - Recall: 0.8481 - Precision: 0.8628 - accuracy: 0.9043\n",
      "Epoch 57/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2472 - auprc: 0.9283 - auroc: 0.9456 - Recall: 0.8487 - Precision: 0.8623 - accuracy: 0.9043\n",
      "Epoch 58/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2471 - auprc: 0.9284 - auroc: 0.9456 - Recall: 0.8479 - Precision: 0.8627 - accuracy: 0.9043\n",
      "Epoch 59/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2470 - auprc: 0.9284 - auroc: 0.9457 - Recall: 0.8488 - Precision: 0.8625 - accuracy: 0.9044\n",
      "Epoch 60/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2469 - auprc: 0.9285 - auroc: 0.9458 - Recall: 0.8490 - Precision: 0.8624 - accuracy: 0.9045\n",
      "Epoch 61/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2470 - auprc: 0.9284 - auroc: 0.9457 - Recall: 0.8494 - Precision: 0.8618 - accuracy: 0.9044\n",
      "Epoch 62/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2468 - auprc: 0.9286 - auroc: 0.9458 - Recall: 0.8492 - Precision: 0.8626 - accuracy: 0.9046\n",
      "Epoch 63/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2467 - auprc: 0.9286 - auroc: 0.9458 - Recall: 0.8489 - Precision: 0.8628 - accuracy: 0.9046\n",
      "Epoch 64/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2467 - auprc: 0.9286 - auroc: 0.9459 - Recall: 0.8495 - Precision: 0.8626 - accuracy: 0.9047\n",
      "Epoch 65/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2468 - auprc: 0.9286 - auroc: 0.9459 - Recall: 0.8490 - Precision: 0.8627 - accuracy: 0.9046\n",
      "Epoch 66/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2465 - auprc: 0.9287 - auroc: 0.9460 - Recall: 0.8490 - Precision: 0.8630 - accuracy: 0.9047\n",
      "Epoch 67/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2467 - auprc: 0.9286 - auroc: 0.9460 - Recall: 0.8492 - Precision: 0.8626 - accuracy: 0.9046\n",
      "Epoch 68/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2467 - auprc: 0.9287 - auroc: 0.9460 - Recall: 0.8499 - Precision: 0.8621 - accuracy: 0.9046\n",
      "Epoch 69/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2466 - auprc: 0.9287 - auroc: 0.9460 - Recall: 0.8498 - Precision: 0.8621 - accuracy: 0.9046\n",
      "Epoch 70/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2465 - auprc: 0.9288 - auroc: 0.9461 - Recall: 0.8507 - Precision: 0.8618 - accuracy: 0.9047\n",
      "Epoch 71/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2465 - auprc: 0.9288 - auroc: 0.9461 - Recall: 0.8498 - Precision: 0.8625 - accuracy: 0.9047\n",
      "Epoch 72/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2465 - auprc: 0.9288 - auroc: 0.9461 - Recall: 0.8495 - Precision: 0.8626 - accuracy: 0.9047\n",
      "Epoch 73/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2463 - auprc: 0.9289 - auroc: 0.9462 - Recall: 0.8502 - Precision: 0.8623 - accuracy: 0.9048\n",
      "Epoch 74/1000\n",
      "1024/1024 [==============================] - 21s 21ms/step - loss: 0.2463 - auprc: 0.9289 - auroc: 0.9462 - Recall: 0.8507 - Precision: 0.8620 - accuracy: 0.9048\n",
      "Epoch 75/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2462 - auprc: 0.9289 - auroc: 0.9462 - Recall: 0.8506 - Precision: 0.8623 - accuracy: 0.9049\n",
      "Epoch 76/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2462 - auprc: 0.9290 - auroc: 0.9463 - Recall: 0.8516 - Precision: 0.8613 - accuracy: 0.9048\n",
      "Epoch 77/1000\n",
      "1024/1024 [==============================] - 21s 20ms/step - loss: 0.2461 - auprc: 0.9290 - auroc: 0.9463 - Recall: 0.8498 - Precision: 0.8629 - accuracy: 0.9049\n",
      "Epoch 78/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2460 - auprc: 0.9290 - auroc: 0.9464 - Recall: 0.8506 - Precision: 0.8625 - accuracy: 0.9049\n",
      "Epoch 79/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2460 - auprc: 0.9291 - auroc: 0.9464 - Recall: 0.8509 - Precision: 0.8621 - accuracy: 0.9049\n",
      "Epoch 80/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2459 - auprc: 0.9291 - auroc: 0.9464 - Recall: 0.8519 - Precision: 0.8617 - accuracy: 0.9050\n",
      "Epoch 81/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2458 - auprc: 0.9292 - auroc: 0.9465 - Recall: 0.8521 - Precision: 0.8614 - accuracy: 0.9050\n",
      "Epoch 82/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2459 - auprc: 0.9291 - auroc: 0.9465 - Recall: 0.8501 - Precision: 0.8627 - accuracy: 0.9049\n",
      "Epoch 83/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2459 - auprc: 0.9292 - auroc: 0.9465 - Recall: 0.8512 - Precision: 0.8623 - accuracy: 0.9050\n",
      "Epoch 84/1000\n",
      "1024/1024 [==============================] - 21s 20ms/step - loss: 0.2458 - auprc: 0.9292 - auroc: 0.9465 - Recall: 0.8512 - Precision: 0.8624 - accuracy: 0.9051\n",
      "Epoch 85/1000\n",
      "1024/1024 [==============================] - 21s 20ms/step - loss: 0.2457 - auprc: 0.9292 - auroc: 0.9465 - Recall: 0.8517 - Precision: 0.8621 - accuracy: 0.9051\n",
      "Epoch 86/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2457 - auprc: 0.9293 - auroc: 0.9465 - Recall: 0.8519 - Precision: 0.8619 - accuracy: 0.9051\n",
      "Epoch 87/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2456 - auprc: 0.9293 - auroc: 0.9466 - Recall: 0.8517 - Precision: 0.8622 - accuracy: 0.9051\n",
      "Epoch 88/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2457 - auprc: 0.9292 - auroc: 0.9465 - Recall: 0.8521 - Precision: 0.8617 - accuracy: 0.9051\n",
      "Epoch 89/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2456 - auprc: 0.9293 - auroc: 0.9466 - Recall: 0.8516 - Precision: 0.8621 - accuracy: 0.9051\n",
      "Epoch 90/1000\n",
      "1024/1024 [==============================] - 21s 20ms/step - loss: 0.2457 - auprc: 0.9292 - auroc: 0.9466 - Recall: 0.8514 - Precision: 0.8623 - accuracy: 0.9051\n",
      "Epoch 91/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2455 - auprc: 0.9294 - auroc: 0.9467 - Recall: 0.8511 - Precision: 0.8627 - accuracy: 0.9052\n",
      "Epoch 92/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2455 - auprc: 0.9294 - auroc: 0.9467 - Recall: 0.8513 - Precision: 0.8625 - accuracy: 0.9052\n",
      "Epoch 93/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2455 - auprc: 0.9294 - auroc: 0.9467 - Recall: 0.8515 - Precision: 0.8625 - accuracy: 0.9052\n",
      "Epoch 94/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2454 - auprc: 0.9295 - auroc: 0.9467 - Recall: 0.8519 - Precision: 0.8626 - accuracy: 0.9054\n",
      "Epoch 95/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2454 - auprc: 0.9295 - auroc: 0.9468 - Recall: 0.8516 - Precision: 0.8627 - accuracy: 0.9053\n",
      "Epoch 96/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2453 - auprc: 0.9295 - auroc: 0.9468 - Recall: 0.8520 - Precision: 0.8625 - accuracy: 0.9053\n",
      "Epoch 97/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2452 - auprc: 0.9295 - auroc: 0.9468 - Recall: 0.8522 - Precision: 0.8622 - accuracy: 0.9053\n",
      "Epoch 98/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2453 - auprc: 0.9295 - auroc: 0.9468 - Recall: 0.8522 - Precision: 0.8622 - accuracy: 0.9053\n",
      "Epoch 99/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2452 - auprc: 0.9296 - auroc: 0.9468 - Recall: 0.8520 - Precision: 0.8625 - accuracy: 0.9053\n",
      "Epoch 100/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2453 - auprc: 0.9295 - auroc: 0.9468 - Recall: 0.8527 - Precision: 0.8620 - accuracy: 0.9054\n",
      "Epoch 101/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2453 - auprc: 0.9295 - auroc: 0.9469 - Recall: 0.8531 - Precision: 0.8616 - accuracy: 0.9053\n",
      "Epoch 102/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2452 - auprc: 0.9296 - auroc: 0.9469 - Recall: 0.8518 - Precision: 0.8626 - accuracy: 0.9053\n",
      "Epoch 103/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2454 - auprc: 0.9295 - auroc: 0.9468 - Recall: 0.8519 - Precision: 0.8626 - accuracy: 0.9053\n",
      "Epoch 104/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2452 - auprc: 0.9296 - auroc: 0.9469 - Recall: 0.8527 - Precision: 0.8621 - accuracy: 0.9054\n",
      "Epoch 105/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2452 - auprc: 0.9296 - auroc: 0.9469 - Recall: 0.8524 - Precision: 0.8622 - accuracy: 0.9054\n",
      "Epoch 106/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2450 - auprc: 0.9297 - auroc: 0.9470 - Recall: 0.8529 - Precision: 0.8623 - accuracy: 0.9055\n",
      "Epoch 107/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2451 - auprc: 0.9296 - auroc: 0.9469 - Recall: 0.8528 - Precision: 0.8620 - accuracy: 0.9054\n",
      "Epoch 108/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2452 - auprc: 0.9296 - auroc: 0.9469 - Recall: 0.8526 - Precision: 0.8622 - accuracy: 0.9054\n",
      "Epoch 109/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2449 - auprc: 0.9297 - auroc: 0.9470 - Recall: 0.8528 - Precision: 0.8622 - accuracy: 0.9055\n",
      "Epoch 110/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2449 - auprc: 0.9298 - auroc: 0.9470 - Recall: 0.8531 - Precision: 0.8621 - accuracy: 0.9055\n",
      "Epoch 111/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2449 - auprc: 0.9297 - auroc: 0.9470 - Recall: 0.8518 - Precision: 0.8629 - accuracy: 0.9055\n",
      "Epoch 112/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2449 - auprc: 0.9298 - auroc: 0.9470 - Recall: 0.8522 - Precision: 0.8629 - accuracy: 0.9056\n",
      "Epoch 113/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2448 - auprc: 0.9298 - auroc: 0.9470 - Recall: 0.8523 - Precision: 0.8627 - accuracy: 0.9055\n",
      "Epoch 114/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2449 - auprc: 0.9297 - auroc: 0.9470 - Recall: 0.8523 - Precision: 0.8626 - accuracy: 0.9055\n",
      "Epoch 115/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2447 - auprc: 0.9299 - auroc: 0.9471 - Recall: 0.8520 - Precision: 0.8631 - accuracy: 0.9056\n",
      "Epoch 116/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2448 - auprc: 0.9298 - auroc: 0.9471 - Recall: 0.8524 - Precision: 0.8624 - accuracy: 0.9054\n",
      "Epoch 117/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2447 - auprc: 0.9298 - auroc: 0.9471 - Recall: 0.8530 - Precision: 0.8623 - accuracy: 0.9055\n",
      "Epoch 118/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2447 - auprc: 0.9299 - auroc: 0.9471 - Recall: 0.8517 - Precision: 0.8634 - accuracy: 0.9056\n",
      "Epoch 119/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2447 - auprc: 0.9299 - auroc: 0.9471 - Recall: 0.8525 - Precision: 0.8627 - accuracy: 0.9056\n",
      "Epoch 120/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2447 - auprc: 0.9299 - auroc: 0.9471 - Recall: 0.8522 - Precision: 0.8632 - accuracy: 0.9057\n",
      "Epoch 121/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2447 - auprc: 0.9298 - auroc: 0.9471 - Recall: 0.8533 - Precision: 0.8620 - accuracy: 0.9055\n",
      "Epoch 122/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2446 - auprc: 0.9299 - auroc: 0.9471 - Recall: 0.8526 - Precision: 0.8629 - accuracy: 0.9057\n",
      "Epoch 123/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2445 - auprc: 0.9300 - auroc: 0.9472 - Recall: 0.8524 - Precision: 0.8632 - accuracy: 0.9057\n",
      "Epoch 124/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2445 - auprc: 0.9300 - auroc: 0.9472 - Recall: 0.8524 - Precision: 0.8633 - accuracy: 0.9057\n",
      "Epoch 125/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2446 - auprc: 0.9299 - auroc: 0.9472 - Recall: 0.8521 - Precision: 0.8633 - accuracy: 0.9057\n",
      "Epoch 126/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2445 - auprc: 0.9300 - auroc: 0.9472 - Recall: 0.8528 - Precision: 0.8627 - accuracy: 0.9057\n",
      "Epoch 127/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2445 - auprc: 0.9300 - auroc: 0.9472 - Recall: 0.8530 - Precision: 0.8625 - accuracy: 0.9056\n",
      "Epoch 128/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2446 - auprc: 0.9299 - auroc: 0.9471 - Recall: 0.8521 - Precision: 0.8632 - accuracy: 0.9056\n",
      "Epoch 129/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2444 - auprc: 0.9300 - auroc: 0.9472 - Recall: 0.8538 - Precision: 0.8622 - accuracy: 0.9057\n",
      "Epoch 130/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2445 - auprc: 0.9300 - auroc: 0.9472 - Recall: 0.8535 - Precision: 0.8623 - accuracy: 0.9057\n",
      "Epoch 131/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2444 - auprc: 0.9300 - auroc: 0.9473 - Recall: 0.8529 - Precision: 0.8630 - accuracy: 0.9058\n",
      "Epoch 132/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2443 - auprc: 0.9300 - auroc: 0.9472 - Recall: 0.8520 - Precision: 0.8636 - accuracy: 0.9057\n",
      "Epoch 133/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2443 - auprc: 0.9301 - auroc: 0.9473 - Recall: 0.8528 - Precision: 0.8632 - accuracy: 0.9058\n",
      "Epoch 134/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2443 - auprc: 0.9301 - auroc: 0.9473 - Recall: 0.8526 - Precision: 0.8632 - accuracy: 0.9058\n",
      "Epoch 135/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2443 - auprc: 0.9301 - auroc: 0.9473 - Recall: 0.8533 - Precision: 0.8628 - accuracy: 0.9058\n",
      "Epoch 136/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2443 - auprc: 0.9301 - auroc: 0.9473 - Recall: 0.8521 - Precision: 0.8636 - accuracy: 0.9058\n",
      "Epoch 137/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2442 - auprc: 0.9301 - auroc: 0.9473 - Recall: 0.8520 - Precision: 0.8638 - accuracy: 0.9058\n",
      "Epoch 138/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2442 - auprc: 0.9301 - auroc: 0.9473 - Recall: 0.8535 - Precision: 0.8626 - accuracy: 0.9058\n",
      "Epoch 139/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2442 - auprc: 0.9301 - auroc: 0.9473 - Recall: 0.8528 - Precision: 0.8630 - accuracy: 0.9058\n",
      "Epoch 140/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2441 - auprc: 0.9302 - auroc: 0.9474 - Recall: 0.8535 - Precision: 0.8627 - accuracy: 0.9058\n",
      "Epoch 141/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2442 - auprc: 0.9302 - auroc: 0.9474 - Recall: 0.8531 - Precision: 0.8630 - accuracy: 0.9058\n",
      "Epoch 142/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2441 - auprc: 0.9302 - auroc: 0.9474 - Recall: 0.8534 - Precision: 0.8628 - accuracy: 0.9059\n",
      "Epoch 143/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2441 - auprc: 0.9302 - auroc: 0.9473 - Recall: 0.8536 - Precision: 0.8628 - accuracy: 0.9059\n",
      "Epoch 144/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2441 - auprc: 0.9302 - auroc: 0.9474 - Recall: 0.8539 - Precision: 0.8626 - accuracy: 0.9059\n",
      "Epoch 145/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2442 - auprc: 0.9302 - auroc: 0.9474 - Recall: 0.8523 - Precision: 0.8635 - accuracy: 0.9058\n",
      "Epoch 146/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2440 - auprc: 0.9303 - auroc: 0.9474 - Recall: 0.8533 - Precision: 0.8632 - accuracy: 0.9060\n",
      "Epoch 147/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2440 - auprc: 0.9303 - auroc: 0.9475 - Recall: 0.8528 - Precision: 0.8636 - accuracy: 0.9060\n",
      "Epoch 148/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2440 - auprc: 0.9303 - auroc: 0.9474 - Recall: 0.8526 - Precision: 0.8636 - accuracy: 0.9059\n",
      "Epoch 149/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2440 - auprc: 0.9303 - auroc: 0.9474 - Recall: 0.8534 - Precision: 0.8631 - accuracy: 0.9060\n",
      "Epoch 150/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2439 - auprc: 0.9303 - auroc: 0.9474 - Recall: 0.8535 - Precision: 0.8631 - accuracy: 0.9060\n",
      "Epoch 151/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2440 - auprc: 0.9302 - auroc: 0.9474 - Recall: 0.8533 - Precision: 0.8632 - accuracy: 0.9060\n",
      "Epoch 152/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2439 - auprc: 0.9303 - auroc: 0.9475 - Recall: 0.8531 - Precision: 0.8634 - accuracy: 0.9060\n",
      "Epoch 153/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2439 - auprc: 0.9303 - auroc: 0.9474 - Recall: 0.8534 - Precision: 0.8633 - accuracy: 0.9061\n",
      "Epoch 154/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2439 - auprc: 0.9303 - auroc: 0.9474 - Recall: 0.8539 - Precision: 0.8629 - accuracy: 0.9060\n",
      "Epoch 155/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2438 - auprc: 0.9303 - auroc: 0.9475 - Recall: 0.8533 - Precision: 0.8634 - accuracy: 0.9061\n",
      "Epoch 156/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2439 - auprc: 0.9303 - auroc: 0.9474 - Recall: 0.8526 - Precision: 0.8639 - accuracy: 0.9060\n",
      "Epoch 157/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2439 - auprc: 0.9303 - auroc: 0.9475 - Recall: 0.8527 - Precision: 0.8637 - accuracy: 0.9060\n",
      "Epoch 158/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2437 - auprc: 0.9304 - auroc: 0.9475 - Recall: 0.8534 - Precision: 0.8636 - accuracy: 0.9061\n",
      "Epoch 159/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2438 - auprc: 0.9303 - auroc: 0.9475 - Recall: 0.8541 - Precision: 0.8629 - accuracy: 0.9061\n",
      "Epoch 160/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2438 - auprc: 0.9304 - auroc: 0.9475 - Recall: 0.8543 - Precision: 0.8628 - accuracy: 0.9061\n",
      "Epoch 161/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2437 - auprc: 0.9304 - auroc: 0.9475 - Recall: 0.8527 - Precision: 0.8640 - accuracy: 0.9061\n",
      "Epoch 162/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2437 - auprc: 0.9304 - auroc: 0.9475 - Recall: 0.8533 - Precision: 0.8635 - accuracy: 0.9061\n",
      "Epoch 163/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2437 - auprc: 0.9304 - auroc: 0.9475 - Recall: 0.8530 - Precision: 0.8640 - accuracy: 0.9062\n",
      "Epoch 164/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2437 - auprc: 0.9303 - auroc: 0.9475 - Recall: 0.8541 - Precision: 0.8630 - accuracy: 0.9061\n",
      "Epoch 165/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8540 - Precision: 0.8633 - accuracy: 0.9062\n",
      "Epoch 166/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2436 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8532 - Precision: 0.8638 - accuracy: 0.9062\n",
      "Epoch 167/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2437 - auprc: 0.9304 - auroc: 0.9475 - Recall: 0.8529 - Precision: 0.8638 - accuracy: 0.9061\n",
      "Epoch 168/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2436 - auprc: 0.9304 - auroc: 0.9475 - Recall: 0.8532 - Precision: 0.8636 - accuracy: 0.9061\n",
      "Epoch 169/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8538 - Precision: 0.8635 - accuracy: 0.9062\n",
      "Epoch 170/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8534 - Precision: 0.8637 - accuracy: 0.9062\n",
      "Epoch 171/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2436 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8531 - Precision: 0.8638 - accuracy: 0.9061\n",
      "Epoch 172/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8536 - Precision: 0.8636 - accuracy: 0.9062\n",
      "Epoch 173/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8542 - Precision: 0.8634 - accuracy: 0.9063\n",
      "Epoch 174/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8533 - Precision: 0.8640 - accuracy: 0.9063\n",
      "Epoch 175/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8536 - Precision: 0.8637 - accuracy: 0.9062\n",
      "Epoch 176/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2434 - auprc: 0.9306 - auroc: 0.9476 - Recall: 0.8546 - Precision: 0.8630 - accuracy: 0.9063\n",
      "Epoch 177/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2435 - auprc: 0.9305 - auroc: 0.9476 - Recall: 0.8533 - Precision: 0.8636 - accuracy: 0.9061\n",
      "Epoch 178/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2434 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8532 - Precision: 0.8640 - accuracy: 0.9063\n",
      "Epoch 179/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2434 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8537 - Precision: 0.8638 - accuracy: 0.9063\n",
      "Epoch 180/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2434 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8538 - Precision: 0.8636 - accuracy: 0.9063\n",
      "Epoch 181/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2433 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8536 - Precision: 0.8638 - accuracy: 0.9063\n",
      "Epoch 182/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2434 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8535 - Precision: 0.8639 - accuracy: 0.9063\n",
      "Epoch 183/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2433 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8536 - Precision: 0.8639 - accuracy: 0.9063\n",
      "Epoch 184/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2434 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8526 - Precision: 0.8643 - accuracy: 0.9062\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2433 - auprc: 0.9307 - auroc: 0.9477 - Recall: 0.8539 - Precision: 0.8636 - accuracy: 0.9063\n",
      "Epoch 186/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2433 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8543 - Precision: 0.8636 - accuracy: 0.9064\n",
      "Epoch 187/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2433 - auprc: 0.9307 - auroc: 0.9477 - Recall: 0.8535 - Precision: 0.8641 - accuracy: 0.9064\n",
      "Epoch 188/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8551 - Precision: 0.8632 - accuracy: 0.9065\n",
      "Epoch 189/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2432 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8542 - Precision: 0.8633 - accuracy: 0.9063\n",
      "Epoch 190/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8540 - Precision: 0.8638 - accuracy: 0.9064\n",
      "Epoch 191/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2432 - auprc: 0.9306 - auroc: 0.9477 - Recall: 0.8540 - Precision: 0.8637 - accuracy: 0.9064\n",
      "Epoch 192/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8546 - Precision: 0.8636 - accuracy: 0.9065\n",
      "Epoch 193/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8548 - Precision: 0.8630 - accuracy: 0.9063\n",
      "Epoch 194/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8555 - Precision: 0.8628 - accuracy: 0.9064\n",
      "Epoch 195/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2430 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8544 - Precision: 0.8636 - accuracy: 0.9064\n",
      "Epoch 196/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8542 - Precision: 0.8636 - accuracy: 0.9064\n",
      "Epoch 197/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2432 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8547 - Precision: 0.8634 - accuracy: 0.9064\n",
      "Epoch 198/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8549 - Precision: 0.8632 - accuracy: 0.9064\n",
      "Epoch 199/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2432 - auprc: 0.9307 - auroc: 0.9477 - Recall: 0.8543 - Precision: 0.8635 - accuracy: 0.9064\n",
      "Epoch 200/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8556 - Precision: 0.8628 - accuracy: 0.9065\n",
      "Epoch 201/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8539 - Precision: 0.8638 - accuracy: 0.9064\n",
      "Epoch 202/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8545 - Precision: 0.8637 - accuracy: 0.9065\n",
      "Epoch 203/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8545 - Precision: 0.8634 - accuracy: 0.9064\n",
      "Epoch 204/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8547 - Precision: 0.8635 - accuracy: 0.9065\n",
      "Epoch 205/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2431 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8545 - Precision: 0.8637 - accuracy: 0.9065\n",
      "Epoch 206/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2430 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8548 - Precision: 0.8634 - accuracy: 0.9064\n",
      "Epoch 207/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2430 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8548 - Precision: 0.8633 - accuracy: 0.9064\n",
      "Epoch 208/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2430 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8551 - Precision: 0.8632 - accuracy: 0.9065\n",
      "Epoch 209/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8550 - Precision: 0.8633 - accuracy: 0.9065\n",
      "Epoch 210/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2430 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8553 - Precision: 0.8631 - accuracy: 0.9065\n",
      "Epoch 211/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2431 - auprc: 0.9307 - auroc: 0.9478 - Recall: 0.8547 - Precision: 0.8632 - accuracy: 0.9064\n",
      "Epoch 212/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2430 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8543 - Precision: 0.8638 - accuracy: 0.9065\n",
      "Epoch 213/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2429 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8556 - Precision: 0.8630 - accuracy: 0.9065\n",
      "Epoch 214/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2430 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8548 - Precision: 0.8635 - accuracy: 0.9065\n",
      "Epoch 215/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2429 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8550 - Precision: 0.8635 - accuracy: 0.9065\n",
      "Epoch 216/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2429 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8557 - Precision: 0.8630 - accuracy: 0.9066\n",
      "Epoch 217/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2429 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8536 - Precision: 0.8643 - accuracy: 0.9065\n",
      "Epoch 218/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8551 - Precision: 0.8634 - accuracy: 0.9065\n",
      "Epoch 219/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2429 - auprc: 0.9308 - auroc: 0.9479 - Recall: 0.8543 - Precision: 0.8640 - accuracy: 0.9065\n",
      "Epoch 220/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2429 - auprc: 0.9308 - auroc: 0.9478 - Recall: 0.8540 - Precision: 0.8640 - accuracy: 0.9065\n",
      "Epoch 221/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8545 - Precision: 0.8641 - accuracy: 0.9067\n",
      "Epoch 222/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9308 - auroc: 0.9479 - Recall: 0.8547 - Precision: 0.8634 - accuracy: 0.9064\n",
      "Epoch 223/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8544 - Precision: 0.8637 - accuracy: 0.9065\n",
      "Epoch 224/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2427 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8548 - Precision: 0.8639 - accuracy: 0.9067\n",
      "Epoch 225/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8542 - Precision: 0.8641 - accuracy: 0.9066\n",
      "Epoch 226/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8545 - Precision: 0.8640 - accuracy: 0.9066\n",
      "Epoch 227/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8543 - Precision: 0.8641 - accuracy: 0.9066\n",
      "Epoch 228/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2427 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8551 - Precision: 0.8635 - accuracy: 0.9066\n",
      "Epoch 229/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2426 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8546 - Precision: 0.8642 - accuracy: 0.9067\n",
      "Epoch 230/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2426 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8550 - Precision: 0.8640 - accuracy: 0.9068\n",
      "Epoch 231/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8542 - Precision: 0.8643 - accuracy: 0.9066\n",
      "Epoch 232/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2427 - auprc: 0.9310 - auroc: 0.9479 - Recall: 0.8556 - Precision: 0.8632 - accuracy: 0.9066\n",
      "Epoch 233/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2426 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8553 - Precision: 0.8636 - accuracy: 0.9067\n",
      "Epoch 234/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2426 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8551 - Precision: 0.8636 - accuracy: 0.9067\n",
      "Epoch 235/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8564 - Precision: 0.8630 - accuracy: 0.9068\n",
      "Epoch 236/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2426 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8557 - Precision: 0.8633 - accuracy: 0.9067\n",
      "Epoch 237/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8555 - Precision: 0.8636 - accuracy: 0.9067\n",
      "Epoch 238/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8555 - Precision: 0.8636 - accuracy: 0.9068\n",
      "Epoch 239/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2426 - auprc: 0.9310 - auroc: 0.9479 - Recall: 0.8559 - Precision: 0.8631 - accuracy: 0.9067\n",
      "Epoch 240/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8558 - Precision: 0.8633 - accuracy: 0.9067\n",
      "Epoch 241/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2424 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8557 - Precision: 0.8633 - accuracy: 0.9067\n",
      "Epoch 242/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8552 - Precision: 0.8635 - accuracy: 0.9066\n",
      "Epoch 243/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2424 - auprc: 0.9311 - auroc: 0.9480 - Recall: 0.8562 - Precision: 0.8630 - accuracy: 0.9067\n",
      "Epoch 244/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2425 - auprc: 0.9311 - auroc: 0.9480 - Recall: 0.8553 - Precision: 0.8636 - accuracy: 0.9067\n",
      "Epoch 245/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2423 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8555 - Precision: 0.8636 - accuracy: 0.9068\n",
      "Epoch 246/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8564 - Precision: 0.8630 - accuracy: 0.9068\n",
      "Epoch 247/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9481 - Recall: 0.8552 - Precision: 0.8638 - accuracy: 0.9067\n",
      "Epoch 248/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2424 - auprc: 0.9311 - auroc: 0.9480 - Recall: 0.8551 - Precision: 0.8637 - accuracy: 0.9067\n",
      "Epoch 249/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2423 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8554 - Precision: 0.8638 - accuracy: 0.9068\n",
      "Epoch 250/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2423 - auprc: 0.9312 - auroc: 0.9481 - Recall: 0.8554 - Precision: 0.8639 - accuracy: 0.9069\n",
      "Epoch 251/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2424 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8553 - Precision: 0.8640 - accuracy: 0.9068\n",
      "Epoch 252/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2424 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8561 - Precision: 0.8632 - accuracy: 0.9068\n",
      "Epoch 253/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2422 - auprc: 0.9312 - auroc: 0.9481 - Recall: 0.8556 - Precision: 0.8639 - accuracy: 0.9069\n",
      "Epoch 254/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2424 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8553 - Precision: 0.8640 - accuracy: 0.9068\n",
      "Epoch 255/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2428 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8551 - Precision: 0.8635 - accuracy: 0.9066\n",
      "Epoch 256/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2429 - auprc: 0.9309 - auroc: 0.9479 - Recall: 0.8548 - Precision: 0.8636 - accuracy: 0.9065\n",
      "Epoch 257/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2427 - auprc: 0.9310 - auroc: 0.9479 - Recall: 0.8552 - Precision: 0.8636 - accuracy: 0.9067\n",
      "Epoch 258/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2426 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8545 - Precision: 0.8641 - accuracy: 0.9067\n",
      "Epoch 259/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2425 - auprc: 0.9310 - auroc: 0.9480 - Recall: 0.8557 - Precision: 0.8635 - accuracy: 0.9068\n",
      "Epoch 260/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2423 - auprc: 0.9312 - auroc: 0.9481 - Recall: 0.8555 - Precision: 0.8637 - accuracy: 0.9068\n",
      "Epoch 261/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2423 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8564 - Precision: 0.8631 - accuracy: 0.9068\n",
      "Epoch 262/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2422 - auprc: 0.9312 - auroc: 0.9481 - Recall: 0.8554 - Precision: 0.8639 - accuracy: 0.9068\n",
      "Epoch 263/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2424 - auprc: 0.9311 - auroc: 0.9480 - Recall: 0.8560 - Precision: 0.8633 - accuracy: 0.9068\n",
      "Epoch 264/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2423 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8555 - Precision: 0.8638 - accuracy: 0.9068\n",
      "Epoch 265/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2422 - auprc: 0.9312 - auroc: 0.9482 - Recall: 0.8556 - Precision: 0.8640 - accuracy: 0.9069\n",
      "Epoch 266/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2422 - auprc: 0.9312 - auroc: 0.9481 - Recall: 0.8553 - Precision: 0.8638 - accuracy: 0.9068\n",
      "Epoch 267/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2422 - auprc: 0.9312 - auroc: 0.9481 - Recall: 0.8555 - Precision: 0.8636 - accuracy: 0.9068\n",
      "Epoch 268/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2423 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8557 - Precision: 0.8636 - accuracy: 0.9068\n",
      "Epoch 269/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2422 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8557 - Precision: 0.8637 - accuracy: 0.9069\n",
      "Epoch 270/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2423 - auprc: 0.9311 - auroc: 0.9481 - Recall: 0.8554 - Precision: 0.8640 - accuracy: 0.9069\n",
      "Epoch 271/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8560 - Precision: 0.8636 - accuracy: 0.9069\n",
      "Epoch 272/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8542 - Precision: 0.8648 - accuracy: 0.9069\n",
      "Epoch 273/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2422 - auprc: 0.9312 - auroc: 0.9482 - Recall: 0.8550 - Precision: 0.8640 - accuracy: 0.9068\n",
      "Epoch 274/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9312 - auroc: 0.9482 - Recall: 0.8552 - Precision: 0.8641 - accuracy: 0.9069\n",
      "Epoch 275/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2421 - auprc: 0.9312 - auroc: 0.9481 - Recall: 0.8557 - Precision: 0.8638 - accuracy: 0.9069\n",
      "Epoch 276/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8564 - Precision: 0.8633 - accuracy: 0.9069\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8560 - Precision: 0.8636 - accuracy: 0.9069\n",
      "Epoch 278/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9312 - auroc: 0.9482 - Recall: 0.8557 - Precision: 0.8638 - accuracy: 0.9069\n",
      "Epoch 279/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8556 - Precision: 0.8640 - accuracy: 0.9069\n",
      "Epoch 280/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9312 - auroc: 0.9482 - Recall: 0.8564 - Precision: 0.8633 - accuracy: 0.9069\n",
      "Epoch 281/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9312 - auroc: 0.9482 - Recall: 0.8562 - Precision: 0.8635 - accuracy: 0.9069\n",
      "Epoch 282/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8564 - Precision: 0.8636 - accuracy: 0.9070\n",
      "Epoch 283/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2420 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8564 - Precision: 0.8634 - accuracy: 0.9069\n",
      "Epoch 284/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2420 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8558 - Precision: 0.8639 - accuracy: 0.9070\n",
      "Epoch 285/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8541 - Precision: 0.8650 - accuracy: 0.9069\n",
      "Epoch 286/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8558 - Precision: 0.8641 - accuracy: 0.9070\n",
      "Epoch 287/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9482 - Recall: 0.8560 - Precision: 0.8641 - accuracy: 0.9071\n",
      "Epoch 288/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8555 - Precision: 0.8643 - accuracy: 0.9070\n",
      "Epoch 289/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2420 - auprc: 0.9313 - auroc: 0.9483 - Recall: 0.8555 - Precision: 0.8641 - accuracy: 0.9069\n",
      "Epoch 290/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2420 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8567 - Precision: 0.8632 - accuracy: 0.9069\n",
      "Epoch 291/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8565 - Precision: 0.8637 - accuracy: 0.9071\n",
      "Epoch 292/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8563 - Precision: 0.8637 - accuracy: 0.9070\n",
      "Epoch 293/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2420 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8557 - Precision: 0.8639 - accuracy: 0.9069\n",
      "Epoch 294/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2420 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8568 - Precision: 0.8632 - accuracy: 0.9070\n",
      "Epoch 295/1000\n",
      "1024/1024 [==============================] - 20s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9482 - Recall: 0.8560 - Precision: 0.8637 - accuracy: 0.9069\n",
      "Epoch 296/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2418 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8563 - Precision: 0.8638 - accuracy: 0.9070\n",
      "Epoch 297/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9482 - Recall: 0.8567 - Precision: 0.8636 - accuracy: 0.9071\n",
      "Epoch 298/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8568 - Precision: 0.8634 - accuracy: 0.9070\n",
      "Epoch 299/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8559 - Precision: 0.8640 - accuracy: 0.9070\n",
      "Epoch 300/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2418 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8565 - Precision: 0.8637 - accuracy: 0.9071\n",
      "Epoch 301/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8564 - Precision: 0.8634 - accuracy: 0.9069\n",
      "Epoch 302/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9482 - Recall: 0.8559 - Precision: 0.8641 - accuracy: 0.9071\n",
      "Epoch 303/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8564 - Precision: 0.8636 - accuracy: 0.9070\n",
      "Epoch 304/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8561 - Precision: 0.8640 - accuracy: 0.9071\n",
      "Epoch 305/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8563 - Precision: 0.8637 - accuracy: 0.9070\n",
      "Epoch 306/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2418 - auprc: 0.9314 - auroc: 0.9484 - Recall: 0.8568 - Precision: 0.8634 - accuracy: 0.9070\n",
      "Epoch 307/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8558 - Precision: 0.8638 - accuracy: 0.9069\n",
      "Epoch 308/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2419 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8563 - Precision: 0.8637 - accuracy: 0.9070\n",
      "Epoch 309/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2418 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8561 - Precision: 0.8642 - accuracy: 0.9072\n",
      "Epoch 310/1000\n",
      "1024/1024 [==============================] - 19s 19ms/step - loss: 0.2418 - auprc: 0.9314 - auroc: 0.9483 - Recall: 0.8570 - Precision: 0.8633 - accuracy: 0.9071\n",
      "Epoch 311/1000\n",
      "1024/1024 [==============================] - 20s 20ms/step - loss: 0.2421 - auprc: 0.9313 - auroc: 0.9482 - Recall: 0.8563 - Precision: 0.8636 - accuracy: 0.9070\n"
     ]
    }
   ],
   "source": [
    "history = mlp.fit(\n",
    "    link_prediction_seq,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=link_prediction_seq.steps_per_epoch,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor='loss',\n",
    "            min_delta=0,\n",
    "            patience=15,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_keras_history import plot_history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate all edges from drug|compounds -> positive nodes (SARS-CoV-2, COVID-19, ARDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226676</th>\n",
       "      <td>0.776691</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL343545</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226672</th>\n",
       "      <td>0.776414</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL343545</td>\n",
       "      <td>NCBITaxon:227859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277655</th>\n",
       "      <td>0.774842</td>\n",
       "      <td>CHEBI:131933</td>\n",
       "      <td>MESH:D045169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404294</th>\n",
       "      <td>0.770889</td>\n",
       "      <td>CHEBI:60193</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403265</th>\n",
       "      <td>0.769113</td>\n",
       "      <td>CHEBI:50858</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347314</th>\n",
       "      <td>0.768964</td>\n",
       "      <td>CHEBI:77386</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277654</th>\n",
       "      <td>0.768642</td>\n",
       "      <td>CHEBI:131933</td>\n",
       "      <td>NCBITaxon:2697049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362602</th>\n",
       "      <td>0.768295</td>\n",
       "      <td>CHEBI:138166</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278889</th>\n",
       "      <td>0.767370</td>\n",
       "      <td>CHEBI:85511</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367667</th>\n",
       "      <td>0.764049</td>\n",
       "      <td>CHEBI:50249</td>\n",
       "      <td>NCBITaxon:2697049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230780</th>\n",
       "      <td>0.763103</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL56731</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277652</th>\n",
       "      <td>0.762839</td>\n",
       "      <td>CHEBI:131933</td>\n",
       "      <td>NCBITaxon:227859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230252</th>\n",
       "      <td>0.759995</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL372797</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247976</th>\n",
       "      <td>0.758348</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL85251</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241508</th>\n",
       "      <td>0.757496</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL2151790</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276579</th>\n",
       "      <td>0.757437</td>\n",
       "      <td>CHEBI:36770</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263514</th>\n",
       "      <td>0.757272</td>\n",
       "      <td>CHEBI:65172</td>\n",
       "      <td>NCBITaxon:2697049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254249</th>\n",
       "      <td>0.757235</td>\n",
       "      <td>CHEBI:145550</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404504</th>\n",
       "      <td>0.756293</td>\n",
       "      <td>CHEBI:84170</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263517</th>\n",
       "      <td>0.755659</td>\n",
       "      <td>CHEBI:65172</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257623</th>\n",
       "      <td>0.754849</td>\n",
       "      <td>CHEBI:75885</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273384</th>\n",
       "      <td>0.753360</td>\n",
       "      <td>CHEBI:42191</td>\n",
       "      <td>NCBITaxon:2697049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408928</th>\n",
       "      <td>0.753356</td>\n",
       "      <td>CHEBI:35676</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233696</th>\n",
       "      <td>0.753240</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL4303664</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226946</th>\n",
       "      <td>0.752560</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL1972294</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266520</th>\n",
       "      <td>0.752542</td>\n",
       "      <td>CHEBI:41688</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277657</th>\n",
       "      <td>0.751427</td>\n",
       "      <td>CHEBI:131933</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270132</th>\n",
       "      <td>0.751162</td>\n",
       "      <td>CHEBI:32369</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358462</th>\n",
       "      <td>0.750486</td>\n",
       "      <td>CHEBI:10036</td>\n",
       "      <td>NCBITaxon:2697049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367670</th>\n",
       "      <td>0.750164</td>\n",
       "      <td>CHEBI:50249</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254039</th>\n",
       "      <td>0.749419</td>\n",
       "      <td>CHEBI:9457</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347783</th>\n",
       "      <td>0.749410</td>\n",
       "      <td>CHEBI:138429</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342694</th>\n",
       "      <td>0.748800</td>\n",
       "      <td>CHEBI:7676</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404291</th>\n",
       "      <td>0.748560</td>\n",
       "      <td>CHEBI:60193</td>\n",
       "      <td>NCBITaxon:2697049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246362</th>\n",
       "      <td>0.748387</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL2360079</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246896</th>\n",
       "      <td>0.748378</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL1255746</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279995</th>\n",
       "      <td>0.748357</td>\n",
       "      <td>CHEBI:85499</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279981</th>\n",
       "      <td>0.748042</td>\n",
       "      <td>CHEBI:85497</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357422</th>\n",
       "      <td>0.747701</td>\n",
       "      <td>CHEBI:58187</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313985</th>\n",
       "      <td>0.747627</td>\n",
       "      <td>CHEBI:18340</td>\n",
       "      <td>MESH:D045169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403237</th>\n",
       "      <td>0.747616</td>\n",
       "      <td>CHEBI:50855</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344017</th>\n",
       "      <td>0.746901</td>\n",
       "      <td>CHEBI:38070</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270129</th>\n",
       "      <td>0.746681</td>\n",
       "      <td>CHEBI:32369</td>\n",
       "      <td>NCBITaxon:2697049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258748</th>\n",
       "      <td>0.746609</td>\n",
       "      <td>CHEBI:36104</td>\n",
       "      <td>MESH:D045169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279582</th>\n",
       "      <td>0.746565</td>\n",
       "      <td>CHEBI:61528</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18002</th>\n",
       "      <td>0.746430</td>\n",
       "      <td>CHEBI:42471</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226674</th>\n",
       "      <td>0.745886</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL343545</td>\n",
       "      <td>MESH:D045169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370204</th>\n",
       "      <td>0.745837</td>\n",
       "      <td>CHEBI:15733</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340398</th>\n",
       "      <td>0.745430</td>\n",
       "      <td>CHEBI:77178</td>\n",
       "      <td>MESH:D045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264096</th>\n",
       "      <td>0.745268</td>\n",
       "      <td>CHEBI:16100</td>\n",
       "      <td>MESH:D045169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred                        subject             object\n",
       "226676  0.776691   CHEMBL.COMPOUND:CHEMBL343545       MESH:D045473\n",
       "226672  0.776414   CHEMBL.COMPOUND:CHEMBL343545   NCBITaxon:227859\n",
       "277655  0.774842                   CHEBI:131933       MESH:D045169\n",
       "404294  0.770889                    CHEBI:60193       MESH:D045473\n",
       "403265  0.769113                    CHEBI:50858       MESH:D045473\n",
       "347314  0.768964                    CHEBI:77386       MESH:D045473\n",
       "277654  0.768642                   CHEBI:131933  NCBITaxon:2697049\n",
       "362602  0.768295                   CHEBI:138166       MESH:D045473\n",
       "278889  0.767370                    CHEBI:85511       MESH:D045473\n",
       "367667  0.764049                    CHEBI:50249  NCBITaxon:2697049\n",
       "230780  0.763103    CHEMBL.COMPOUND:CHEMBL56731       MESH:D045473\n",
       "277652  0.762839                   CHEBI:131933   NCBITaxon:227859\n",
       "230252  0.759995   CHEMBL.COMPOUND:CHEMBL372797       MESH:D045473\n",
       "247976  0.758348    CHEMBL.COMPOUND:CHEMBL85251       MESH:D045473\n",
       "241508  0.757496  CHEMBL.COMPOUND:CHEMBL2151790       MESH:D045473\n",
       "276579  0.757437                    CHEBI:36770       MESH:D045473\n",
       "263514  0.757272                    CHEBI:65172  NCBITaxon:2697049\n",
       "254249  0.757235                   CHEBI:145550       MESH:D045473\n",
       "404504  0.756293                    CHEBI:84170       MESH:D045473\n",
       "263517  0.755659                    CHEBI:65172       MESH:D045473\n",
       "257623  0.754849                    CHEBI:75885       MESH:D045473\n",
       "273384  0.753360                    CHEBI:42191  NCBITaxon:2697049\n",
       "408928  0.753356                    CHEBI:35676       MESH:D045473\n",
       "233696  0.753240  CHEMBL.COMPOUND:CHEMBL4303664       MESH:D045473\n",
       "226946  0.752560  CHEMBL.COMPOUND:CHEMBL1972294       MESH:D045473\n",
       "266520  0.752542                    CHEBI:41688       MESH:D045473\n",
       "277657  0.751427                   CHEBI:131933       MESH:D045473\n",
       "270132  0.751162                    CHEBI:32369       MESH:D045473\n",
       "358462  0.750486                    CHEBI:10036  NCBITaxon:2697049\n",
       "367670  0.750164                    CHEBI:50249       MESH:D045473\n",
       "254039  0.749419                     CHEBI:9457       MESH:D045473\n",
       "347783  0.749410                   CHEBI:138429       MESH:D045473\n",
       "342694  0.748800                     CHEBI:7676       MESH:D045473\n",
       "404291  0.748560                    CHEBI:60193  NCBITaxon:2697049\n",
       "246362  0.748387  CHEMBL.COMPOUND:CHEMBL2360079       MESH:D045473\n",
       "246896  0.748378  CHEMBL.COMPOUND:CHEMBL1255746       MESH:D045473\n",
       "279995  0.748357                    CHEBI:85499       MESH:D045473\n",
       "279981  0.748042                    CHEBI:85497       MESH:D045473\n",
       "357422  0.747701                    CHEBI:58187       MESH:D045473\n",
       "313985  0.747627                    CHEBI:18340       MESH:D045169\n",
       "403237  0.747616                    CHEBI:50855       MESH:D045473\n",
       "344017  0.746901                    CHEBI:38070       MESH:D045473\n",
       "270129  0.746681                    CHEBI:32369  NCBITaxon:2697049\n",
       "258748  0.746609                    CHEBI:36104       MESH:D045169\n",
       "279582  0.746565                    CHEBI:61528       MESH:D045473\n",
       "18002   0.746430                    CHEBI:42471       MESH:D045473\n",
       "226674  0.745886   CHEMBL.COMPOUND:CHEMBL343545       MESH:D045169\n",
       "370204  0.745837                    CHEBI:15733       MESH:D045473\n",
       "340398  0.745430                    CHEBI:77178       MESH:D045473\n",
       "264096  0.745268                    CHEBI:16100       MESH:D045169"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these BP graph edges are the ones we want to evaluate\n",
    "edges_to_eval = np.array(reduced_graph.get_bipartite_edge_names(\n",
    "    removed_existing_edges=True,\n",
    "    first_node_types_set=set(nodes_of_interest),\n",
    "    second_nodes_set=set(positive_nodes.curie)\n",
    "))\n",
    "\n",
    "edge_transform = GraphTransformer(best_edge_method)\n",
    "edge_transform.fit(reduced_graph_embedding)\n",
    "edges_to_eval_emb = edge_transform.transform(edges_to_eval)\n",
    "\n",
    "edges_to_eval_predict = mlp.predict(edges_to_eval_emb, batch_size=1048)\n",
    "\n",
    "edges_to_eval_predict_sorted = pd.DataFrame({\n",
    "    \"pred\": edges_to_eval_predict.flatten(),\n",
    "    \"subject\": edges_to_eval[:,0],\n",
    "    \"object\": edges_to_eval[:,1]\n",
    "}).sort_values(by=[\"pred\"], ascending=False)\n",
    "\n",
    "edges_to_eval_predict_sorted[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(edges_to_eval_predict_sorted[\"pred\"], bins=500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  see what a BP graph with random edges looks like\n",
    "from random import shuffle\n",
    "nodes = reduced_graph.get_node_names()\n",
    "shuffle(nodes)\n",
    "random_nodes_left = nodes[0:500]\n",
    "random_nodes_right = nodes[501:507]\n",
    "\n",
    "random_edges_to_eval = np.array(reduced_graph.get_bipartite_edge_names(\n",
    "    removed_existing_edges=True,\n",
    "    first_nodes_set=set(random_nodes_left),\n",
    "    second_nodes_set=set(random_nodes_right)\n",
    "))\n",
    "\n",
    "random_edge_transform = GraphTransformer(best_edge_method)\n",
    "random_edge_transform.fit(reduced_graph_embedding)\n",
    "random_edges_to_eval_emb = edge_transform.transform(random_edges_to_eval)\n",
    "\n",
    "random_edges_to_eval_predict = mlp.predict(random_edges_to_eval_emb, batch_size=1048)\n",
    "\n",
    "plt.hist(random_edges_to_eval_predict, bins=500);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model, history, and ranked drug list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# edges_to_eval_predict_sorted = pd.read_csv(\n",
    "#     os.path.join(mlp_link_pred_outdir, \"mlp_link_pred_ranked_drug_compound_list.csv\"),\n",
    "#     index_col=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtr4v/PycharmProjects/kg_covid_19_drug_analyses/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (6,7,8,10,11,12,13,14,15,16,17,18,20,21,24,25,26,27,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>subject</th>\n",
       "      <th>name_x</th>\n",
       "      <th>object</th>\n",
       "      <th>name_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776691</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL343545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESH:D045473</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776414</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL343545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCBITaxon:227859</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774842</td>\n",
       "      <td>CHEBI:131933</td>\n",
       "      <td>(-)-DCA-CL(1-)</td>\n",
       "      <td>MESH:D045169</td>\n",
       "      <td>(-)-DCA-CL(1-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770889</td>\n",
       "      <td>CHEBI:60193</td>\n",
       "      <td>queuosine</td>\n",
       "      <td>MESH:D045473</td>\n",
       "      <td>queuosine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.769113</td>\n",
       "      <td>CHEBI:50858</td>\n",
       "      <td>corticosteroid</td>\n",
       "      <td>MESH:D045473</td>\n",
       "      <td>corticosteroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410955</th>\n",
       "      <td>0.018630</td>\n",
       "      <td>ttd.drug:D06WUE</td>\n",
       "      <td>2,5-dichloro-N-p-tolylthiophene-3-sulfonamide</td>\n",
       "      <td>MESH:D045473</td>\n",
       "      <td>2,5-dichloro-N-p-tolylthiophene-3-sulfonamide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410956</th>\n",
       "      <td>0.018516</td>\n",
       "      <td>ttd.drug:D0M0ZX</td>\n",
       "      <td>6-ethyl-3-(2-ethylbutoxycarbonyl)-4-quinolone</td>\n",
       "      <td>MESH:D045473</td>\n",
       "      <td>6-ethyl-3-(2-ethylbutoxycarbonyl)-4-quinolone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410957</th>\n",
       "      <td>0.017998</td>\n",
       "      <td>ttd.drug:D02OZK</td>\n",
       "      <td>Obatoclax</td>\n",
       "      <td>MESH:D045473</td>\n",
       "      <td>Obatoclax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410958</th>\n",
       "      <td>0.017590</td>\n",
       "      <td>ttd.drug:D0I2RB</td>\n",
       "      <td>ONO-4641</td>\n",
       "      <td>MESH:D012128</td>\n",
       "      <td>ONO-4641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410959</th>\n",
       "      <td>0.015704</td>\n",
       "      <td>ttd.drug:D0Y1YZ</td>\n",
       "      <td>4-(2-Imidazol-1-yl-ethoxy)-benzamide</td>\n",
       "      <td>MESH:D045473</td>\n",
       "      <td>4-(2-Imidazol-1-yl-ethoxy)-benzamide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410960 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred                       subject  \\\n",
       "0       0.776691  CHEMBL.COMPOUND:CHEMBL343545   \n",
       "1       0.776414  CHEMBL.COMPOUND:CHEMBL343545   \n",
       "2       0.774842                  CHEBI:131933   \n",
       "3       0.770889                   CHEBI:60193   \n",
       "4       0.769113                   CHEBI:50858   \n",
       "...          ...                           ...   \n",
       "410955  0.018630               ttd.drug:D06WUE   \n",
       "410956  0.018516               ttd.drug:D0M0ZX   \n",
       "410957  0.017998               ttd.drug:D02OZK   \n",
       "410958  0.017590               ttd.drug:D0I2RB   \n",
       "410959  0.015704               ttd.drug:D0Y1YZ   \n",
       "\n",
       "                                               name_x            object  \\\n",
       "0                                                 NaN      MESH:D045473   \n",
       "1                                                 NaN  NCBITaxon:227859   \n",
       "2                                      (-)-DCA-CL(1-)      MESH:D045169   \n",
       "3                                           queuosine      MESH:D045473   \n",
       "4                                      corticosteroid      MESH:D045473   \n",
       "...                                               ...               ...   \n",
       "410955  2,5-dichloro-N-p-tolylthiophene-3-sulfonamide      MESH:D045473   \n",
       "410956  6-ethyl-3-(2-ethylbutoxycarbonyl)-4-quinolone      MESH:D045473   \n",
       "410957                                      Obatoclax      MESH:D045473   \n",
       "410958                                       ONO-4641      MESH:D012128   \n",
       "410959           4-(2-Imidazol-1-yl-ethoxy)-benzamide      MESH:D045473   \n",
       "\n",
       "                                               name_y  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                      (-)-DCA-CL(1-)  \n",
       "3                                           queuosine  \n",
       "4                                      corticosteroid  \n",
       "...                                               ...  \n",
       "410955  2,5-dichloro-N-p-tolylthiophene-3-sulfonamide  \n",
       "410956  6-ethyl-3-(2-ethylbutoxycarbonyl)-4-quinolone  \n",
       "410957                                      Obatoclax  \n",
       "410958                                       ONO-4641  \n",
       "410959           4-(2-Imidazol-1-yl-ethoxy)-benzamide  \n",
       "\n",
       "[410960 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add drug names and categories\n",
    "nodes_info = pd.read_csv(nodes_file, sep=\"\\t\").filter(['id', 'name', 'category'])\n",
    "edges_to_eval_predict_sorted = pd.merge(edges_to_eval_predict_sorted, nodes_info, how='left', left_on='subject', right_on='id').drop(labels=['id'], axis=1)\n",
    "edges_to_eval_predict_sorted = edges_to_eval_predict_sorted[['pred', 'subject', 'name', 'category', 'object']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add positive node names\n",
    "edges_to_eval_predict_sorted = \\\n",
    "    pd.merge(edges_to_eval_predict_sorted, positive_nodes, how='left', left_on='object', right_on='curie').drop(labels=['curie'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save(\n",
    "    os.path.join(mlp_link_pred_outdir, \"mlp_link_pred.h5\")\n",
    ")\n",
    "pd.DataFrame(history).to_csv(\n",
    "    os.path.join(mlp_link_pred_outdir, \"mlp_link_pred.history.csv\")\n",
    ")\n",
    "edges_to_eval_predict_sorted.to_csv(\n",
    "    os.path.join(mlp_link_pred_outdir, \"mlp_link_pred_ranked_drug_compound_list.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Upload the base_dl_dir (results, and cache stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"s3cmd put --recursive --acl-public --cf-invalidate {base_dl_dir} {s3_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
