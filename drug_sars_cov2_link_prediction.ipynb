{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying classifiers to make drug predictions\n",
    "\n",
    "Here we apply embeddings generated in the NB:\n",
    "`Graph embedding using SkipGram 20201012 homogeneous graph training.ipynb`\n",
    "md5 hash: 261f9f7b0137263728c292a1a878d7baf3f875f3\n",
    "\n",
    "that were used to generate link classifiers in this NB:\n",
    "`Link prediction 20201012 homogeneous graph.ipynb`\n",
    "md5 hash 3a13cb16b3db2a53917f7d25e16313b0fb3d411d\n",
    "\n",
    "kg-covid-19:\n",
    "version 20201012\n",
    "\n",
    "ensmallen-graph\n",
    "Version: 0.4.4 # upgraded from 0.4.3 for an update vers that has get_edge_id() and a few other methods. Otherwise 0.4.3 and 0.4.4 should be the same\n",
    "\n",
    "embiggen\n",
    "Version: 0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "w2v = \"SkipGram\"\n",
    "exp_name = \"80_20_kg_covid_19_20201012_training_test_epoch_500_delta_0.0001\"\n",
    "s3_path = \"s3://kg-hub-public-data/embeddings/20201012/\"  # keep trailing slash\n",
    "\n",
    "base_dl_dir = \"downloaded_data\"\n",
    "graph_data_dir = os.path.join(base_dl_dir, \"kg-covid-19-20201012\")\n",
    "embedding_data_dir = os.path.join(base_dl_dir, \"embeddings-20201012\")\n",
    "classifier_data_dir = os.path.join(base_dl_dir, \"classifiers-20201012\")\n",
    "\n",
    "# graph stuff\n",
    "graph_out_file = os.path.join(graph_data_dir + \"/kg-covid-19.tar.gz\")\n",
    "nodes_file = os.path.join(graph_data_dir, \"merged-kg_nodes.tsv\")\n",
    "edges_file = os.path.join(graph_data_dir, \"merged-kg_edges.tsv\")\n",
    "sorted_edges_file = os.path.join(graph_data_dir, \"merged-kg_edges_SORTED.tsv\")\n",
    "graph_tar_url = \"https://kg-hub.berkeleybop.io/kg-covid-19/20201012/kg-covid-19.tar.gz\"\n",
    "\n",
    "# embeddings URLs\n",
    "base_kghub_url = \"http://kg-hub.berkeleybop.io/\"\n",
    "embeddings_url = os.path.join(base_kghub_url, \"embeddings/20201012/SkipGram_80_20_kg_covid_19_20201012_training_test_epoch_500_delta_0.0001_embedding.npy\")\n",
    "embedding_file = os.path.join(embedding_data_dir, \"SkipGram_embedding.npy\")\n",
    "\n",
    "# classifier URLs\n",
    "classifier_base_url = \"http://kg-hub.berkeleybop.io/embeddings/20201012/SkipGram_80_20_kg_covid_19_20201012_training_test_epoch_500_delta_0.0001_\"\n",
    "classifier_edge_models_to_use = 'average'\n",
    "classifier_edge_models = ['average', 'hadamard', 'weightedL1', 'weightedL2']\n",
    "classifier_suffix = '_finalized_model.h5'\n",
    "classifier_urls = [f\"{classifier_base_url}{m}{classifier_suffix}\" for m in classifier_edge_models]\n",
    "classifier_files = [f\"{classifier_data_dir}/{w2v}_{exp_name}{m}{classifier_suffix}\" for m in classifier_edge_models]\n",
    "\n",
    "# params\n",
    "seed = 42\n",
    "train_percentage = 0.8\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pkg_resources import get_distribution\n",
    "assert(get_distribution(\"ensmallen-graph\").version == '0.4.4')  # upgraded from 0.4.3 for an update vers that has get_edge_id() and other methods\n",
    "assert(get_distribution(\"embiggen\").version == '0.6.0')\n",
    "assert(get_distribution(\"tensorflow\").version == '2.3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto # Import needed to avoid TensorFlow warnings and general useless infos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the graphs, if necessary\n",
    "\n",
    "import urllib\n",
    "import os\n",
    "os.makedirs(graph_data_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(nodes_file) or not os.path.exists(edges_file):\n",
    "    with urllib.request.urlopen(graph_tar_url) as response, \\\n",
    "        open(graph_out_file, 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)\n",
    "    os.system(\"tar -xvzf \" + graph_out_file + \" -C \" + graph_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 ms, sys: 2.07 ms, total: 3.98 ms\n",
      "Wall time: 6.92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "if not os.path.exists(sorted_edges_file):\n",
    "    graph = EnsmallenGraph.from_unsorted_csv(\n",
    "        edge_path = edges_file,\n",
    "        sources_column=\"subject\",\n",
    "        destinations_column=\"object\",\n",
    "        directed=False,\n",
    "        node_path = nodes_file,\n",
    "        nodes_column = 'id',\n",
    "        node_types_column = 'category',\n",
    "        default_node_type = 'biolink:NamedThing'\n",
    "    )\n",
    "\n",
    "    graph.dump_edges(sorted_edges_file,\n",
    "        sources_column=\"subject\",\n",
    "        destinations_column=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_loops_number': '480',\n",
       " 'directed': 'false',\n",
       " 'has_edge_types': 'false',\n",
       " 'self_loops_rate': '0.000015373068830289457',\n",
       " 'degree_mean': '69.73158748096104',\n",
       " 'unique_node_types_number': '42',\n",
       " 'edges_number': '31223434',\n",
       " 'has_weights': 'false',\n",
       " 'has_node_types': 'true',\n",
       " 'singletons': '8355',\n",
       " 'density': '0.010673045865565448',\n",
       " 'unique_edge_types_number': '0',\n",
       " 'nodes_number': '447766'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "graph = EnsmallenGraph.from_sorted_csv(\n",
    "    edge_path = sorted_edges_file,\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    nodes_number=500000,  # should be = or > than actual number\n",
    "    edges_number=42949369,   # same ^\n",
    "    node_path = nodes_file,\n",
    "    nodes_column = 'id',\n",
    "    node_types_column = 'category',\n",
    "    default_node_type = 'biolink:NamedThing'\n",
    ")\n",
    "\n",
    "graph.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make same holdouts as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.5 s, sys: 350 ms, total: 40.9 s\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pos_training, pos_validation = graph.connected_holdout(train_size=train_percentage, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings are check that are not necessary, but are offered as sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 11s, sys: 5.91 s, total: 21min 17s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coherence_check=True\n",
    "if coherence_check:\n",
    "    assert graph.contains(pos_training)\n",
    "    assert graph.contains(pos_validation)\n",
    "    assert (pos_training | pos_validation).contains(graph)\n",
    "    assert graph.contains(pos_training | pos_validation)\n",
    "    assert not pos_training.overlaps(pos_validation)\n",
    "    assert not pos_validation.overlaps(pos_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(embedding_data_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(embedding_file):\n",
    "    with urllib.request.urlopen(embeddings_url) as response, \\\n",
    "        open(embedding_file, 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = np.load(embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More coherence checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pos_training.get_nodes_reverse_mapping()) == len(embeddings)\n",
    "assert len(pos_training.get_node_types()) == len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_curies = list(np.array(pos_training.get_nodes_reverse_mapping()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_cov_2_curie = 'NCBITaxon:2697049'\n",
    "sars_cov_2_idx = node_curies.index(sars_cov_2_curie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_idx = list(np.where(pos_training.get_node_types() == pos_training.get_node_types_reverse_mapping().index('biolink:Drug'))[0])\n",
    "drug_names = [node_curies[i] for i in drug_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_substance_idx = list(np.where(pos_training.get_node_types() == pos_training.get_node_types_reverse_mapping().index('biolink:ChemicalSubstance'))[0])\n",
    "chem_substance_names = [node_curies[i] for i in chem_substance_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chembl_prefix = 'CHEMBL.COMPOUND'\n",
    "chembl_names = [x for x in node_curies if (re.compile(chembl_prefix).search(x))]\n",
    "chembl_idx = [index for index, x in enumerate(node_curies) if (re.compile(chembl_prefix).search(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading trained MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(classifier_data_dir, exist_ok=True)\n",
    "\n",
    "for i, url in enumerate(classifier_urls):\n",
    "    with urllib.request.urlopen(url) as response, \\\n",
    "        open(os.path.join(classifier_files[i]), 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mlp_model = (classifier_edge_models_to_use,\n",
    "             tf.keras.models.load_model(\n",
    "                 classifier_files[classifier_edge_models.index(classifier_edge_models_to_use)]\n",
    "             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_cov_2_emb = embeddings[sars_cov_2_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using average model for edge embeddings\n"
     ]
    }
   ],
   "source": [
    "print(f\"using %s model for edge embeddings\" % mlp_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__and__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__ror__',\n",
       " '__rsub__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__xor__',\n",
       " 'adamic_adar_index',\n",
       " 'complete_walks',\n",
       " 'connected_components_number',\n",
       " 'connected_holdout',\n",
       " 'contains',\n",
       " 'cooccurence_matrix',\n",
       " 'degree',\n",
       " 'degrees',\n",
       " 'degrees_mean',\n",
       " 'degrees_median',\n",
       " 'degrees_mode',\n",
       " 'degrees_product',\n",
       " 'disable_fast_walk',\n",
       " 'drop_edge_types',\n",
       " 'drop_node_types',\n",
       " 'drop_weights',\n",
       " 'dump_edges',\n",
       " 'dump_nodes',\n",
       " 'edge_types_subgraph',\n",
       " 'enable_fast_walk',\n",
       " 'from_sorted_csv',\n",
       " 'from_unsorted_csv',\n",
       " 'get_dense_node_mapping',\n",
       " 'get_destination_names',\n",
       " 'get_destinations',\n",
       " 'get_edge_id',\n",
       " 'get_edge_id_string',\n",
       " 'get_edge_type',\n",
       " 'get_edge_type_counts',\n",
       " 'get_edge_types',\n",
       " 'get_edge_types_number',\n",
       " 'get_edge_types_reverse_mapping',\n",
       " 'get_edges_number',\n",
       " 'get_node_id',\n",
       " 'get_node_name',\n",
       " 'get_node_type',\n",
       " 'get_node_type_counts',\n",
       " 'get_node_types',\n",
       " 'get_node_types_number',\n",
       " 'get_node_types_reverse_mapping',\n",
       " 'get_nodes_mapping',\n",
       " 'get_nodes_number',\n",
       " 'get_nodes_reverse_mapping',\n",
       " 'get_selfloops_number',\n",
       " 'get_selfloops_rate',\n",
       " 'get_source_names',\n",
       " 'get_source_nodes_number',\n",
       " 'get_sources',\n",
       " 'get_weights',\n",
       " 'has_edge',\n",
       " 'has_edge_string',\n",
       " 'has_edge_types',\n",
       " 'has_node_types',\n",
       " 'has_selfloops',\n",
       " 'has_weights',\n",
       " 'is_edge_trap',\n",
       " 'is_node_trap',\n",
       " 'jaccard_index',\n",
       " 'link_prediction',\n",
       " 'node2vec',\n",
       " 'overlaps',\n",
       " 'random_holdout',\n",
       " 'random_subgraph',\n",
       " 'random_walks',\n",
       " 'report',\n",
       " 'resource_allocation_index',\n",
       " 'sample_negatives',\n",
       " 'set_all_edge_types',\n",
       " 'strongly_connected_components',\n",
       " 'traps_rate']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen import GraphTransformer, EdgeTransformer\n",
    "\n",
    "assert(mlp_model[0] in EdgeTransformer.methods)\n",
    "\n",
    "transformer = GraphTransformer(mlp_model[0]) # pass edge embedding method, which is mlp_model[0]\n",
    "transformer.fit(embeddings)\n",
    "train_edges = transformer.transform(pos_training)\n",
    "assert(pos_training.get_edges_number() == len(train_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's try to predict a link that should exist in training graph\n",
    "# example SARS-CoV-2 -> ChEMBL compound edge (which should bge positive)\n",
    "example_chembl_edge = train_edges[pos_training.get_edge_id(sars_cov_2_idx, chembl_idx[0])]\n",
    "example_chembl_edge.shape\n",
    "example_chembl_edge.__class__\n",
    "mlp_model[1].predict(example_chembl_edge.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare source (drugs) and destination (SARS-CoV-2) numpy arrays\n",
    "import logging\n",
    "import numpy as np\n",
    "drug_idx_wo_exist_links = []\n",
    "for drug_id in drug_idx:\n",
    "    if not pos_training.has_edge(drug_id, sars_cov_2_idx) and not pos_training.has_edge(sars_cov_2_idx, drug_id):\n",
    "        drug_idx_wo_exist_links.append(drug_id)\n",
    "    else:\n",
    "        logging.warning(\"Not using edge %s %s which was present in training graph\" % (drug_id, sars_cov_2_idx))\n",
    "drug_idx_wo_exist_links = np.asarray(drug_idx_wo_exist_links)\n",
    "sars_cov_2_dest = np.repeat(sars_cov_2_idx, len(drug_idx_wo_exist_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an edge transformer for drug -> SARS-CoV-2 edge for every member of drug_idx\n",
    "\n",
    "from embiggen import GraphTransformer, EdgeTransformer\n",
    "assert(mlp_model[0] in EdgeTransformer.methods)\n",
    "\n",
    "edge_transformer = EdgeTransformer(mlp_model[0]) # pass edge embedding method, which is mlp_model[0]\n",
    "assert(drug_idx_wo_exist_links.shape == sars_cov_2_dest.shape)\n",
    "edge_transformer.fit(embeddings)\n",
    "drug_edges = edge_transformer.transform(sources=drug_idx_wo_exist_links, destinations=sars_cov_2_dest)\n",
    "assert(len(drug_idx_wo_exist_links) == len(drug_edges))\n",
    "\n",
    "drug_prediction_pval = mlp_model[1].predict(drug_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(drug_prediction_pval, density=False, bins=30)  # `density=False` would make counts\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('pval');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(drug_prediction_pval, axis=0)[::-1]\n",
    "\n",
    "with open(\"drug_sars_cov2_link_prediction.tsv\", \"w\") as out:\n",
    "    out.write(\"graph_id\\tCURIE\\tpval\\n\")\n",
    "    for idx in np.nditer(sort_idx, order='F'):\n",
    "        line = f\"%i    %s     %f\\n\" % (drug_idx_wo_exist_links[idx],\n",
    "                        pos_training.get_nodes_reverse_mapping()[drug_idx_wo_exist_links[idx]],\n",
    "                        drug_prediction_pval[idx])\n",
    "        print(line)\n",
    "        out.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
