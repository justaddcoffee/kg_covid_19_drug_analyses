{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embedding using SkipGram\n",
    "\n",
    "This is an embedding of the whole graph, no training and validation split and all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jtr4v/kg_covid_19_drug_analyses', '/home/jtr4v/anaconda3/lib/python38.zip', '/home/jtr4v/anaconda3/lib/python3.8', '/home/jtr4v/anaconda3/lib/python3.8/lib-dynload', '', '/home/jtr4v/anaconda3/lib/python3.8/site-packages', '/home/jtr4v/anaconda3/lib/python3.8/site-packages/IPython/extensions', '/home/jtr4v/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto # Import needed to avoid TensorFlow warnings and general useless infos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the graphs\n",
    "We load the ppi graph from the repository as an undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "os.makedirs(\"whole_graph\", exist_ok=True)\n",
    "if not os.path.exists(\"whole_graph/kg-covid-19-skipgram-aug-2020.tar.gz\"):\n",
    "    with urllib.request.urlopen(\"https://zenodo.org/record/4011267/files/kg-covid-19-skipgram-aug-2020.tar.gz\") as response, \\\n",
    "        open(\"graph/kg-covid-19-skipgram-aug-2020.tar.gz\", 'wb') as out_file:\n",
    "            data = response.read()  # a `bytes` object\n",
    "            out_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"tar -xvzf whole_graph/kg-covid-19-skipgram-aug-2020.tar.gz -C whole_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "graph = EnsmallenGraph.from_csv(\n",
    "    edge_path=\"whole_graph/merged-kg_edges.tsv\",\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    default_edge_type=\"biolink:association\",\n",
    "    node_path=\"whole_graph/merged-kg_nodes.tsv\",\n",
    "    nodes_column=\"id\",\n",
    "    node_types_column=\"category\",\n",
    "    default_node_type=\"biolink:NamedThing\",\n",
    "    ignore_duplicated_edges=True,\n",
    "    ignore_duplicated_nodes=True,\n",
    "    force_conversion_to_undirected=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first thing, we print a short report showing all the avalable graph details, including the number of edges, nodes, trap nodes and both the connected components and the strongly connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edges_number': '30861027',\n",
       " 'selfloops_rate': '0.000015391581103247148',\n",
       " 'is_directed': 'false',\n",
       " 'density': '0.00021902960686152735',\n",
       " 'degrees_mode': '1',\n",
       " 'unique_node_types_number': '36',\n",
       " 'degrees_median': '6',\n",
       " 'strongly_connected_components_number': '8976',\n",
       " 'unique_edge_types_number': '0',\n",
       " 'traps_rate': '0.021906677500566116',\n",
       " 'connected_components_number': '8976',\n",
       " 'degrees_min': '0',\n",
       " 'degrees_max': '90378',\n",
       " 'nodes_number': '375365',\n",
       " 'degrees_mean': '82.21604837957722',\n",
       " 'singleton_nodes': '8223',\n",
       " 'bidirectional_rate': '1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings are check that are not necessary, but are offered as sanity checks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considered parameters\n",
    "We are going to use the following parameters:\n",
    "\n",
    "- **Walk lengths:** $100$ nodes.\n",
    "- **Batch size:** $2^{7} = 128$ walks per batch.\n",
    "- **Walk iterations:** $20$ iterations on the graph.\n",
    "- **Window size:** $4$ nodes, meaning $4$ on the left and $4$ on the right of the center nodes. Consider that the first *window_size* values on the left and the right of the walks will be trimmed.\n",
    "- **Return weight, inverse of $p$:** $1.0$.\n",
    "- **Explore weight, inverse of $q$:** $1.0$.\n",
    "- **Embedding size:** $100$.\n",
    "- **Negative samples:** For the porpose of the [NCE function negative samples](https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss), we are going to use $10$. These are the number of negative classes to randomly sample per batch. This single sample of negative classes is evaluated for each element in the batch.\n",
    "- **Optimizer:** [Nadam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam).\n",
    "- **Early stopping parameters:** We are going to use an Early Stopping criterion on the *validation loss*, with patience $5$ and delta $0.0001$.\n",
    "- **Epochs:** The model will be trained up to $1000$ epochs.\n",
    "- **Learning rate:** since tipically the loss function is quite convex for the embedding problem, we can use a relatively higher learning rate. We are going to us $0.1$ for this example, to get to a faster convergence: this might lead to skipping some better minima that might be identified with a lower learning rate, such as the default one which is $0.0001$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length=100\n",
    "batch_size=2**8\n",
    "iterations=20\n",
    "window_size=4\n",
    "p=1.0\n",
    "q=1.0\n",
    "embedding_size=100\n",
    "negatives_samples=30\n",
    "patience=5\n",
    "delta=0.0001\n",
    "epochs=1000\n",
    "learning_rate=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the training and validation Keras sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen import Node2VecSequence\n",
    "\n",
    "graph_sequence = Node2VecSequence(\n",
    "    graph,\n",
    "    walk_length=walk_length,\n",
    "    batch_size=batch_size,\n",
    "    iterations=iterations,\n",
    "    window_size=window_size,\n",
    "    return_weight=1/p,\n",
    "    explore_weight=1/q\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the SkipGram model\n",
    "We are going to setup the model to use, if available, multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SkipGram\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_embedding (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 100)       37536500    words_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise_contrastive_estimation_2  (None, 375365)       37911865    flatten_2[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 75,448,365\n",
      "Trainable params: 75,448,365\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from embiggen import SkipGram\n",
    "\n",
    "strategy = MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = SkipGram(\n",
    "        vocabulary_size=graph.get_nodes_number(),\n",
    "        embedding_size=embedding_size,\n",
    "        window_size=window_size,\n",
    "        negatives_samples=negatives_samples,\n",
    "        optimizer=Nadam(learning_rate=learning_rate)\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the SkipGram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1435/1435 [==============================] - 677s 472ms/step - loss: 58.3536\n",
      "Epoch 2/1000\n",
      "1435/1435 [==============================] - 664s 463ms/step - loss: 35.8007\n",
      "Epoch 3/1000\n",
      "1435/1435 [==============================] - 667s 465ms/step - loss: 32.2220\n",
      "Epoch 4/1000\n",
      "1435/1435 [==============================] - 676s 471ms/step - loss: 27.3401\n",
      "Epoch 5/1000\n",
      "1435/1435 [==============================] - 678s 472ms/step - loss: 23.8743\n",
      "Epoch 6/1000\n",
      "1435/1435 [==============================] - 672s 468ms/step - loss: 22.7970\n",
      "Epoch 7/1000\n",
      "1435/1435 [==============================] - 668s 465ms/step - loss: 21.4614\n",
      "Epoch 8/1000\n",
      "1435/1435 [==============================] - 667s 465ms/step - loss: 19.5975\n",
      "Epoch 9/1000\n",
      "1435/1435 [==============================] - 658s 458ms/step - loss: 19.5827\n",
      "Epoch 10/1000\n",
      "1435/1435 [==============================] - 662s 461ms/step - loss: 18.9434\n",
      "Epoch 11/1000\n",
      "1435/1435 [==============================] - 665s 463ms/step - loss: 18.2576\n",
      "Epoch 12/1000\n",
      "1435/1435 [==============================] - 669s 466ms/step - loss: 17.5691\n",
      "Epoch 13/1000\n",
      "1435/1435 [==============================] - 666s 464ms/step - loss: 17.8011\n",
      "Epoch 14/1000\n",
      "1435/1435 [==============================] - 659s 459ms/step - loss: 17.8842\n",
      "Epoch 15/1000\n",
      "1435/1435 [==============================] - 646s 450ms/step - loss: 18.1442\n",
      "Epoch 16/1000\n",
      "1435/1435 [==============================] - 634s 442ms/step - loss: 17.9058\n",
      "Epoch 17/1000\n",
      "1435/1435 [==============================] - 634s 442ms/step - loss: 17.6338\n",
      "Epoch 18/1000\n",
      "1435/1435 [==============================] - 645s 450ms/step - loss: 17.4498\n",
      "Epoch 19/1000\n",
      "1435/1435 [==============================] - 620s 432ms/step - loss: 17.1121\n",
      "Epoch 20/1000\n",
      "1435/1435 [==============================] - 632s 440ms/step - loss: 17.1226\n",
      "Epoch 21/1000\n",
      "1435/1435 [==============================] - 631s 439ms/step - loss: 16.4533\n",
      "Epoch 22/1000\n",
      "1435/1435 [==============================] - 632s 441ms/step - loss: 16.6221\n",
      "Epoch 23/1000\n",
      "1435/1435 [==============================] - 634s 442ms/step - loss: 16.8457\n",
      "Epoch 24/1000\n",
      "1435/1435 [==============================] - 659s 459ms/step - loss: 16.8125\n",
      "Epoch 25/1000\n",
      "1435/1435 [==============================] - 657s 458ms/step - loss: 16.9712\n",
      "Epoch 26/1000\n",
      "1435/1435 [==============================] - 665s 463ms/step - loss: 17.0400\n",
      "Epoch 27/1000\n",
      "1435/1435 [==============================] - 663s 462ms/step - loss: 16.7362\n",
      "Epoch 28/1000\n",
      "1435/1435 [==============================] - 672s 468ms/step - loss: 16.3200\n",
      "Epoch 29/1000\n",
      "1435/1435 [==============================] - 667s 464ms/step - loss: 16.2494\n",
      "Epoch 30/1000\n",
      "1435/1435 [==============================] - 655s 456ms/step - loss: 16.8913\n",
      "Epoch 31/1000\n",
      "1435/1435 [==============================] - 653s 455ms/step - loss: 16.3812\n",
      "Epoch 32/1000\n",
      "1435/1435 [==============================] - 625s 435ms/step - loss: 16.0153\n",
      "Epoch 33/1000\n",
      "1435/1435 [==============================] - 627s 437ms/step - loss: 15.8844\n",
      "Epoch 34/1000\n",
      "1435/1435 [==============================] - 627s 437ms/step - loss: 16.1448\n",
      "Epoch 35/1000\n",
      "1435/1435 [==============================] - 638s 445ms/step - loss: 15.7419\n",
      "Epoch 36/1000\n",
      "1435/1435 [==============================] - 644s 449ms/step - loss: 16.3002\n",
      "Epoch 37/1000\n",
      "1435/1435 [==============================] - 634s 442ms/step - loss: 16.3143\n",
      "Epoch 38/1000\n",
      "1435/1435 [==============================] - 665s 463ms/step - loss: 15.6219\n",
      "Epoch 39/1000\n",
      "1435/1435 [==============================] - 657s 458ms/step - loss: 16.1357\n",
      "Epoch 40/1000\n",
      "1435/1435 [==============================] - 675s 470ms/step - loss: 16.0734\n",
      "Epoch 41/1000\n",
      "1435/1435 [==============================] - 663s 462ms/step - loss: 15.9331\n",
      "Epoch 42/1000\n",
      "1435/1435 [==============================] - 656s 457ms/step - loss: 15.3958\n",
      "Epoch 43/1000\n",
      "1435/1435 [==============================] - 669s 466ms/step - loss: 15.8503\n",
      "Epoch 44/1000\n",
      "1435/1435 [==============================] - 656s 457ms/step - loss: 16.1183\n",
      "Epoch 45/1000\n",
      "1435/1435 [==============================] - 651s 454ms/step - loss: 16.1605\n",
      "Epoch 46/1000\n",
      "1435/1435 [==============================] - 651s 454ms/step - loss: 16.3127\n",
      "Epoch 47/1000\n",
      "1435/1435 [==============================] - 648s 451ms/step - loss: 15.7636\n",
      "Epoch 48/1000\n",
      "1435/1435 [==============================] - 664s 462ms/step - loss: 15.5085\n",
      "Epoch 49/1000\n",
      "1435/1435 [==============================] - 662s 461ms/step - loss: 15.3709\n",
      "Epoch 50/1000\n",
      "1435/1435 [==============================] - 663s 462ms/step - loss: 15.7038\n",
      "Epoch 51/1000\n",
      "1435/1435 [==============================] - 659s 459ms/step - loss: 15.5451\n",
      "Epoch 52/1000\n",
      "1435/1435 [==============================] - 654s 456ms/step - loss: 15.6412\n",
      "Epoch 53/1000\n",
      "1435/1435 [==============================] - 653s 455ms/step - loss: 15.9211\n",
      "Epoch 54/1000\n",
      "1435/1435 [==============================] - 654s 456ms/step - loss: 15.5775\n",
      "Epoch 55/1000\n",
      "1435/1435 [==============================] - 660s 460ms/step - loss: 15.6942\n",
      "Epoch 56/1000\n",
      "1435/1435 [==============================] - 667s 465ms/step - loss: 15.4743\n",
      "Epoch 57/1000\n",
      "1435/1435 [==============================] - 659s 459ms/step - loss: 15.5281\n",
      "Epoch 58/1000\n",
      "1435/1435 [==============================] - 656s 457ms/step - loss: 15.2065\n",
      "Epoch 59/1000\n",
      "1435/1435 [==============================] - 653s 455ms/step - loss: 15.7934\n",
      "Epoch 60/1000\n",
      "1435/1435 [==============================] - 659s 459ms/step - loss: 15.5924\n",
      "Epoch 61/1000\n",
      "1435/1435 [==============================] - 650s 453ms/step - loss: 15.5711\n",
      "Epoch 62/1000\n",
      "1435/1435 [==============================] - 652s 454ms/step - loss: 14.9778\n",
      "Epoch 63/1000\n",
      "1435/1435 [==============================] - 644s 449ms/step - loss: 15.4375\n",
      "Epoch 64/1000\n",
      "1435/1435 [==============================] - 641s 447ms/step - loss: 15.1717\n",
      "Epoch 65/1000\n",
      "1435/1435 [==============================] - 644s 449ms/step - loss: 15.4243\n",
      "Epoch 66/1000\n",
      "1435/1435 [==============================] - 645s 450ms/step - loss: 14.7148\n",
      "Epoch 67/1000\n",
      "1435/1435 [==============================] - 642s 447ms/step - loss: 15.0169\n",
      "Epoch 68/1000\n",
      "1435/1435 [==============================] - 647s 451ms/step - loss: 15.0760\n",
      "Epoch 69/1000\n",
      "1435/1435 [==============================] - 651s 453ms/step - loss: 15.1078\n",
      "Epoch 70/1000\n",
      "1435/1435 [==============================] - 651s 454ms/step - loss: 15.2315\n",
      "Epoch 71/1000\n",
      "1435/1435 [==============================] - 644s 449ms/step - loss: 15.1900\n",
      "Epoch 72/1000\n",
      "1435/1435 [==============================] - 647s 451ms/step - loss: 15.0062\n",
      "Epoch 73/1000\n",
      "1435/1435 [==============================] - 648s 451ms/step - loss: 14.8965\n",
      "Epoch 74/1000\n",
      "1435/1435 [==============================] - 655s 457ms/step - loss: 15.3215\n",
      "Epoch 75/1000\n",
      "1435/1435 [==============================] - 652s 454ms/step - loss: 14.9683\n",
      "Epoch 76/1000\n",
      "1435/1435 [==============================] - 653s 455ms/step - loss: 15.1307\n",
      "Epoch 77/1000\n",
      "1435/1435 [==============================] - 649s 452ms/step - loss: 14.9076\n",
      "Epoch 78/1000\n",
      "1435/1435 [==============================] - 649s 452ms/step - loss: 14.7041\n",
      "Epoch 79/1000\n",
      "1435/1435 [==============================] - 648s 452ms/step - loss: 14.9413\n",
      "Epoch 80/1000\n",
      "1435/1435 [==============================] - 651s 453ms/step - loss: 14.9065\n",
      "Epoch 81/1000\n",
      "1435/1435 [==============================] - 646s 450ms/step - loss: 15.2077\n",
      "Epoch 82/1000\n",
      "1435/1435 [==============================] - 633s 441ms/step - loss: 15.3111\n",
      "Epoch 83/1000\n",
      "1435/1435 [==============================] - 628s 438ms/step - loss: 15.2528\n",
      "Epoch 84/1000\n",
      "1435/1435 [==============================] - 626s 436ms/step - loss: 15.1598\n",
      "Epoch 85/1000\n",
      "1435/1435 [==============================] - 630s 439ms/step - loss: 14.4405\n",
      "Epoch 86/1000\n",
      "1261/1435 [=========================>....] - ETA: 1:16 - loss: 14.6000"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "history = model.fit(\n",
    "    graph_sequence,\n",
    "    steps_per_epoch=graph_sequence.steps_per_epoch,\n",
    "    epochs=1000,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            \"val_loss\",\n",
    "            min_delta=delta,\n",
    "            patience=patience,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the model weights\n",
    "We save the obtained model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"{model.name}_whole_graph_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the training history\n",
    "We can visualize the performance of the model during the training process as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_keras_history import plot_history\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some hickups in the plot of the history if the model is reloaded from stored weights: [this is a known Keras issue](https://github.com/keras-team/keras/issues/4875) and is not related to either the holdouts used or the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the obtained embeddings\n",
    "Finally we save our hard earned model embeddings. In another notebook we will show how to do link prediction on the obtained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(f\"{model.name}_whole_graph_embedding.npy\", model.embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
